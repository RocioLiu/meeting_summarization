[
    {
        "uid": "1-Bdb001",
        "id": "Bdb001",
        "text": "Speaker PhD F: and  the main thing that I was gonna ask people to help with today is  to give input on what kinds of database format we should  use in starting to link up things like word transcripts and annotations of word transcripts ,\nSpeaker graduate student C: Th - there are sort of two choices .",
        "summary": "Two main options were discussed as to the organisation of the collected data.",
        "split": "train"
    },
    {
        "uid": "2-Bdb001",
        "id": "Bdb001",
        "text": "Speaker graduate student C: I mean , we  I sort of already have developed an XML format for this sort of stuff . So tha it has a single time - line ,. I think for word - level , this would be OK .",
        "summary": "On the one hand, a bespoke XML structure that connects transcriptions and annotations (down to the word-level) to a common timeline.",
        "split": "train"
    },
    {
        "uid": "3-Bdb001",
        "id": "Bdb001",
        "text": "Speaker graduate student C: and I thought it was better if you 're looking at a raw file to be  t for the tags to say \" it 's an utterance \" , as opposed to the tag to say \" it 's a link \" . One of them is that it 's easy to parse .\nSpeaker PhD F: Can you  But you can add to those structures if you \nSpeaker graduate student C: The other thing  the other way that I sort of established this was as easy translation to and from the Transcriber format .",
        "summary": "Its advantages are that it is easier to read, parse, map onto the Transcriber format and to expand with extra features.",
        "split": "train"
    },
    {
        "uid": "4-Bdb001",
        "id": "Bdb001",
        "text": "Speaker graduate student C: So I think it  it 's debatable whether you want to do phone - level in the same thing .",
        "summary": "Phone-level analysis can be included in the same structure, or in a separate, linked file.",
        "split": "train"
    },
    {
        "uid": "5-Bdb001",
        "id": "Bdb001",
        "text": "Speaker graduate student C: or  or any frame - level stuff I would use P - file . It 's ICS , ICSI has a format for frame - level representation of features . And we have a lot of tools already to deal with it . I mean , it 's something that we developed at ICSI . But , I mean , it is just something we developed at ICSI .",
        "summary": "The respective frame-level representation can be handled by P-files, a technology developed at ICSI, which also comes with a library of tools.",
        "split": "train"
    },
    {
        "uid": "6-Bdb001",
        "id": "Bdb001",
        "text": "Speaker graduate student C: More compact ,",
        "summary": "Separation of levels of analysis makes files more compact and manageable.",
        "split": "train"
    },
    {
        "uid": "7-Bdb001",
        "id": "Bdb001",
        "text": "Speaker graduate student C: There 's a  standard again in XML , specifically for searching XML documents  structured X - XML documents , where you can specify both the content and the structural position . It 's  it 's  you would use that to build your tool to do that sort of search . What you would do is , someone would build a tool that used that as a library .",
        "summary": "XML standards offer libraries that can be used for the development of search tools.",
        "split": "train"
    },
    {
        "uid": "8-Bdb001",
        "id": "Bdb001",
        "text": "Speaker graduate student C: which was their file format is just nodes and links ,",
        "summary": "On the other hand, the ATLAS (NIST) technology offers a very similar, but more generic organisational scheme based on nodes and links.",
        "split": "train"
    },
    {
        "uid": "9-Bdb001",
        "id": "Bdb001",
        "text": "Speaker graduate student C: and then \" type \" would be \" utterance \" .",
        "summary": "These are labeled with domain specific types, like \"utterance\" or \"speaker\".",
        "split": "train"
    },
    {
        "uid": "10-Bdb001",
        "id": "Bdb001",
        "text": "Speaker graduate student C: they 're developing a big infrastructure . , and apparently they 've also developed a lot of tools ,. One of the things that ATLAS is doing is they 're trying to define an API which is independent of the back store ,. so that , , you could define a single API and the  the storage could be flat XML files or a database .",
        "summary": "This option offer well-developed infrastructure and flexibility as to the type of data storage (flat XML files or relational database).",
        "split": "train"
    },
    {
        "uid": "11-Bdb001",
        "id": "Bdb001",
        "text": "Speaker PhD F: But I thought it would be good to get something that we can  that other people can use or adopt for their own kinds of encoding . And so I wanted something where  all of this can be done in a elegant way. and that if somebody wants to try something or compute something else , that it can be done flexibly .",
        "summary": "In either case, it is important for the chosen format to allow for fast searches, flexible updates and, if possible, be reusable in future work.",
        "split": "train"
    },
    {
        "uid": "12-Bed002",
        "id": "Bed002",
        "text": "Speaker professor C: Oh , this was about  , inferring intentions from features in context , and the words ,",
        "summary": "The initial task of the EDU group is to work on inferring intentions through context.",
        "split": "train"
    },
    {
        "uid": "13-Bed002",
        "id": "Bed002",
        "text": "Speaker graduate student B: So ,  what we found interesting is , first of all , intentions differ . Maybe you want to enter a building . Maybe you want to see it ,. Or maybe you actually want to come as close as possible to the building . If you don't have the intention of entering your building , but you know that something is really close to it , and you just want to approach it , or get to that building .",
        "summary": "In the navigational paradigm used for the task, these intentions are to \"see\" to \"enter\" or to \"get to the closest point of\" a building.",
        "split": "train"
    },
    {
        "uid": "14-Bed002",
        "id": "Bed002",
        "text": "Speaker graduate student B: But , , since we are designing a  a  a  an , compared to this , even bigger data collection effort ,  , we will definitely take care to put it in there ,",
        "summary": "There will be purpose-designed experiments carried out.",
        "split": "train"
    },
    {
        "uid": "15-Bed002",
        "id": "Bed002",
        "text": "Speaker graduate student B: , we can look at some factors that may make a difference . . Sometimes I found in the  , looking at the data , in a superficial way , I found some s sort of modifiers that  that m may also give us a hint ,. And this leads us straight to the context which also should be considered . And I will try to  to sort of come up with a list of factors that we need to get out of there ,\nSpeaker professor C: there 's gonna be contextual things ,. there 're gonna be linguistic things ,. there 're gonna be discourse things ,. The issue is , can we find a way to , basically , featurize it",
        "summary": "However, the starting point is, through the use of existing data, to determine possible linguistic, discourse or situation features that define intentionality.",
        "split": "train"
    },
    {
        "uid": "16-Bed002",
        "id": "Bed002",
        "text": "Speaker professor C: like \" s go to see \" , or \" visit \" , or some\nSpeaker graduate student B: This is of course a crucial factor , \" what type of object is it ? \". Then of course the  the actual phrases may give us some idea of what the person wants .\nSpeaker professor C: Oh , another thing you want is some information abou I think , about the time of day . So if it turns out that , whatever it is , you want to know whether the person 's , a tourist or not , OK ? that becomes a feature .",
        "summary": "These may include the type of building, time of day, particular phrases used or whether the user is a tourist or a native.",
        "split": "train"
    },
    {
        "uid": "17-Bed002",
        "id": "Bed002",
        "text": "Speaker professor C: and we 're able to , by hand , extract the features to put in the belief - net . If that goes well , then we can start worrying about how we would extract them .\nSpeaker graduate student F: So we 'll be like , hand , , doing all the probabilities .",
        "summary": "Initially, these features will be hand-coded, but the goal is to find ways of extracting them automatically from the XML data.",
        "split": "train"
    },
    {
        "uid": "18-Bed002",
        "id": "Bed002",
        "text": "Speaker graduate student B: if we feed it through a belief - net or  or something along those lines . We 'd get an inferred intention , we  we produce a structure that differentiates between the Vista , the Enter , and the , , Tango mode .\nSpeaker professor C: And , my idea on how to combine them is with a belief - net ,. which is going to have as output , the conditional pr probability of one of three things ,. but the idea is to take as a first goal , see if we could actually build a belief - net that would make this three way distinction , in a plausible way ,. here 're the things which , if you get them out of  out of the language and discourse , and put them into the belief - net , it would tell you which of these three , intentions is most likely . \". I think that , , if we can get the information , a belief - net is a perfectly good way of doing the inferential combination of it . JavaBayes or something ?",
        "summary": "Consequently, they will be fed into a belief-net -implemented on a software package like JavaBayes- and the conditional probability of each intention calculated.",
        "split": "train"
    },
    {
        "uid": "19-Bed002",
        "id": "Bed002",
        "text": "Speaker professor C: So one thing you could do is build a little system that , said , \" whenever you got a question like that I 've got one of three answers .\nSpeaker graduate student B: u u Sort of I 'm , at the moment , curious and I 'm  I 'm  s w want to approach it from the end where we can s sort of start with this toy system that we can play around with ,\nSpeaker professor C: and then in the longer run , you would figure out how you could derive them . From previous discourse or w any anything else you knew . And , then as soon as we have it , I think we should start trying to populate it for this problem .",
        "summary": "A prototype system will be put together to test hypotheses regarding both the exact nature of the features and how intentions are derived from them.",
        "split": "train"
    },
    {
        "uid": "20-Bed003",
        "id": "Bed003",
        "text": "Speaker graduate student B: right now it 's still kind of  in a toy  version of it ,",
        "summary": "The group discussed the first version of the Bayes-net used to work out a user's intentions when asking for directions from a navigation device.",
        "split": "train"
    },
    {
        "uid": "21-Bed003",
        "id": "Bed003",
        "text": "Speaker graduate student B: The probability  whether the probability of a Vista , Tango , or Enter .",
        "summary": "Three intentions were identified: Vista (to view), Enter (to visit) and Tango (to approach).",
        "split": "train"
    },
    {
        "uid": "22-Bed003",
        "id": "Bed003",
        "text": "Speaker graduate student B: So then the features we decided  or we decided we were  talked about ,. You know . We had a list of things like \" to go \" and \" to visit \" and what not . the  the prosody , the discourse ,  verb choice .\nSpeaker graduate student D: So there are certain cues that are very strong  either lexical or topic - based , concept cues. and some of them are sort of  either world knowledge or situational  things .\nSpeaker graduate student A: is that maybe we ob we could observe a couple of discourse phenomena such as the admission fee ,",
        "summary": "The structure of the belief-net comprises, firstly, a feature layer, which includes linguistic, discourse and world knowledge information that can be gleaned from the data.",
        "split": "train"
    },
    {
        "uid": "23-Bed003",
        "id": "Bed003",
        "text": "Speaker graduate student A: So maybe this could be sort of a separate region of the net ,  which has two   has it 's own middle layer . They ra may have there own hidden layer  that points to some of  the  the real hidden layer , or the general hidden layer .",
        "summary": "It is possible for these variables to form thematic clusters( eg \"entrance\", \"type of object\", \"verb\"), each one with a separate middle layer.",
        "split": "train"
    },
    {
        "uid": "24-Bed003",
        "id": "Bed003",
        "text": "Speaker graduate student B: but the middle thing , we were thinking along the lines of maybe trying to figure out , like , the concept of whether they 're a tourist  or  whether they 're running an errand or something like that. So then the hidden variables  hair variables we came up with were whether someone was on a tour , running an errand , or whether they were in a hurry ,\nSpeaker graduate student C: but the other ones , the final destination , the whether they 're doing business , whether they 're in a hurry , and whether they 're tourists ,\nSpeaker graduate student A: They ra may have there own hidden layer  that points to some of  the  the real hidden layer , or the general hidden layer . And then these should then connect somehow to the more plan - based deep space",
        "summary": "These feed, in turn, into the main middle layer, that defines more general hidden variables, such as the tourist/business status of the user.",
        "split": "train"
    },
    {
        "uid": "25-Bed003",
        "id": "Bed003",
        "text": "Speaker graduate student D: So there are certain cues that are very strong  either lexical or topic - based , concept cues\nSpeaker graduate student A: so  maybe what  what  what happened  what might happen is that we do get this sort of task - based middle layer ,\nSpeaker graduate student D: entering or som you know like they might be more task - based .",
        "summary": "The feature layer can end up being cue-based, while the middle layers task-based.",
        "split": "train"
    },
    {
        "uid": "26-Bed003",
        "id": "Bed003",
        "text": "Speaker graduate student B: So . The mode  basically has three different  outputs .",
        "summary": "The latter determine the final probability of each intention in the output layer.",
        "split": "train"
    },
    {
        "uid": "27-Bed003",
        "id": "Bed003",
        "text": "Speaker graduate student C: it 's cra has a GUI and it 's . But  it 's free .\nSpeaker graduate student B: But actually it had an interface . and he 's updated it for an XML version of I guess Bayes - nets .",
        "summary": "This first model of the belief-net was built in JavaBayes, since it is a free package, has a graphical interface, and it can take XML files as input.",
        "split": "train"
    },
    {
        "uid": "28-Bed003",
        "id": "Bed003",
        "text": "Speaker graduate student C: Like ,  we totally hand - tuned the probabilities ,. The probabilities and all are completely ad - hoc .",
        "summary": "At this stage, all the actual probabilities are ad-hoc and hand-coded.",
        "split": "train"
    },
    {
        "uid": "29-Bed003",
        "id": "Bed003",
        "text": "Speaker graduate student A: But  in terms of specifying the scenario ,     we 've gotten a little further. So we wanted just to collect data , to get  that  that  that  elicits more , , that elicits richer language .",
        "summary": "However, there has been progress in the design and organisation of experiments, that will eventually provide data more useful and appropriate for this task.",
        "split": "train"
    },
    {
        "uid": "30-Bed004",
        "id": "Bed004",
        "text": "Speaker graduate student D: So . On Friday we had our wizard test data test and  these are some of the results .",
        "summary": "A test run of the data collection design was very successful.",
        "split": "valid"
    },
    {
        "uid": "31-Bed004",
        "id": "Bed004",
        "text": "Speaker graduate student D: , we have to refine the tasks more and more , which of course we haven't done at all , so far , in order to avoid this rephrasing ,. And my suggestion is of course we  we keep the wizard , because I think she did a wonderful job ,\nSpeaker professor B:  And also if she 's willing to take on the job of organizing all those subjects and stuff that would be wonderful .",
        "summary": "The group decided to hire the \"wizard\" and continue with the refinement of the design and recruitment of subjects.",
        "split": "valid"
    },
    {
        "uid": "32-Bed004",
        "id": "Bed004",
        "text": "Speaker graduate student A: So , what I did for this  this is  , a pedagogical belief - net. and I grouped things according to what  how I thought they would fit in to image schemas that would be related . Well , this is not a working Bayes - net .\nSpeaker graduate student D: But the  the  the nice thing is that you know , it just is a  is a visual aid for thinking about these things which has comple clearly have to be specified m more carefully",
        "summary": "It is not a working net yet, but identifying clusters of features that define the output mode provides a visual aid for further work.",
        "split": "valid"
    },
    {
        "uid": "33-Bed004",
        "id": "Bed004",
        "text": "Speaker professor B: is , if we just do this , we could wind up with a huge , combinatoric input to the Mode thing . , we have a d a technical problem with the belief - nets that we  we don't want all the com. too many factors if we  if we allow them to just go combinatorially .",
        "summary": "There are potential problems from a combinatorics perspective.",
        "split": "valid"
    },
    {
        "uid": "34-Bed004",
        "id": "Bed004",
        "text": "Speaker professor B: which is there are technical ways of doing it ,. And the other trick , which is not a technical trick , it 's kind of a knowledge engineering trick , is to make the n  each node sufficiently narrow that you don't get this combinatorics .",
        "summary": "These can be tackled either with technical adjustments or through careful knowledge engineering.",
        "split": "valid"
    },
    {
        "uid": "35-Bed004",
        "id": "Bed004",
        "text": "Speaker professor B: we have to add , you know , not too much about object types and stuff ,. that 's another sort of thing \" OK , here 's a  another kind of minimal way of tackling this \" . Add extra properties ,. a deterministic rule for every property",
        "summary": "A base solution for the task would be to simply add some extra action-mode rules in the SmartKom system.",
        "split": "valid"
    },
    {
        "uid": "36-Bed004",
        "id": "Bed004",
        "text": "Speaker graduate student D: And  and here is exactly where what 's gonna be replaced with our Bayes - net ,",
        "summary": "Action modes, however, can be inferred more efficiently by feeding a collection of features -from the ontology, discourse history, parsing, etc.- into Bayes-nets that would replace those rules.",
        "split": "valid"
    },
    {
        "uid": "37-Bed004",
        "id": "Bed004",
        "text": "Speaker professor B: So . What you 're trying to get out of this deep co cognitive linguistics is the fact that w if you know about source  source , paths and goals , and nnn  all this sort of stuff , that a lot of this is the same , for different tasks . And that  there 's  there 's some  some important generalities that you 're getting ,. So that if you have sources , you have trajectors and stuff like that ,. But what I 'd like to be able to do is to have the way that you extract properties , that will go into different Bayes - nets , be the  general . What you 'd really like of course is the same thing you 'd always like which is that you have a kind of intermediate representation which looks the same o over a bunch of inputs and a bunch of outputs .",
        "summary": "For instance, the final combination of features used in the current study may form a representation of the ontology, general enough to employ in any task that includes trajectors and paths.",
        "split": "valid"
    },
    {
        "uid": "38-Bed005",
        "id": "Bed005",
        "text": "Speaker professor B: What we think is gonna happen is that , , in parallel starting about now  we 're gonna get Fey  to , where you 're working with me and Robert , draft a note that we 're gonna send out to various CogSci c and other classes saying , \" here 's an opportunity to be a subject . But what I 'd like to do , if it 's O K ,  is to s to , as I say , start the recruiting in parallel and possibly start running subjects next week .",
        "summary": "The data collection running in parallel with the project can start shortly with recruiting subjects.",
        "split": "train"
    },
    {
        "uid": "39-Bed005",
        "id": "Bed005",
        "text": "Speaker graduate student C: And ,  and now it 's  We have a complete English parser that does everything the German parser does . And it still is , now in English .\nSpeaker professor B: That , these guys did in a  in a day .",
        "summary": "Meanwhile, the german parser now works with english sentences.",
        "split": "train"
    },
    {
        "uid": "40-Bed005",
        "id": "Bed005",
        "text": "Speaker graduate student D: One thing I was wondering , was , those functions there , are those things that modify the M - three - L basically ?. I think each of those functions act on the current XML structure , and change it in some way , for example , by adding a  a l a field to it , or something .\nSpeaker professor B: there were other actions , that  that s seemed to step  state variables somewhere ,. which , in German , , takes these t sentence templates and produces XML structures .",
        "summary": "The parser's output modifies the XML used by the system to initiate actions and generate responses.",
        "split": "train"
    },
    {
        "uid": "41-Bed005",
        "id": "Bed005",
        "text": "Speaker graduate student C:  You  you have a route ,. And every  every element of that e r r f of that  Every segment we call a \" route element \" . where y where  you sort of end , and some points of interest along the way .",
        "summary": "The XML for Map requests also comprise a route, route elements and points of interest along the way.",
        "split": "train"
    },
    {
        "uid": "42-Bed005",
        "id": "Bed005",
        "text": "Speaker graduate student C: is one , ,   Also allocating , , some tags for our Action Schema Enter - Vista - Approach ,",
        "summary": "It is at this level that Enter/Vista/Approach tags will be added as action modes.",
        "split": "train"
    },
    {
        "uid": "43-Bed005",
        "id": "Bed005",
        "text": "Speaker professor B: , at some point we 're going to have to worry about the language end .",
        "summary": "As the project evolves, further enrichment of the ontology (actions, linguistic features) will be necessary.",
        "split": "train"
    },
    {
        "uid": "44-Bed005",
        "id": "Bed005",
        "text": "Speaker professor B: Eh  so , you  you  you may or  So , then you 'd have this little vector of , , you know , Approach Mode or EVA Mode . It 's part of what you know about  a  an object ,  is its EVA vector .",
        "summary": "Similarly, object representations will include an EVA vector.",
        "split": "train"
    },
    {
        "uid": "45-Bed005",
        "id": "Bed005",
        "text": "Speaker professor B: If you know it for a specific landmark you put it there . If you don't , you just go up the hierarchy to the first place you find one . If it 's that type of thing , and we want its EVA vector , pppt - pppt !  it 's that . \"",
        "summary": "This can be incorporated in the database entry for a particular building or inherited from the ontology of the building type.",
        "split": "train"
    },
    {
        "uid": "46-Bed005",
        "id": "Bed005",
        "text": "Speaker graduate student D: the typical example is that , , these are all a bunch of cues for something ,. and this is a certain effect that we 'd like to conclude .",
        "summary": "These elements will constitute only a small part of the inputs of the Bayes-net that determines the action mode.",
        "split": "train"
    },
    {
        "uid": "47-Bed005",
        "id": "Bed005",
        "text": "Speaker graduate student D: And , that 's a lot of probabilities to put here , which is kind of a pain .",
        "summary": "The actual number of the inputs can create a combinatorial explosion when setting the probabilities.",
        "split": "train"
    },
    {
        "uid": "48-Bed005",
        "id": "Bed005",
        "text": "Speaker graduate student D: So  Noisy - ORs are a way to , ,  sort of deal with this . So we come up with these l little tables for each of those. And the final thing is that ,    this is a deterministic function of these ,\nSpeaker professor B: Th - c the full conditional probability table  with some function .",
        "summary": "Noisy-OR's can help avoid this by simplifying the probability tables and applying a deterministic function to produce their complete version.",
        "split": "train"
    },
    {
        "uid": "49-Bed006",
        "id": "Bed006",
        "text": "Speaker graduate student G: so they 'll have a little bit more natural interaction ?",
        "summary": "The data collection script has been slightly modified, so that it encourages more natural dialogue between the subjects and the \"wizard\".",
        "split": "train"
    },
    {
        "uid": "50-Bed006",
        "id": "Bed006",
        "text": "Speaker graduate student C: And we have a little description of asking peop subjects to contact Fey for you know recruiting them for our thing. however there is always more people in a  in a facul in a department than are just taking his class or anybody else 's class at the moment. And then we 're going to have another  we 're gonna have w another trial run",
        "summary": "Another trial run will take place, while a call to recruit subjects is being emailed to students.",
        "split": "train"
    },
    {
        "uid": "51-Bed006",
        "id": "Bed006",
        "text": "Speaker graduate student C: , the basic requirement is fulfilled almost . you can speak into it and ask for TV and movie information",
        "summary": "Meanwhile, the translation of the TV and cinema information system to english is almost complete.",
        "split": "train"
    },
    {
        "uid": "52-Bed006",
        "id": "Bed006",
        "text": "Speaker graduate student C: Then on to the modeling . In the future though , the content of a hypothesis will not only be an object and an  an action and a domain object but an action , a domain object , and a rich action description ,",
        "summary": "On the other hand, there was a presentation of the model that offers more elaborate action planning for SmartKom, of which Enter/View/Approach (EVA) modes are a part.",
        "split": "train"
    },
    {
        "uid": "53-Bed006",
        "id": "Bed006",
        "text": "Speaker graduate student B: Inside of Enter there will be roles that can be filled basically .",
        "summary": "These modes will form categories of complete XML schemas with information filled in from the language understanding in a more elaborate way than the current Object-\"Go Action\"-Object model.",
        "split": "train"
    },
    {
        "uid": "54-Bed006",
        "id": "Bed006",
        "text": "Speaker graduate student C: The idea is , so , imagine we have a library of schema. such as the Source - Path - Goal\nSpeaker graduate student E: Well one of the types of action schemas is Source - Path - Goal action .",
        "summary": "These categories will, in turn, be linked with action schemas, one of which is Source-Path-Goal (SPG).",
        "split": "train"
    },
    {
        "uid": "55-Bed006",
        "id": "Bed006",
        "text": "Speaker graduate student C: The idea is , so , imagine we have a library of schema\nSpeaker graduate student B: So if you wanted to have a new type of action you 'd create a new type of category .",
        "summary": "Categories and action schemas can have -in theory- any number of blocks depending on the expansion of the domain.",
        "split": "train"
    },
    {
        "uid": "56-Bed006",
        "id": "Bed006",
        "text": "Speaker graduate student C: meaning we can reference . and link it to another one , and this not only within a document but also via documents ,",
        "summary": "The notation provides for linking and referencing between different schemas.",
        "split": "train"
    },
    {
        "uid": "57-Bed006",
        "id": "Bed006",
        "text": "Speaker graduate student B: And then those actions can be in multiple categories at the same time if necessary .\nSpeaker graduate student C: it 's  it 's crucially necessary , is that we can have multiple schemas and multiple action schemas in parallel .",
        "summary": "The model also allows for multiple action schemas to be triggered in parallel.",
        "split": "train"
    },
    {
        "uid": "58-Bed006",
        "id": "Bed006",
        "text": "Speaker graduate student C: and I agree that you know this is something we need to discuss ,",
        "summary": "However, the structure of the model is open for discussion, since its use was to elicit discussion and highlight issues.",
        "split": "train"
    },
    {
        "uid": "59-Bed008",
        "id": "Bed008",
        "text": "Speaker professor B: one of which is just lay out the influence structure of what we think influences what",
        "summary": "Its structure was discussed during the meeting.",
        "split": "train"
    },
    {
        "uid": "60-Bed008",
        "id": "Bed008",
        "text": "Speaker professor B: the way we had been designing this , there were three intermediate nodes. which were the endpoint decision as seen from the user model as seen from the ontology and as seen from the discourse .\nSpeaker graduate student D: These are all like saying EV or A ,",
        "summary": "There are several endpoints (User, Ontology, Discourse etc) with separate EVA (Enter/View/Approach) values.",
        "split": "train"
    },
    {
        "uid": "61-Bed008",
        "id": "Bed008",
        "text": "Speaker professor B: one of which is just lay out the influence structure of what we think influences what",
        "summary": "Details of how different inputs feed into them were discussed at length.",
        "split": "train"
    },
    {
        "uid": "62-Bed008",
        "id": "Bed008",
        "text": "Speaker graduate student E: if it 's fixing things selling things , or servicing things\nSpeaker professor B: so the idea would be that you might wanna merge those three. you could have a node that 's  that was a measure of the match between the object 's feature , you know , the match between the object the entity , I 'm sorry and the user .",
        "summary": "Ideas mentioned included grouping features of buildings like \"selling\", \"fixing\" and \"exhibiting\", as well as creating a User-compatibility node that would take different values depending on the situation and the user status.",
        "split": "train"
    },
    {
        "uid": "63-Bed008",
        "id": "Bed008",
        "text": "Speaker graduate student E: So here is the  the  we had that the user 's budget may influence the outcome of decisions .\nSpeaker professor B: Well the fir see the first thing is , getting back to thing we left out of the other is the actual discourse .",
        "summary": "Similarly, a Go-there (towards a building) node can be influenced by things like the user's budget and discourse parameters amongst other things.",
        "split": "train"
    },
    {
        "uid": "64-Bed008",
        "id": "Bed008",
        "text": "Speaker professor B: and we don't know what they are yet .",
        "summary": "The latter are still ill-defined at this stage.",
        "split": "train"
    },
    {
        "uid": "65-Bed008",
        "id": "Bed008",
        "text": "Speaker professor B: because we 're gonna want to know you know , which constructions indicate various of these properties",
        "summary": "The study of the linguistic constructions that people use in this kind of navigational domain is expected to be prove useful in that respect.",
        "split": "train"
    },
    {
        "uid": "66-Bed008",
        "id": "Bed008",
        "text": "Speaker graduate student D: So recall the basic problem which is that you have a belief - net and you have like a lot of different nodes all contributing to one node . So the problem is to specify the so the conditional property of this given all those ,",
        "summary": "As each node in the tree is the decision point of the combination of its parent nodes, which rules govern this combination is an important issue.",
        "split": "train"
    },
    {
        "uid": "67-Bed008",
        "id": "Bed008",
        "text": "Speaker graduate student D: and we just take the we essentially take averages ,. This is a hidden variable .\nSpeaker graduate student C: W I was just , if you wanted to pay attention to more than one you could pass a w a weighting s system though too ,",
        "summary": "There are several approaches ranging from simply averaging the inputs to using a hidden variable in order to weight them differently depending on context.",
        "split": "train"
    },
    {
        "uid": "68-Bed008",
        "id": "Bed008",
        "text": "Speaker graduate student C: OK , so they  they could either be hand coded or learned or",
        "summary": "If the latter architecture is used, the net could -to an extent- be trained with the data that is currently being collected.",
        "split": "train"
    },
    {
        "uid": "69-Bed009",
        "id": "Bed009",
        "text": "Speaker graduate student B:  so far I 've thought of it as sort of adding it onto the modeler knowledge module .\nSpeaker professor F: We talked about this several times that  that  the  the input end is gonna need a fair amount of feedback from the planning end . So we talked about the fact that There 're going to be a certain number of decisions That you want the knowledge modeler to make , that will be then fed to the function module , that does , route planning .",
        "summary": "The Berkeley Even Deeper Understanding group discussed plans and concerns regarding the architecture of SmartKom, its proposed modules, and the types of interactions expected to take place between modules.",
        "split": "valid"
    },
    {
        "uid": "70-Bed009",
        "id": "Bed009",
        "text": "Speaker graduate student B: and then that can be sort of developed as needed when we get  enter the tourism domain .\nSpeaker professor F: We probably won't do this early on , because the current focus is more on the decision making and stuff like that .",
        "summary": "The meeting was largely focused on SmartKom's decision making capacity and how to adapt this functionality to the tourist information domain.",
        "split": "valid"
    },
    {
        "uid": "71-Bed010",
        "id": "Bed010",
        "text": "Speaker graduate student E: Right now it 's brittle and you need to ch start it up and then make ts twenty changes on  on  on  on seventeen modules before they actually can stomach it , anything . we can even make a  sort of an internal demo ,. .  Well it was just amazing to  to see how  how instable the whole thing is ,",
        "summary": "The system is still buggy and unstable, but it will soon be ready for a demonstration.",
        "split": "train"
    },
    {
        "uid": "72-Bed010",
        "id": "Bed010",
        "text": "Speaker professor C: n no , to just get the dem get the demos they need . So th the demo the demo requirements for this Fall are sort of taken care of as of later this week or something .",
        "summary": "This is the first of two working demos required for the project.",
        "split": "train"
    },
    {
        "uid": "73-Bed010",
        "id": "Bed010",
        "text": "Speaker professor C: But , more focused on an idealized version than just getting the demo out .",
        "summary": "Further than that, there are no restrictions on the focus of the research or its possible applications.",
        "split": "train"
    },
    {
        "uid": "74-Bed010",
        "id": "Bed010",
        "text": "Speaker professor C: And so these issues about , reference , and  spatial  reference , discourse reference , - - -  all this sort of stuff , , deixis which is part of what you were talking about ,. So we gotta do all this .",
        "summary": "For example, issues like spatial descriptions could be investigated.",
        "split": "train"
    },
    {
        "uid": "75-Bed010",
        "id": "Bed010",
        "text": "Speaker graduate student E: On this scale , you have it either be ego or allocentric .\nSpeaker professor C: So in addition to e ego and allocentric which appear all over the place , you also apparently have this proximal - distal thing which is very deeply embedded .",
        "summary": "The variety of linguistic conventions seem to develop around an ego/allo-centric and a proximal/distal paradigm.",
        "split": "train"
    },
    {
        "uid": "76-Bed010",
        "id": "Bed010",
        "text": "Speaker professor C: By the way , there  something that I didn't know until about a week ago or so , is apparently , there are separate brain areas for things within reach , and things that are out of reach .",
        "summary": "The latter is also reflected in neuro-physiological data.",
        "split": "train"
    },
    {
        "uid": "77-Bed010",
        "id": "Bed010",
        "text": "Speaker professor C: so , I think as far as this group goes , , it 's certainly worth continuing for the next few weeks to get closure on the belief - net and the ideas that are involved in that , and what are th what are the concepts .",
        "summary": "From an engineering perspective, the belief-net for the AVE task should be completed within a few weeks.",
        "split": "train"
    },
    {
        "uid": "78-Bed010",
        "id": "Bed010",
        "text": "Speaker professor C: and we went through this , and , I think , more or less convinced ourselves that at least the vast majority of the nodes that we needed for the demo level we were thinking of , were in there .",
        "summary": "The majority of the nodes are already there.",
        "split": "train"
    },
    {
        "uid": "79-Bed010",
        "id": "Bed010",
        "text": "Speaker professor C: OK ? What all  you know , what are the considerations and how and what are the ways in which they relate .",
        "summary": "This leaves the dependencies between them and the rules of computation to be set.",
        "split": "train"
    },
    {
        "uid": "80-Bed010",
        "id": "Bed010",
        "text": "Speaker professor C: So \" OK , we 're not using their system . That means we need our system . \". But to do that we 're gonna need to make some decisions like ontology ,. i Does either the SmartKom project or one of the projects at EML have something that we can just p pull out , for that .",
        "summary": "Since the whole system is going to be re-designed, there are major decisions to be taken regarding the parser and the ontology, as well as what can be re-used from past EML projects.",
        "split": "train"
    },
    {
        "uid": "81-Bed010",
        "id": "Bed010",
        "text": "Speaker professor C: so The idea is there 's this , other subgroup that 's worrying about formalizing the nota getting a notation .",
        "summary": "In parallel, another team is working on formalisation and notation.",
        "split": "train"
    },
    {
        "uid": "82-Bed010",
        "id": "Bed010",
        "text": "Speaker professor C: Oh there 's yet another one of the incoming first   incoming first - year graduate students who 's expressed interest ,. And actually I talked today to a undergraduate who wants to do an honors thesis on this . And , while we 're at this level , , there 's at least one new doctoral student in computer science who will be joining the project , either next week or the first of August , depending on the blandishments of Microsoft .",
        "summary": "Finally, more ideas are expected to come from students and their research.",
        "split": "train"
    },
    {
        "uid": "83-Bed011",
        "id": "Bed011",
        "text": "Speaker professor D: one of them is to work on the semantics of the belief - net which is going to be the main inference engine for thi the system making decisions . And we 're also , sort of in the same process , going to work with Fey on what there should be in the dialogues .",
        "summary": "The main focus of the meeting was firstly on the structure of the belief-net, its decision nodes and the parameters that influence them, and secondly, on the design of the data collection tasks.",
        "split": "train"
    },
    {
        "uid": "84-Bed011",
        "id": "Bed011",
        "text": "Speaker graduate student C: And  And Fey has some thirty subjects lined up ?\nSpeaker professor D: So we  yeah we don't know how many we can get next door at the  shelter for example .",
        "summary": "For the latter, there are already 30 subjects lined up and more are expected to be recruited off campus.",
        "split": "train"
    },
    {
        "uid": "85-Bed011",
        "id": "Bed011",
        "text": "Speaker graduate student C: And  And then they gonna have to f choose from one of these tasks , which are listed here .\nSpeaker professor D: so if  if it 's one service , one luxury item , you know , one big - ish place , and so forth and so on ,  then my guess is that  that the data is going to be easier to handle .\nSpeaker undergraduate student E: That w maybe one thing we should do is go through this list and sort of select things that are categories and then o offer only one member of that category ?",
        "summary": "It was agreed that making subjects select from categories of tasks, such as \"big place\", \"service\", etc. could provide a better range of data.",
        "split": "train"
    },
    {
        "uid": "86-Bed011",
        "id": "Bed011",
        "text": "Speaker professor D: I b My guess is it 's gonna be ten .",
        "summary": "The duration of each dialogue will probably be no more than 10 minutes.",
        "split": "train"
    },
    {
        "uid": "87-Bed011",
        "id": "Bed011",
        "text": "Speaker professor D: And decisions are going to turn out to be parameter choices for calls on other modules .",
        "summary": "These nodes represent decisions that will function as parameters to action calls in the system.",
        "split": "train"
    },
    {
        "uid": "88-Bed011",
        "id": "Bed011",
        "text": "Speaker graduate student C: And that we can actually infer them to a significant de degree , or we ask .\nSpeaker professor D: Or  eh so , y but there 's th but definitely a back - off position to asking .",
        "summary": "Their values will either be inferred from the user-system interaction, or -as a last resort- requested directly from the user.",
        "split": "train"
    },
    {
        "uid": "89-Bed011",
        "id": "Bed011",
        "text": "Speaker professor D: OK , Because  we do wanna get them r u perfectly  but I think we 're gonna have to do a first cut at a lot of them to see how they interact .",
        "summary": "Finally, as to the semantic and syntactic constructions, work will start with more general and brief descriptions, before moving to exhaustive analysis of at least a subset.",
        "split": "train"
    },
    {
        "uid": "90-Bed011",
        "id": "Bed011",
        "text": "Speaker professor D: We are expecting Johno to build a parser ,.  He 's g he 's hoping to do this for his masters ' thesis s by a year from now .  limited . Well , the hope is that the parser itself is , , pretty robust .",
        "summary": "Similarly, the construction parser that is to be built within a year is expected to be relatively basic, yet robust.",
        "split": "train"
    },
    {
        "uid": "91-Bed012",
        "id": "Bed012",
        "text": "Speaker graduate student B: That 's basically  just specifying the  the input for the  w what 's\nSpeaker graduate student A: it 's based on things like , , there 's gonna be a node for Go - there or not , and there 's gonna be a node for Enter , View , Approach .",
        "summary": "The input layer deriving information from things like the user and situation models, feeds into a set of decision nodes, such as the Enter/View/Approach (EVA) endpoint.",
        "split": "train"
    },
    {
        "uid": "92-Bed012",
        "id": "Bed012",
        "text": "Speaker graduate student B: And some  some things will always be sort of too  not significant enough .",
        "summary": "In any particular situation, most of the outputs will not be relevant to the given context.",
        "split": "train"
    },
    {
        "uid": "93-Bed012",
        "id": "Bed012",
        "text": "Speaker graduate student A: Cuz , that 's what  I mean , in the Bayes - net you always ask for the posterior probability of a specific node .",
        "summary": "Therefore, they will either have to be pruned a posteriori, or only a subset of the possible decision nodes will be computed in each occasion.",
        "split": "train"
    },
    {
        "uid": "94-Bed012",
        "id": "Bed012",
        "text": "Speaker graduate student B: I mean , maybe it does make a difference in terms of performance , computational time .\nSpeaker graduate student C: So basically , you 'd have a decision tree  query ,  Go - there . And just basically do a binary search through the  ?",
        "summary": "The latter option could could follow a binary search-tree approach and it could also be better in computational terms.",
        "split": "train"
    },
    {
        "uid": "95-Bed012",
        "id": "Bed012",
        "text": "Speaker graduate student C: You won't  it 'll be hard to decide .",
        "summary": "In any case, on what basis the \"winner\" output is chosen is not clear.",
        "split": "train"
    },
    {
        "uid": "96-Bed012",
        "id": "Bed012",
        "text": "Speaker graduate student C: And for the Where - Is construction , we know we need to l look at this node , that merges these three things together. So my i So , if we were to it with a Bayes - net , we 'd have to have a node  for every question that we knew how to deal with ,. Every construction .",
        "summary": "One suggestion was discussed: the particular constructions used can determine the pertinent decision (output) nodes.",
        "split": "train"
    },
    {
        "uid": "97-Bed012",
        "id": "Bed012",
        "text": "Speaker graduate student B: And , , finish up this Bayes - net . And we present our results ,",
        "summary": "The complete prototype of the Bayes-net will be presented in the next meeting.",
        "split": "train"
    },
    {
        "uid": "98-Bed012",
        "id": "Bed012",
        "text": "Speaker graduate student B: OK . Because then , once we have it sort of up and running , then we can start you know , defining the interfaces. and then hook it up to some fake construction parser",
        "summary": "After that, it will be possible to define interfaces and a dummy construction parser, in order to test and link modules together.",
        "split": "train"
    },
    {
        "uid": "99-Bed013",
        "id": "Bed013",
        "text": "Speaker graduate student D: and the other bit of news is we had  you know , , I was visited by my German project manager. and he came up  we came up  with a pretty strange idea . It should be possible to make that system produce questions .",
        "summary": "An idea for future work was suggested during the visit of the german project manager: the possibility to use the same system for language generation.",
        "split": "train"
    },
    {
        "uid": "100-Bed013",
        "id": "Bed013",
        "text": "Speaker graduate student D: But maybe one could do some learning .",
        "summary": "Having a system able to ask questions could contribute significantly to training the belief-net.",
        "split": "train"
    },
    {
        "uid": "101-Bed013",
        "id": "Bed013",
        "text": "Speaker graduate student B: The basic idea I guess would be to give  allow the system to have intentions , basically ?\nSpeaker graduate student D: Well you can observe some user and context stuff and ask , what 's the posterior probabilities of all of our decision nodes .",
        "summary": "Setting up certain inputs in the Bayes-net would imply certain intentions, which would trigger dialogues.",
        "split": "train"
    },
    {
        "uid": "102-Bed013",
        "id": "Bed013",
        "text": "Speaker graduate student B: I mean we just  I mean it wouldn't hurt to write up a paper ,\nSpeaker graduate student D: Well , I  I also think that if we sort of write about what we have done in the past six months , we  we  we could sort of craft a nice little paper that  if it gets rejected , which could happen , doesn't hurt. And then we can say , well what we do is this .",
        "summary": "There is potential to make a conference paper out of presenting the current work and the project aspirations within a parsing paradigm.",
        "split": "train"
    },
    {
        "uid": "103-Bed013",
        "id": "Bed013",
        "text": "Speaker graduate student D: So this will be sort of documenting what we think , and documenting what we have in terms of the Bayes - net stuff . Well , in the moment it 's a Bayes - net . And it has sort of fifty not - yet - specified interfaces .",
        "summary": "The focus should be the Bayes-net, to which all other modules interface.",
        "split": "train"
    },
    {
        "uid": "104-Bed013",
        "id": "Bed013",
        "text": "Speaker graduate student D: The SUDO - square  is ,  \" Situation \" , \" User \" , \" Discourse \" , right ? \" Ontology \" .",
        "summary": "Situation, User, Discourse and Ontology feed into the net to infer user intentions.",
        "split": "train"
    },
    {
        "uid": "105-Bed013",
        "id": "Bed013",
        "text": "Speaker graduate student D: and Johno coming up with the idea that if the person discussed the  discussed the admission fee , in  eh previously , that might be a good indication that , \" how do I get to the castle ? \" , actually he wants to enter .",
        "summary": "Someone asking where the castle is after having asked about the admission fee, indicates that -given that the castle is open to tourists- they want to go there, as opposed to knowing its whereabouts.",
        "split": "train"
    },
    {
        "uid": "106-Bed013",
        "id": "Bed013",
        "text": "Speaker graduate student D: and specify , what  what we think the  the output , observe , out  i input nodes for our Bayes - nets for the sub sub - D , for the discourse bit , should be . So we want to sort of come up with what gets , input , and how inter in case of a \" where is \" question . so that we actually end up with , , nodes for the discourse and ontology. so that we can put them into our Bayes - net ,",
        "summary": "It was suggested that they start analysing what the Discourse and Ontology would give as inputs to the Bayes-net by working on simple utterances like \"where is X?\".",
        "split": "train"
    },
    {
        "uid": "107-Bed013",
        "id": "Bed013",
        "text": "Speaker graduate student D: and we can run our better JavaBayes , and have it produce some output .",
        "summary": "With this addition, all input layers of the net would be functioning.",
        "split": "train"
    },
    {
        "uid": "108-Bed014",
        "id": "Bed014",
        "text": "Speaker graduate student E: and Eva is using the Xalan style sheet processor to convert the XML that 's output by the Java Bayes for the  into the , , E Bayes input .",
        "summary": "Minor technical issues,such as format conversions for XML and JavaBayes and the full translation of the SmartKom generation module in English, are currently being resolved.",
        "split": "train"
    },
    {
        "uid": "109-Bed014",
        "id": "Bed014",
        "text": "Speaker graduate student E: Yep . We ha we have to change the voice .",
        "summary": "The voice synthesiser will also be replaced by better technology.",
        "split": "train"
    },
    {
        "uid": "110-Bed014",
        "id": "Bed014",
        "text": "Speaker professor C: , w Which is  mental spaces and  and - or . But the other part of it is the way they connect to these , , probabilistic relational models .",
        "summary": "An important research issue to be investigated is how the concept of mental spaces and probabilistic relational models can be integrated into the belief-net.",
        "split": "train"
    },
    {
        "uid": "111-Bed014",
        "id": "Bed014",
        "text": "Speaker professor C: so there probably are some , , relatively clean rules ,. is that people do manage to do this",
        "summary": "Mental space interdependencies are based on relatively clean rules, since people seem to manage them easily.",
        "split": "train"
    },
    {
        "uid": "112-Bed014",
        "id": "Bed014",
        "text": "Speaker professor C: No , I know , I th I I think that is gonna be sort of the key to this wh to th the big project of the summer of  of getting the constructions right",
        "summary": "A step towards this goal is the construction formalism being put together.",
        "split": "train"
    },
    {
        "uid": "113-Bed014",
        "id": "Bed014",
        "text": "Speaker graduate student A: which is the issue of , , how do you simulate questions ?\nSpeaker professor C: We didn't  we never did figure out how we were gonna do emphasis in  in , the semspec . incl including the questions \nSpeaker graduate student A: , no , all the focus stuff . and we 'll figure out exactly how to write that up and so on ,",
        "summary": "This module will eventually have to include ways to simulate questions, do emphasis and focus.",
        "split": "train"
    },
    {
        "uid": "114-Bed014",
        "id": "Bed014",
        "text": "Speaker graduate student A: The question of whether the polysemy is sort of like in the construction or pragmatic . Well the question is basically , is this conventional or conversational implicature ?",
        "summary": "The constructions could be built assuming either conventional or conversational implicature.",
        "split": "train"
    },
    {
        "uid": "115-Bed014",
        "id": "Bed014",
        "text": "Speaker professor C: W we know for sure that we have to be able to do both . I mean it  th  I can thi I can think of arguments in either direction on that .",
        "summary": "At this stage both routes need to be examined.",
        "split": "train"
    },
    {
        "uid": "116-Bed014",
        "id": "Bed014",
        "text": "Speaker professor C: Right . So .  Right . So thing  That 's part of why we want the formalism ,",
        "summary": "The formalism will also serve as a starting point for the definition of construal mechanisms.",
        "split": "train"
    },
    {
        "uid": "117-Bed014",
        "id": "Bed014",
        "text": "Speaker graduate student B: priming a spreading activation",
        "summary": "One suggestion was to use the spreading activation as a paradigm for activating nodes in the belief-net.",
        "split": "train"
    },
    {
        "uid": "118-Bed014",
        "id": "Bed014",
        "text": "Speaker graduate student B: Which  , so far , in terms of like putting up all the constraints as , you know , pushing them into type constraints , the  when I 've , you know , propo then proposed it to linguists who haven't yet given me  you know , we haven't yet thought of a reason that that wouldn't work . Right ? As long as we allow our type constraints to be reasonably  complex .",
        "summary": "Finally, using type constraints in the construction analysis should work, as long as they are complex enough not to generate too many parses.",
        "split": "train"
    },
    {
        "uid": "119-Bed015",
        "id": "Bed015",
        "text": "Speaker graduate student F: And so one on one side is  on one side is a sort of the revised sort of updated semantic specification . And the other side is , , sort of a revised construction formalism .",
        "summary": "The discussion concerned the revised semantic specification and the construction formalism.",
        "split": "train"
    },
    {
        "uid": "120-Bed015",
        "id": "Bed015",
        "text": "Speaker graduate student F: So they could all have a type at the beginning . OK , and then again semantic constraints here are just  are just bindings .",
        "summary": "The different levels of the latter focus on what construction types are encountered and what bindings there are between them.",
        "split": "train"
    },
    {
        "uid": "121-Bed015",
        "id": "Bed015",
        "text": "Speaker graduate student F: But , you know , we have the  properties of dependency grammars and some properties of constituents  constituent - based grammar .",
        "summary": "The notation maintains properties of both dependency and constituent-based grammars.",
        "split": "train"
    },
    {
        "uid": "122-Bed015",
        "id": "Bed015",
        "text": "Speaker graduate student F: I think that 's still in progress . Other things we didn't  totally deal with , ,. well , we 've had a lot of other stuff that Keith and I have them working on in terms of like how you deal with like an adjective . You know , a  a nominal expression .",
        "summary": "The encoding of features is still incomplete: frame profiles, focus, adjectives, nominal expressions are phenomena in the process of being integrated.",
        "split": "train"
    },
    {
        "uid": "123-Bed015",
        "id": "Bed015",
        "text": "Speaker graduate student F: So there 's going to be some extra  you know , definitely other notation we 'll need for that which we skip for now .",
        "summary": "Similarly, ways to handle mental spaces will have to be added on top.",
        "split": "train"
    },
    {
        "uid": "124-Bed015",
        "id": "Bed015",
        "text": "Speaker graduate student F: So you see it 's \" scenario \" , \" referent \" and \" discourse segment \" .\nSpeaker graduate student E: The \" scenario \" box ,",
        "summary": "On the other hand, the semantic specification structures information in terms of \"scenario\", \"referent\" and \"discourse segment\".",
        "split": "train"
    },
    {
        "uid": "125-Bed015",
        "id": "Bed015",
        "text": "Speaker graduate student F: And actually it 's just a list of various slots from which you would draw  draw in order to paint your picture , a bunch of frames , bi and bindings , right ?",
        "summary": "Each category comprises a number of slots filled in by information derived from the utterance.",
        "split": "train"
    },
    {
        "uid": "126-Bed015",
        "id": "Bed015",
        "text": "Speaker professor C: which is made up entirely of these things and , , bindings among them . And bindings to ontology items . So that  that the who that this is the tool kit under whi out of which you can make a semantic specification . So this is an that anything you have , in the party line ,  anything you have as the semantic side of constructions comes , from pieces of this  ignoring li. But it 's got to be pieces of this along with constraints among them .",
        "summary": "It is, essentially, a toolkit with which to create semantic constructions, as well as the bindings between them and with the ontology.",
        "split": "train"
    },
    {
        "uid": "127-Bed015",
        "id": "Bed015",
        "text": "Speaker graduate student A: Yeah , but you  Don't we ultimately want to handle that analogously to the way we handle time and place ,\nSpeaker professor C: , we might be able to handle context in the same way that we handle mental spaces. So that pulling something out of a discourse context is I think similar to other kinds of , , mental space phenomena .",
        "summary": "Among the issues still being defined, mental spaces and context (eg pronoun references) present similarities that can be echoed in the specification.",
        "split": "train"
    },
    {
        "uid": "128-Bed015",
        "id": "Bed015",
        "text": "Speaker professor C: , and we 're going to have to s sort of bound the complexity . but just try to describe which ones you think we ought to have . Just  just sort of , you know , define your space .",
        "summary": "Work on both of these formalisms will continue with circumscription of the construction space that will be studied in more detail.",
        "split": "train"
    },
    {
        "uid": "129-Bed015",
        "id": "Bed015",
        "text": "Speaker graduate student A: , imagine you  you write a Bayes - net ,. , completely from scratch every time you do construal . And that fills in your CPT 's with which you can then query , , the  the net that you just wrote. and find out how thing X is construed as an utterance U . You may have some general rules as to how things can be  can be construed as what , so that will allow you to craft the  the  the initial notes .",
        "summary": "Work on construal will use Bayes-nets, which will be fed information from other modules and implement general rules to infer how utterances are construed.",
        "split": "train"
    },
    {
        "uid": "130-Bed016",
        "id": "Bed016",
        "text": "Speaker graduate student C: Then I 'm also going to present a little talk at EML , about what we have done here\nSpeaker professor E: let 's talk about your thesis proposal .",
        "summary": "The meeting was taken up by discussion about a thesis proposal and a talk about to take place at EML.",
        "split": "valid"
    },
    {
        "uid": "131-Bed016",
        "id": "Bed016",
        "text": "Speaker graduate student C: Then I 'm also going to present a little talk at EML , about what we have done here. Then I 'm going to talk about the data ,",
        "summary": "The latter will present the work that is currently being done at ICSI including examples of inference of user intentions and of the recordings of the on-going data collection.",
        "split": "valid"
    },
    {
        "uid": "132-Bed016",
        "id": "Bed016",
        "text": "Speaker graduate student C: e tell a little bit  as much as I  can about the NTL story . and then maybe talk about the big picture here ,. So X - schemas , then , I would like to do . and then at the end about our Bayes - net .",
        "summary": "The talk will also outline the theoretical (X-schemas, image schemas, Bayes-nets) and neural background.",
        "split": "valid"
    },
    {
        "uid": "133-Bed016",
        "id": "Bed016",
        "text": "Speaker graduate student C: It basically says , well \" this is construal \" ,. and then it continues to say that one could potentially build a probabilistic relational model that has some general , domain - general rules. and then the idea is to use ontology , situation , user , and discourse model to instantiate elements in the classes of the probabilistic relational model  to do some inferences in terms of what is being construed as what",
        "summary": "The thesis proposal, on the other hand, presents the idea of \"construal\" and makes claims as to how inferences are drawn in a probabilistic relational model by using information from the ontology, situation, user and discourse models.",
        "split": "valid"
    },
    {
        "uid": "134-Bed016",
        "id": "Bed016",
        "text": "Speaker professor E: And to make them apply to metaphorical cases and metonymic cases and all those things , requires this additional mechanism , of construal . but cover only base cases . but there are basic cases .\nSpeaker graduate student C: w Well we have , for example , a canonical use of something. and y it 's , you know , we have some constructions. and then it 's construed as something ,. and then we  we may get the same constructions with a metaphorical use that 's also relevant to the  to the domain .",
        "summary": "Base constructions deal with the norm, while further general domain mechanisms determine how the constructions are invoked depending on the context.",
        "split": "valid"
    },
    {
        "uid": "135-Bed016",
        "id": "Bed016",
        "text": "Speaker graduate student C: But \" walked into the cafe and ordered a drink , \" and \" walked into the cafe and broke his nose , \"\nSpeaker professor E: But \" run into \" does . So \" in the bus \" and \" on the bus , \"\nSpeaker graduate student C: We had  we had  initially we 'd  started discussing the \" out of film . \". Where is the castle ?. I mean maybe the \" where is something \" question as a whole , you know , can be construed as , u i locational versus instructional request .",
        "summary": "Several potential examples of polysemy were discussed in detail: \"walk/run into\", \"on the bus\", \"out of film\", \"where is X?\".",
        "split": "valid"
    },
    {
        "uid": "136-Bed016",
        "id": "Bed016",
        "text": "Speaker graduate student C: But I think the argument should be  , can be made that , you know , despite the fact that this is not the most met metaphorical domain ,",
        "summary": "However, none of them was an example of lexical polysemy resolved by construal straightforward enough to include in the proposal; the tourist domain is not metaphor rich.",
        "split": "valid"
    },
    {
        "uid": "137-Bed017",
        "id": "Bed017",
        "text": "Speaker graduate student B: , and we found another , cogsci student who 's interested in playing wizard for us . Here we 're gonna make it a little bit more complicated for the subjects , this round .",
        "summary": "There is a new wizard for phase two, during which subjects will be given more complex scenarios.",
        "split": "train"
    },
    {
        "uid": "138-Bed017",
        "id": "Bed017",
        "text": "Speaker graduate student B: As for SmartKom , I 'm  the last SmartKom meeting I mentioned that we have some problems with the synthesis ,. which as of this morning should be resolved . so maybe , when tomorrow is over , we 're done .",
        "summary": "Also finished are the modifications on SmartKom: the remaining glitches will take no more than a day to iron out.",
        "split": "train"
    },
    {
        "uid": "139-Bed017",
        "id": "Bed017",
        "text": "Speaker graduate student B: something happened , in  on Eva 's side with the PRM that we 're gonna look at today ,",
        "summary": "A big part of the meeting was covered by the presentation of the PRM of the proposed system.",
        "split": "train"
    },
    {
        "uid": "140-Bed017",
        "id": "Bed017",
        "text": "Speaker graduate student D: I sorta constructed a couple of classes . The red lines on the , , graph are the , relations between the different , classes . this is more or less similar to the flat Bayes - net that I have , you know , with the input nodes and all that .",
        "summary": "An alternative representation of the Bayes-net, it depicts context features as classes, and dependencies as relations between them.",
        "split": "train"
    },
    {
        "uid": "141-Bed017",
        "id": "Bed017",
        "text": "Speaker graduate student D: OK . So it only makes two decisions , in this model . And one is basically how desirable a site is. And the other is the mode of the visit ,. whether th It 's the EVA decision .",
        "summary": "The current outputs show the desirability of a site, as well as its EVA mode.",
        "split": "train"
    },
    {
        "uid": "142-Bed017",
        "id": "Bed017",
        "text": "Speaker professor F: I mean , the notion of instantiating your el elements from the ontology and stuff fits this very nicely and doesn't fit very well into the extended belief - net .",
        "summary": "The fact that this model allows for instantiations of classes fits the research purposes much better than the extended belief-net.",
        "split": "train"
    },
    {
        "uid": "143-Bed017",
        "id": "Bed017",
        "text": "Speaker graduate student B: we have a visitor from Bruchsal from the International University . Good . Then , we can move on and see what Andreas has got out his sleeve .",
        "summary": "Following this, a visiting researcher presented an overview of a parallel project at the International University.",
        "split": "train"
    },
    {
        "uid": "144-Bed017",
        "id": "Bed017",
        "text": "Speaker graduate student C: and so , what I want to build is basically a  a smart F A Q system . So , I want to be able to model information like , , so in the  in the context of  in the context of developing distributed systems , of a at a computer science school ,. , I want to build a smart librarian , basically",
        "summary": "It attempts to build a smart tutoring system for a computer science course.",
        "split": "train"
    },
    {
        "uid": "145-Bed017",
        "id": "Bed017",
        "text": "Speaker graduate student C: Now , what you need to do here is you need to provide some context information. Now , what I plan to do is I want to sort of do a   try to improve the quality of the search results ,",
        "summary": "The assumption is that document searches can give more personalised results, if they take into account contextual parameters (user, situation).",
        "split": "train"
    },
    {
        "uid": "146-Bed017",
        "id": "Bed017",
        "text": "Speaker graduate student A: and I 'm guessing that you  you won't be doing that ?\nSpeaker graduate student C: No .\nSpeaker professor F: On the other hand , , FrameNet could well be useful .",
        "summary": "Although no detailed linguistic analysis takes place, it was suggested that the use of FrameNet could be a useful approach.",
        "split": "train"
    },
    {
        "uid": "147-Bed017",
        "id": "Bed017",
        "text": "Speaker graduate student A: The other person I thought of is Dan Gildea ?",
        "summary": "There were also further suggestions for meetings with ICSI researchers.",
        "split": "train"
    },
    {
        "uid": "148-Bmr003",
        "id": "Bmr003",
        "text": "Speaker graduate student A: topic of this meeting is I wanna talk a little bit about transcription . So , well w shall we move on and talk a little bit about transcription then ?. is  and so one of the things was to get an estimate of how long it would take ,. and then also what tools we would use . And so the next decision which has to be made actually pretty soon is how are we gonna do it ?. I mean , I looked at Cyber Transcriber",
        "summary": "The Berkeley Meeting Recorder group discussed the aims, methods, timing, and outsourcing issues concerning transcription of the Meeting Recorder corpus.",
        "split": "train"
    },
    {
        "uid": "149-Bmr003",
        "id": "Bmr003",
        "text": "Speaker graduate student A: What we 're using right now is a tool , , from this French group , called \" Transcriber \"\nSpeaker Postdoc E: So as far as I 'm concerned those transcription conventions are fixed right now . and  But so in terms of the con the conventions , then ,  , basically ,  , it 's strictly orthographic. So I have  I have a convention of putting like a dash  arrow just to indicate that this person 's utterance continues .",
        "summary": "The Transcriber software tool was introduced, along with a set of transcription conventions for coding different speech events.",
        "split": "train"
    },
    {
        "uid": "150-Bmr003",
        "id": "Bmr003",
        "text": "Speaker graduate student A: these are linguistics grad students .\nSpeaker PhD C: But we can pay a graduate student seven dollars an hour .",
        "summary": "The prospect of sending the data to an external transcription service was weighed against that of hiring a graduate student transcriber pool.",
        "split": "train"
    },
    {
        "uid": "151-Bmr003",
        "id": "Bmr003",
        "text": "Speaker PhD C: so that means that even if it takes them thirty times real time it 's cheaper to  to do graduate students .\nSpeaker graduate student A: I mean , that 's why I said originally , that I couldn't imagine sending it out 's gonna be cheaper .",
        "summary": "It was tentatively decided that the latter option would be less costly and allow BMR to maintain greater control over the transcription process.",
        "split": "train"
    },
    {
        "uid": "152-Bmr003",
        "id": "Bmr003",
        "text": "Speaker PhD C: Maybe we should s consider also , , starting to build up a web site around all of these things .",
        "summary": "Methods for distributing the data were briefly discussed, along with an initiative for creating a BMR project website.",
        "split": "train"
    },
    {
        "uid": "153-Bmr003",
        "id": "Bmr003",
        "text": "Speaker graduate student A: and then get an update on the electronics ,. , let 's move on to electronics .",
        "summary": "The group received an update on the meeting room recording setup and electronics.",
        "split": "train"
    },
    {
        "uid": "154-Bmr005",
        "id": "Bmr005",
        "text": "Speaker professor E: , so the one th one thing I know that we have on that is we had talked a  a couple weeks before about the  the stuff you were doing with  with l l attempting to locate events ,. but anyway some  some potential collaboration there about  about the  about the  working with these data .\nSpeaker Postdoc B: , so , , he was interested in the question of  you know , relating to his  to the research he presented recently , of inference structures ,\nSpeaker professor E: so we were trying to think of ways that his interests could interact with ours\nSpeaker Postdoc B: He 's interested in these  these knowledge structures ,. inferences that you draw  i from \nSpeaker PhD D: to  to find a  a good solution to detect eh , the overlapping zone in eh speech recorded .\nSpeaker professor E: but you have  you have time , marked  twelve minute  the  the  the overlaps in twelve minutes of it .\nSpeaker PhD C: like very straightforward question is where we are on the amount of data and the amount of transcribed data ,",
        "summary": "Topics discussed by the Berkeley Meeting Recorder group included a potential collaboration with another ICSI member regarding the analysis of inference structures, efforts by speaker mn005 to detect speaker overlap, the current status on recordings and transcriptions, and future efforts to collect meeting data.",
        "split": "test"
    },
    {
        "uid": "155-Bmr005",
        "id": "Bmr005",
        "text": "Speaker professor E: but there 's at least one meeting recorded of the natural language guys . , we 've started having a morning meeting , today i starting a w a week or two ago , on the front - end issues ,. and we 're recording those ,. there 's a network services and applications group here who 's agreed to have their meetings recorded ,\nSpeaker PhD C: if anyone knows of one more m or two more wee meetings per week that happen at ICSI , that we could record , I think it would be worth it .",
        "summary": "In addition to weekly meetings by the BMR group, efforts are in progress to record meetings by other ICSI research groups, as well as routine discussions by non-ICSI members.",
        "split": "test"
    },
    {
        "uid": "156-Bmr006",
        "id": "Bmr006",
        "text": "Speaker PhD F: , but I 'd rather try to get more regular meetings of types that we know about , and hear , then sort of a mish - mosh of a bunch of one  one - time ",
        "summary": "The Berkeley Meeting Recorder group discussed research aims and corresponding concerns for future data collection.",
        "split": "train"
    },
    {
        "uid": "157-Bmr006",
        "id": "Bmr006",
        "text": "Speaker PhD F: And in that , regard , I thought we definitely w will need  it 'd b it 'd be nice for us to have a bunch of data from a few different domains , or a few different kinds of meetings . , but I 'd rather try to get more regular meetings of types that we know about , and hear , then sort of a mish - mosh of a bunch of one  one - time . but also data where we hold some parameters constant or fairly similar ,\nSpeaker professor D: , for other kinds of research , particularly the acoustic oriented research , I actually feel the opposite need . I 'd like to have many different speakers . So , I think I would also very much like us to have a fair amount of really random scattered meetings , of somebody coming down from campus , and  and ,\nSpeaker PhD F: I 'd love to get people that are not linguists or engineers , cuz these are both weird ",
        "summary": "It was agreed that a substantial amount of meeting data is required from different domains, and comprising several speakers, to perform the types of discourse and acoustic analyses desired.",
        "split": "train"
    },
    {
        "uid": "158-Bmr006",
        "id": "Bmr006",
        "text": "Speaker PhD C: I have , eh ,  The result of my work during the last days . It 's a real problem ,  a frequently problem  , because you have overlapping zones eh , eh , eh , all the time . but , eh , my idea is , eh , is very interesting to  to work  in  in the line of , eh , automatic segmenter . No , I  I  plan to do that . Now ,  eh , I need ehm ,  to detect eh all the overlapping zones exactly .\nSpeaker professor D: So the first thing is for you to  to build up something that will detect the overlaps .",
        "summary": "Ongoing efforts by speaker mn005 to automatically  detect regions of speaker overlap were considered.",
        "split": "train"
    },
    {
        "uid": "159-Bmr006",
        "id": "Bmr006",
        "text": "Speaker professor D: I would take just a few features . Instead of taking all the MFCC 's , or all the PLP 's or whatever , I would just take a couple . , and on the other hand , the LPC residual , the energy in the LPC residual ,  will say how well ,  the low - order LPC  model 's fitting it , which should be  pretty poorly for two two or more  people speaking at the same time , and it should be pretty well , for w for  for one . Well , that  that  that 's another reason why very simple features , things like energy , and things  things like harmonicity , and  residual energy are , yeah are  are better to use than very complex ones because they 'll be more reliable .",
        "summary": "It was suggested that speaker mn005 focus on a small set of acoustic parameters, e.g. energy and harmonics-related features, to distinguish regions of overlap from those containing the speech of just one speaker.",
        "split": "train"
    },
    {
        "uid": "160-Bmr006",
        "id": "Bmr006",
        "text": "Speaker professor D: and  then , I guess another topic would be  where are we in the whole disk resources  question",
        "summary": "Disk space issues were discussed.",
        "split": "train"
    },
    {
        "uid": "161-Bmr006",
        "id": "Bmr006",
        "text": "Speaker graduate student B: and then also anonymity , how we want to anonymize the data .\nSpeaker Postdoc E: the question becomes what symbol are you gonna put in there for everybody 's name ,. and whether you 're gonna put it in the text where he says \" Hey Roger \" or are we gonna put that person 's anonymized name in instead ?\nSpeaker graduate student B: Because if we made the  the transcript be the tag that we 're using for Roger , someone who had the transcript and the audio would then have a mapping between the anonymized name and the real name , and we wanna avoid that .\nSpeaker Postdoc E: , how important is it for a person to be identified by first name versus full name ?. However , taking one step further back , they 'd be identifiable anyway , even if we changed all the names . On the other hand , this is a small  this is a small pool , and people who say things about topic X e who are researchers and well - known in the field , they 'll be identifiable and simply from the  from the first name . Now , it would be very possible for me to take those data put them in a  in a study , and just change everybody 's name for the purpose of the publication . And within that , it may be that it 's sufficient to not change the  to not incorporate anonymization yet , but always , always in the publications we have to .",
        "summary": "And, finally, the problem of speaker anonymization was explored.",
        "split": "train"
    },
    {
        "uid": "162-Bmr007",
        "id": "Bmr007",
        "text": "Speaker professor D: And what we 're doing now is ,  aside from the many other differences in the task , we are considering overlap",
        "summary": "The Berkeley Meeting Recorder group focussed its discussion on overlapping speech segments.",
        "split": "train"
    },
    {
        "uid": "163-Bmr007",
        "id": "Bmr007",
        "text": "Speaker Postdoc F: Raw counts . so . Of the times a person spoke and furthermore was involved in a two two - person overlap ,   what percentage of the time were they the overlapper and what percent of the time were they th the overlappee ?. but , of course , i e  this is just one meeting ,   there 's no statistical testing involved , and that would be  required for a  for a finding  of  any  kind of  scientific  reliability .\nSpeaker professor D: Well , of course th the biggest ,   result here , which is one we 've   we 've talked about many times and isn't new to us , but which I think would be interesting to show someone who isn't familiar with this   is just the sheer number of overlaps . it 's a forty   forty plus minute   meeting ,. what we 've learned about is overlaps in this situation , is that  the first   the first - order thing I would say is that there 's a lot of them . In fact   and it 's not just an overlap  bunch of overlaps  second - order thing is  it 's not just a bunch of overlaps in one particular point ,  but that there 's overlaps , throughout the thing .   preliminary analysis of overlaps in the pilot data we have transcribed ,",
        "summary": "Speaker fe008 presented raw counts and percentages for one transcribed meeting, revealing a large number of overlaps throughout the 40-plus-minute transcript.",
        "split": "train"
    },
    {
        "uid": "164-Bmr007",
        "id": "Bmr007",
        "text": "Speaker Postdoc F: ,  that some people tend to be overlapped  with more often than they 're overlapped ,. And  it would be , you know  of course ,  there 's also the question of what type of overlap was this , and w what were they ,. So , Then it beco  though  so  just  just superficially to give   a couple ideas of the types of overlaps involved , I have at the bottom several that I noticed . So , , the point is that ,   overlap 's not necessarily a bad thing and that it would be im  i useful to subdivide these further and see if there are individual differences in styles with respect to the types involved .\nSpeaker PhD B: So , the question is , you know , how many more overlaps   do you have  of , say the two - person type , by adding more people . to a meeting ,. So it may be that having three people   is very different from having two people or it may not be . But we should still be able to somehow say what  what is the added contra contribution to sort of overlap time of each additional person , or something like that .\nSpeaker Postdoc F: These were  these were  benevolent types , as people  finishing each other 's sentences , and  stuff .\nSpeaker PhD B: and that it would be interesting to look at  whether there are these kinds of constraints that Jane mentioned , that  what maybe the additional people add to this competition that happens right after a turn ,",
        "summary": "Efforts by speakers fe008 and fe016 are in progress to categorize and subcategorize types of overlapping speech and evaluate the contribution of multiple speakers in an interaction to the amount and types of overlap observed.",
        "split": "train"
    },
    {
        "uid": "165-Bmr007",
        "id": "Bmr007",
        "text": "Speaker graduate student H: Yeah , I 've been playing with , , using the close - talking mike to do  to try to figure out who 's speaking . So my first attempt was just using thresholding and filtering , that we talked about  about two weeks ago ,. OK and then the other thing I did , was I took  Javier 's speaker - change detector  acoustic - change detector , and I implemented that with the close - talking mikes ,.  So , at any rate , my next attempt ,  which I 'm in the midst of and haven't quite finished yet was actually using the  , thresholding as the way of generating the candidates . But all of this is close - talking mike ,. What I 'm doing  is trying to use the close - talking mike  and just use   Can - and just generate candidate and just  try to get a first pass at something that sort of works .",
        "summary": "Speaker me011 described his attempts to automatically identify speakers via the close-talking microphone channels using thresholding and filtering methods and an existing speaker-change detection algorithm.",
        "split": "train"
    },
    {
        "uid": "166-Bmr007",
        "id": "Bmr007",
        "text": "Speaker PhD G: Or , this is getting a little extravagant , we could put up some kind of blinds or something to   to remove ,  visual contact .\nSpeaker professor D: So this is the things that I think we did  in the last three months",
        "summary": "The group also tentatively discussed the erection of visual barriers during meeting recordings, and speaker me013 presented a list of work performed by BMR over the previous three months to be included in a forthcoming report to IBM.",
        "split": "train"
    },
    {
        "uid": "167-Bmr009",
        "id": "Bmr009",
        "text": "Speaker professor C: but Jose and I were just talking about  the  , speech e energy thing ,. He was  he  he was taking everything over two hundred milliseconds. And so i i his  his  He 's making the constraint it has to be at least two hundred milliseconds .",
        "summary": "The Berkely Meeting Recorder group discussed efforts by speaker mn005 to measure energy levels in cases of speaker overlap in which the time window analyzed was 200 milliseconds or greater.",
        "split": "train"
    },
    {
        "uid": "168-Bmr009",
        "id": "Bmr009",
        "text": "Speaker professor C: Right now , that he 's not really showing any kind of distinction , but . . And one is that this is all in log energy. and  But one thing he was pointing out is when he  he looked at a bunch of examples in log domain , it is actually pretty hard to see  the change . And when he 's looking in the log domain he 's not really seeing it .",
        "summary": "Preliminary results were presented showing that log domain analyses did not reveal a significant difference in mean energy levels for windows of overlapping versus non-overlapping speech.",
        "split": "train"
    },
    {
        "uid": "169-Bmr009",
        "id": "Bmr009",
        "text": "Speaker professor C: And when he 's looking in straight energy he is ,.  But  since   your intuition from looking at some of the data , is that when you looked at the regular energy , that it did in fact usually go up ,  when two people were talking ,  that 's  eh you know , you should be able to come up with a measure which will  match your intuition .",
        "summary": "In contrast, raw energy analyses were successful in showing the two groups to be distinct.",
        "split": "train"
    },
    {
        "uid": "170-Bmr009",
        "id": "Bmr009",
        "text": "Speaker Postdoc B: and I had plan to go through with it , of  of co coding the types of overlaps that people were involved in s just with reference to speaker style so , you know , with reference . so I was planning to do a taxonomy of types overlaps with reference to that .",
        "summary": "Participants discussed alternate strategies for examining energy and the importance of categorizing types of speaker overlap.",
        "split": "train"
    },
    {
        "uid": "171-Bmr009",
        "id": "Bmr009",
        "text": "Speaker graduate student A: Yeah this was the problem with these categories ,",
        "summary": "Participants also reviewed the latest iteration of speaker forms, and discussed recent changes to the Transcriber tool.",
        "split": "train"
    },
    {
        "uid": "172-Bmr010",
        "id": "Bmr010",
        "text": "Speaker Postdoc F: Well , , I can  give you an update on the  transcription effort . because at present ,   , because  of the limitations of  th the interface we 're using ,. overlaps are , , not being  encoded by  the transcribers in as complete  and , , detailed a way as it might be ,\nSpeaker graduate student A: What our decision was is that  we 'll go ahead with what we have with a not very fine time scale on the overlaps .",
        "summary": "The Berkeley Meeting Recorder group talked about the ongoing transcription effort and issues related to the Transcriber tool, which despite its limitations for capturing tight time markings for overlapping speech, will continue to remain in use.",
        "split": "train"
    },
    {
        "uid": "173-Bmr010",
        "id": "Bmr010",
        "text": "Speaker Postdoc F: The  we have great  great , , p steps forward in terms of the nonspeech - speech pre - segmenting of the signal .\nSpeaker PhD C: , so , , what we basically did so far was using the mixed file to  to detect s speech or nonspeech  portions in that .\nSpeaker Postdoc F: But  it  it saves so much time  the  the  transcribers",
        "summary": "Speaker mn014 explained his efforts to pre-segment the signal into speech and non-speech portions for facilitating transcriptions.",
        "split": "train"
    },
    {
        "uid": "174-Bmr010",
        "id": "Bmr010",
        "text": "Speaker Postdoc F: , maybe  raise the issue of microphone , , procedures\nSpeaker professor G: Well , let 's  why don't we talk about microphone issues ?. But I  I think that it  it doesn't hurt , , the naturalness of the situation to try to have people  wear the microphones properly , if possible ,\nSpeaker PhD B: So , anything to reduce breathing is  is  is a good thing .\nSpeaker graduate student A: So you want it enough to the side so that when you exhale through your nose , it doesn't  the wind doesn't hit the mike .",
        "summary": "Recording equipment and procedures were discussed, with a focus on audible breathing and the need for standards in microphone wear and use.",
        "split": "train"
    },
    {
        "uid": "175-Bmr010",
        "id": "Bmr010",
        "text": "Speaker professor G: But , I mean , the other things that we talked about is , ,  pitch - related things and harmonicity - related things ,. You know , have a  have a couple Markov models. which is to say , don't worry so much about the , , features . and , , try to indi try to determine , you know , w when is th when are you in an overlap , when are you not in an overlap . And let the , , , statistical system  determine what 's the right way to look at the data .\nSpeaker PhD D: And I hope the  the next week I will have , eh , some results and we  we will show  we will see , eh , the  the parameter  the pitch ,  eh , tracking in  with the program .\nSpeaker professor G: , the  has  has , , been exploring , , e largely the energy issue. So far , , , Jose has  has been . but it may be  given that you have a limited time here , it  it just may not be the best thing to   to  to focus on for the remaining of it . Th - they were suggesting going to Markov models ,",
        "summary": "And, finally, it was determined that speaker mn005's efforts to detect speaker overlap using energy should instead be focussed on pitch- and harmonicity-related features or be guided by a non-featural, statistical approach, i.e. via the use of Markov models.",
        "split": "train"
    },
    {
        "uid": "176-Bmr011",
        "id": "Bmr011",
        "text": "Speaker professor B: And the other one is , , , is there some good use that we can make of the transcribers to do other things ?. One  one was , we had s had some discussion in the past about some very high level labelings ,\nSpeaker PhD A: , the other thing is that  there was a number of things at the transcription side that , , transcribers can do , like dialogue act tagging ,",
        "summary": "The Berkeley Meeting Recorder group discussed recording equipment and setup issues, recent developments in the transcription effort, other potential types of tagging to be assigned to transcribers, and the post-processing of waveforms.",
        "split": "train"
    },
    {
        "uid": "177-Bmr011",
        "id": "Bmr011",
        "text": "Speaker PhD A: And actually in addition to that , that the  the close talking mikes are worn in such a way as to best capture the signal .\nSpeaker graduate student H: So it 's towards the corner of your mouth so that breath sounds don't get on it .\nSpeaker PhD A: But if we could actually standardize , you know , the  the microphones , , as much as possible that would be really helpful .\nSpeaker professor B: but have them all be the same mike .\nSpeaker Postdoc G: It 's the equipment and also how it 's worn . it 's really   it makes a big difference from the transcribers ' point of view\nSpeaker graduate student H: So we might as well get it as uniform as we can .\nSpeaker Postdoc G: And , , also Dan Ellis 's innovation of the ,  the multi - channel to here really helped a r a lot in terms of clearing  clearing up h hearings that involve overlaps .",
        "summary": "The discussion was largely focused on efforts to facilitate transcriptions, including the improvement of strategies for transcribing overlapping speech, and achieving greater uniformity in the type of equipment used during recordings and the manner in which recording devices are worn by speakers.",
        "split": "train"
    },
    {
        "uid": "178-Bmr012",
        "id": "Bmr012",
        "text": "Speaker graduate student E: And I 'm sure Liz and Andreas wanna talk about recognition results .\nSpeaker PhD C: Anyway so it 's twenty minutes and I actually. So this is only twenty minutes of one meeting with no  no tailoring at all .",
        "summary": "The Berkeley Meeting Recorder group discussed recognition results generated for 20 minutes of close-talking microphone data.",
        "split": "train"
    },
    {
        "uid": "179-Bmr012",
        "id": "Bmr012",
        "text": "Speaker PhD C: and this is  this is good news. because that means the force alignments should be good. but if the force alignments are good we can get all kinds of information . For example about , you know prosodic information. and speaker overlaps and so forth directly from the aligned times .",
        "summary": "Recognition performance was very good, indicating promising results for forced alignment procedures and the ability to analyze other important signal information, e.g. prosody and overlapping speech.",
        "split": "train"
    },
    {
        "uid": "180-Bmr012",
        "id": "Bmr012",
        "text": "Speaker graduate student E: And I have to try it on the far field mike\nSpeaker professor B: yeah certainly I 'd like to see as soon as we could ,. but soon as we could how well it does with say with the P Z Ms or maybe even one of the",
        "summary": "It was decided that close-talking data should be downsampled and fed to the SRI recognizer to compare recognition performance, and that data from the far-field microphones should be tested on the recognizer as soon as possible.",
        "split": "train"
    },
    {
        "uid": "181-Bmr012",
        "id": "Bmr012",
        "text": "Speaker graduate student E: well I have  I wanna talk about new microphones and wireless stuff .",
        "summary": "The group also discussed recording setup and equipment issues.",
        "split": "train"
    },
    {
        "uid": "182-Bmr012",
        "id": "Bmr012",
        "text": "Speaker PhD C: Is   is there any way we can have you know like a  a wireless microphone that you pass around to the people who you know the extra people for the times they wanna talk that ",
        "summary": "A tentative decision was also made to integrate the use of a hand-held wireless microphone to help compensate for the lack of available close-talking microphones.",
        "split": "train"
    },
    {
        "uid": "183-Bmr012",
        "id": "Bmr012",
        "text": "Speaker PhD C: and it 's a meeting on even deeper understanding , EDU ,\nSpeaker Postdoc G: And then also an idea for another meeting , which would be to have the transcribers talk about the data",
        "summary": "The collection of Meeting Recorder data is ongoing, and will include meetings by the Berkeley Even Deeper Understanding research group and, possibly, an organized discussion by members of the transcriber pool.",
        "split": "train"
    },
    {
        "uid": "184-Bmr013",
        "id": "Bmr013",
        "text": "Speaker graduate student F: OK well , the , w as you can see from the numbers on the digits we 're almost done . And so , once we 're  it 's done it would be very nice to train up a recognizer and actually start working with this data .",
        "summary": "The Berkeley Meeting Recorder group discussed the collection status for a set of connected digits recordings that are nearly complete and ready to be trained on a recognizer.",
        "split": "train"
    },
    {
        "uid": "185-Bmr013",
        "id": "Bmr013",
        "text": "Speaker professor C: Yeah just by way of , , a , order of magnitude , , , we 've been working with this Aurora , data set . And , , the best score , on the , nicest part of the data , that is , where you 've got training and test set that are basically the same kinds of noise and so forth , , is about ,. I think the best score was something like five percent , , error , per digit .",
        "summary": "Anticipated results were discussed in reference to results obtained for other digits corpora, i.e. Aurora and TI-digits.",
        "split": "train"
    },
    {
        "uid": "186-Bmr013",
        "id": "Bmr013",
        "text": "Speaker professor C: One question I have that  that I mean , we wouldn't know the answer to now but might , do some guessing , but I was talking before about doing some model modeling of arti , , marking of articulatory , features , with overlap and so on . One thought might be to do this , on  on the digits , or some piece of the digits . So , I mean another way to look at this is to , is to , , do some stuff on Switchboard which has all this other , stuff to it . And then , , As we get , further down the road and we can do more things ahead of time , we can , do some of the same things to the meeting data .",
        "summary": "The group also considered the prospect of performing fine-grained acoustic-phonetic analyses on a subset of Meeting Recorder digits or Switchboard data.",
        "split": "train"
    },
    {
        "uid": "187-Bmr013",
        "id": "Bmr013",
        "text": "Speaker PhD A: , oh yeah , ,  I worked a little bit on the  on the presegmentation to  to get another version which does channel - specific , , speech - nonspeech detection .",
        "summary": "Pre-segmentation manipulations that allow for the segmentation of channel-specific speech/non-speech portions of the signal and the distinction of foreground versus background speech were discussed.",
        "split": "train"
    },
    {
        "uid": "188-Bmr013",
        "id": "Bmr013",
        "text": "Speaker Postdoc B: also we discussed some adaptational things ,.  You know I hadn't , , incorporated , a convention explicitly to handle acronyms , for example ,. And then , a similar conv , convention for numbers .\nSpeaker PhD G: So if they hear a breath and they don't know who breath it is it 's better to put it in that channel than to put it in the speaker 's channel",
        "summary": "Finally, speaker fe008 and fe016 reported on new efforts to adapt transcriptions to the needs of the SRI recognizer, including conventions for encoding acronyms, numbers, ambient noise, and unidentified inbreaths.",
        "split": "train"
    },
    {
        "uid": "189-Bmr014",
        "id": "Bmr014",
        "text": "Speaker professor E: The other topic I was thinking of was the sta status on microphones and channels , and all that .\nSpeaker graduate student C: , the new microphones , the two new ones are in . so what we would do is replace the wired mikes with wireless . And so we could replace our wired mikes with wireless if we bought another base station and more wireless mikes . No , we 're just replacing the wired  the two wired that are still working ,. along with a couple of the wired that aren't working , one of the wired that 's not working , with a wireless .",
        "summary": "The Berkeley Meeting Recorder group discussed recording equipment issues, including the purchase of two additional headsets and the prospect of getting a new base station and a set of wireless microphones to replace those wired microphones currently in use.",
        "split": "train"
    },
    {
        "uid": "190-Bmr014",
        "id": "Bmr014",
        "text": "Speaker Postdoc F: but I  think it would come to about eleven hours that are finished , transcribing from them right now . The next step is to  that I 'm working on is to insure that the data are clean first , and then channelized . and also that we now incorporate these additional conventions that , Liz requested in terms of ,  in terms of having a s a systematic handling of numbers , and acronyms which I hadn't been specific about . that the mark - up is consistent all the way throughout ,",
        "summary": "Speaker fe008 presented the current status on transcriptions, and explained procedures for cleaning up transcripts and ensuring they conform with set conventions.",
        "split": "train"
    },
    {
        "uid": "191-Bmr014",
        "id": "Bmr014",
        "text": "Speaker PhD A: Yeah , and I  and I tried t to normalize  the features , there 's loudness and modified loudness , , within one channel ,. because they 're ,  yeah to  to be able to distinguish between foreground and background speech .",
        "summary": "Speaker mn014 briefly described his efforts to normalize loudness levels across speech channels to distinguish between foreground and background speech.",
        "split": "train"
    },
    {
        "uid": "192-Bmr014",
        "id": "Bmr014",
        "text": "Speaker graduate student C: I wanna talk a little bit about getting  how we 're gonna to get people to edit bleeps , parts of the meeting that they don't want to include .\nSpeaker professor E: the transcription part ? So I guess the next thing is this  bleep editing .\nSpeaker graduate student C: We need to provide the transcripts to every participant of every meeting to give them an opportunity to bleep out sections they don't want . \" If you agree to participate you 'll have the opportunity to have anything ex anything excised , which you would prefer not to have included in the data set . \". There again you will be allowed to indicate any sections that you 'd prefer to have excised from the database ,. and they will m be removed both from the transcript and the recording . \"",
        "summary": "Finally, the group discussed legal and procedural issues concerning the provision of transcripts to meeting participants for 'bleeping out' any sections of speech they want excluded from the Meeting Recorder database.",
        "split": "train"
    },
    {
        "uid": "193-Bmr015",
        "id": "Bmr015",
        "text": "Speaker graduate student B: I have a short thing about digits. and then I wanna talk a little bit about naming conventions ,. So the only thing I wanna say about digits is , we are pretty much done with the first test set .\nSpeaker professor A: , the last one was  that you had there ,  was about naming ?\nSpeaker graduate student B: We want some way of specifying , more than looking in the \" key \" file , what channel and what mike . What channel , what mike , and what broadcaster .",
        "summary": "Topics discussed by the Berkeley Meeting Recorder group included the status of the first test set of digits data, naming conventions for files, speaker identification tags, and encoding files with details about the recording.",
        "split": "train"
    },
    {
        "uid": "194-Bmr015",
        "id": "Bmr015",
        "text": "Speaker professor A: , right , so  so I  I was just gonna talk briefly about the NSF ITR . OK , so e l I guess , let me , , get my  my short thing out about the NSF . so this was , , a , , proposal that we put in. so is i for  it was a  proposal for the ITR program ,. ,   since we have such a short agenda list I guess I wi I will ask how  how are the transcriptions going ?\nSpeaker PhD C: And  and I 'm tried to  to , , adjust the  to  to improve , eh , an harmonicity , eh , detector that , eh , I  I implement . eh , and now I 'm  I 'm  I 'm trying to  to find , eh , some kind of a ,   of h of help , eh , using the energy to  to distinguish between possible harmonics , and  and other fre frequency peaks , that , eh , corres not harmonics .\nSpeaker professor A: You 're trying distinguish between the case where there is ,  where  where there are more than  , where there 's more than one speaker. and the case where there 's only one speaker .",
        "summary": "The group also discussed a proposal for a grant from the NSF's ITR (Information Technology Research) program, transcriptions, and efforts by speaker mn005 to detect speaker overlap using harmonicity-related features.",
        "split": "train"
    },
    {
        "uid": "195-Bmr015",
        "id": "Bmr015",
        "text": "Speaker Postdoc F: that there 's one third thing I wanted to  to ex raise as a to as an issue. which is , , how to handle breaths .",
        "summary": "Particular focus was paid to questions about transcription procedures, i.e. how to deal with overlooked backchannels, and audible breaths.",
        "split": "train"
    },
    {
        "uid": "196-Bmr016",
        "id": "Bmr016",
        "text": "Speaker graduate student D: So the other topic with digits is ,. We have ASR results from Liz ,. transcript status from Jane ,. and disk space and storage formats from Don . Don , you had disk space and storage formats .",
        "summary": "The Berkeley Meeting Recorder group discussed digits data, recent ASR results, the status of transcriptions, and disk space and storage format issues.",
        "split": "train"
    },
    {
        "uid": "197-Bmr016",
        "id": "Bmr016",
        "text": "Speaker graduate student D: We have about two hours worth . So what that means is we have about an hour of transcribed digits that we can play with .\nSpeaker professor F: And you 're saying two hours , , is digits ,",
        "summary": "Approximately two hours of digits have been recorded, half of which have been extracted.",
        "split": "train"
    },
    {
        "uid": "198-Bmr016",
        "id": "Bmr016",
        "text": "Speaker PhD G: , leads us to believe that doing a better segmentation , like your channel - based segmentation , or some kind of , echo cancellation to get basically back down to the individual speaker utterances would be probably all that we would need to be able to do good recognition on the  on the close - talking mikes .",
        "summary": "Researchers doing ASR are looking into methods for generating a better channel-based segmentation to improve recognition results for close-talking microphone data.",
        "split": "train"
    },
    {
        "uid": "199-Bmr016",
        "id": "Bmr016",
        "text": "Speaker Postdoc E: Alright so , first of all , , there was a  an interest in the transcribe transcription , , checking procedures",
        "summary": "Transcription checking procedures were reviewed, and efforts to coordinate the channelization and presegmention of data with the tightening of time bins were discussed.",
        "split": "train"
    },
    {
        "uid": "200-Bmr018",
        "id": "Bmr018",
        "text": "Speaker PhD B: and then we go in and adjust the boundaries . how quickly can the transcribers scan over and fix the boundaries ,\nSpeaker professor C: and then it 's  then it 's  then it 's the transcribers tightening stuff up ,. So you 're talking about tightening up time boundaries ?\nSpeaker graduate student E: Well , so  so that 's something that the transcribers will have to  have to do .\nSpeaker PhD F: So , if I excluded the pathological ones ,  by definition , those that had like over ninety - five percent error rate ,  and the non - natives , then the average error rate was like one point four or something ,",
        "summary": "The Berkeley Meeting Recorder group discussed the preparation of a data sample for IBM, the manual adjustment of time bins by transcribers, recognition results for a test set of digits data, and forced alignments.",
        "split": "train"
    },
    {
        "uid": "201-Bmr018",
        "id": "Bmr018",
        "text": "Speaker PhD F: So , if I excluded the pathological ones ,  by definition , those that had like over ninety - five percent error rate ,  and the non - natives , then the average error rate was like one point four or something ,",
        "summary": "Preliminary recognition results were presented for a subset of digits data.",
        "split": "train"
    },
    {
        "uid": "202-Bmr018",
        "id": "Bmr018",
        "text": "Speaker PhD D: So we need some way to push these first chunk of meetings into a state where we get good alignments .",
        "summary": "Efforts to deal with cross-talk and improve forced alignments for non-digits data were also discussed.",
        "split": "train"
    },
    {
        "uid": "203-Bmr019",
        "id": "Bmr019",
        "text": "Speaker professor B: And the interesting thing is that even though ,  yes , it 's a digits task and that 's a relatively small number of words and there 's a bunch of digits that you train on ,  it 's just not as good as having a  a l very large amount of data and training up a  a  a nice good big  HMM .",
        "summary": "The Berkeley Meeting Recorder group discussed efforts to train and test the Aurora group's HTK-based recognition system on ICSI's digits corpus.",
        "split": "valid"
    },
    {
        "uid": "204-Bmr019",
        "id": "Bmr019",
        "text": "Speaker graduate student E: Two items , which was , , digits and possibly stuff on  on , , forced alignment ,\nSpeaker PhD A: So we  we only r hav I only looked at actually alignments from one meeting that we chose ,",
        "summary": "Members also discussed efforts to produce forced alignments from a selection of Meeting Recorder data.",
        "split": "valid"
    },
    {
        "uid": "205-Bmr019",
        "id": "Bmr019",
        "text": "Speaker professor B: , but the other is that , , the digits  recorded here in this room with these close mikes , i , are actually a lot harder than the  studio - recording TI - digits .\nSpeaker PhD F: If you have only one utterance per speaker you might actually screw up on estimating the  the warping , , factor .\nSpeaker graduate student G: Well , I know there were some speaker labelling problems , , after interruptions . But you 're actually saying that certain , , speakers were mis mis - identified .",
        "summary": "Performance in both tasks was adversely affected by the manner of recording conditions implemented and difficulties attributing utterances to the appropriate speakers.",
        "split": "valid"
    },
    {
        "uid": "206-Bmr019",
        "id": "Bmr019",
        "text": "Speaker PhD A: and  and  W we  we were able to get some definite improvement on the forced alignments by looking at them first and then realizing the kinds of errors  that were occurring. So just sort of working through a bunch of debugging kinds of issues .",
        "summary": "While debugging efforts resulted in improved forced alignments, dealing with mixed channel speech and speaker overlap remains a key objective for future work.",
        "split": "valid"
    },
    {
        "uid": "207-Bmr019",
        "id": "Bmr019",
        "text": "Speaker PhD F: So  so the key  thing that 's missing here is basically the ability to feed , you know , other features  i into the recognizer. and also then to train the system .\nSpeaker professor B: we want to  have the ability to feed it different features .",
        "summary": "The group is additionally focused on a continued ability to feed different features into the recognizer and then train the system accordingly.",
        "split": "valid"
    },
    {
        "uid": "208-Bmr020",
        "id": "Bmr020",
        "text": "Speaker graduate student A: so the only agenda items were Jane  was Jane wanted to talk about some of the IBM transcription process .\nSpeaker professor F: , and you just sent off a Eurospeech paper ,. So , we should probably talk about the IBM transcription process stuff that ",
        "summary": "The main topics of the agenda were a paper submitted to Eurospeech and the organising of the recording transcriptions to be done by IBM.",
        "split": "train"
    },
    {
        "uid": "209-Bmr020",
        "id": "Bmr020",
        "text": "Speaker PhD G: , the one was that the  just the  the amount of overlap. But , even if you take out all the backchannels . you still have significant overlap .",
        "summary": "The results presented in the former show a significant percentage of overlapping speech even without counting in backchanneling.",
        "split": "train"
    },
    {
        "uid": "210-Bmr020",
        "id": "Bmr020",
        "text": "Speaker PhD G: And we rescored things , a little bit more carefully . and then the second one was just basically the   the stuff we had in the  in the HLT paper on how overlaps effect the  recognition performance . But basically what we found is after we take out these regions  so we only score the regions that were certified as foreground speech ,   the recognition error went down to almost  , the  level of the non - overlapped  speech .",
        "summary": "Additionally, the high error rate in the recognition of such overlapping speech by the SRI recogniser was minimised simply by changing the scoring method used.",
        "split": "train"
    },
    {
        "uid": "211-Bmr020",
        "id": "Bmr020",
        "text": "Speaker PhD G: so at the end after a discourse marker or after backchannel or after filled pause , you 're much more likely to be interrupted  than before .",
        "summary": "Finally, a strong correlation between pauses and interruptions was confirmed.",
        "split": "train"
    },
    {
        "uid": "212-Bmr020",
        "id": "Bmr020",
        "text": "Speaker PhD G: No . Well , according to the transcripts .",
        "summary": "All these measurements were based on the sample of available transcripts.",
        "split": "train"
    },
    {
        "uid": "213-Bmr020",
        "id": "Bmr020",
        "text": "Speaker PhD G: although that 's  I  I take it that 's something that Don will  will look at",
        "summary": "Other features, like prosody, will be studied in the near future.",
        "split": "train"
    },
    {
        "uid": "214-Bmr020",
        "id": "Bmr020",
        "text": "Speaker PhD G: and also , , the other person that wants it  There is one person at SRI who wants to look at the  , you know , the  the data we have so far ,. and so I figured that FTP is the best  approach . So what I did is I    @ @  I made a n new directory",
        "summary": "An FTP directory containing such experimental data is being set up for the benefit of other researchers.",
        "split": "train"
    },
    {
        "uid": "215-Bmr020",
        "id": "Bmr020",
        "text": "Speaker graduate student A: so the only agenda items were Jane  was Jane wanted to talk about some of the IBM transcription process .\nSpeaker professor F: So , we should probably talk about the IBM transcription process stuff that ",
        "summary": "Regarding the transcriptions to be carried out by IBM, the discussion mainly concerned the format of the recordings that should be sent to them.",
        "split": "train"
    },
    {
        "uid": "216-Bmr020",
        "id": "Bmr020",
        "text": "Speaker Postdoc C: And , if the chunked files focused on the dominant speakers ,  then , when  when it got s patched together when it comes back from IBM , we can add the backchannels .\nSpeaker PhD B: and you just use the s the segments of the dominant speaker then ? For  for sending to  to IBM. But then we could just use the  the output of the detector , and do the beeping on it , and send it to I B\nSpeaker PhD D: Without having her check anything .\nSpeaker professor F: but  but I  I  I have  another suggestion on that , which is ,  since , really what this is , is  is  is trying to in the large , send the right thing to them and there is gonna be this  this post - processing step ,. and we 'll  we 'll fix things up",
        "summary": "Suggestions included sending only the channels with the dominant speakers for transcription, but it was finally agreed on sending the original files with minimal modifications, as there will be extensive in-house post-processing.",
        "split": "train"
    },
    {
        "uid": "217-Bmr020",
        "id": "Bmr020",
        "text": "Speaker Postdoc C: so that if you  if you play  back that bin and have it in the mode where it stops at the boundary ,  it sounds like a normal word . but my general goal  when there was  sufficient space , room , pause  after it  to have it be  kind of a natural feeling  gap .",
        "summary": "Within this discussion, the rationale behind the coding of the time bins according to the flow of discourse was also explained.",
        "split": "train"
    },
    {
        "uid": "218-Bmr023",
        "id": "Bmr023",
        "text": "Speaker professor F: because  it occurred to me that this is late May and the DARPA meeting is in  mid July . I mean in particular I would  I would really hope that when we do this DARPA meeting in July that we sort of have  we 're  we 're into production mode , somehow . , we are gonna have this DARPA  meeting in the middle of July ,. given that we 've been  we 've given a couple public talks about it already , spaced by months and months , I think it 'd be pretty bad if we continued to say none of this is available .",
        "summary": "A pressing concern for the group is the DARPA meeting in July, which is only a short time away, and for which they would like to have some progress.",
        "split": "train"
    },
    {
        "uid": "219-Bmr023",
        "id": "Bmr023",
        "text": "Speaker PhD D: And so he talked it over with the transcriber. and the transcriber thought that the easiest thing for them would be if there was a beep and then the nu a number , a digit , and then a beep , , at the beginning of each one\nSpeaker professor F: e e u u  The reason I 'm asking is because , , Jane and I have just been talking , and she 's just been doing .  , e a , you know , further hiring of transcribers . And so we don't sort of really know exactly what they 'll be doing , how long they 'll be doing it , and so forth ,. because right now she has no choice but to operate in the mode that we already have working .\nSpeaker Postdoc A: I hired two transcribers today . I 'm thinking of hiring another one ,. which will  because we 've had a lot of attrition .\nSpeaker PhD D: Yeah . So , , , Jane and Adam and I had a meeting where we talked about the reorganization of the  directory structure for all of the meeting . For all the Meeting Recorder data .",
        "summary": "Specifically, the group would like to have transcripts available, which would mean resolving legal issues for data use and on the basis of feedback from IBM get more transcription underway.",
        "split": "train"
    },
    {
        "uid": "220-Bmr023",
        "id": "Bmr023",
        "text": "Speaker professor F: I know that we were gonna do something with the transcriber interface is one thing ,\nSpeaker PhD G: Well , we were gonna do a mock - up , like , question answering or something , I thought ,\nSpeaker professor F: I was gonna ask Adam to , , say if he thought anymore about the demo stuff",
        "summary": "Additionally they would also like to have the question answering mock-up and transcriber interface ready for then.",
        "split": "train"
    },
    {
        "uid": "221-Bmr023",
        "id": "Bmr023",
        "text": "Speaker professor F: Is there stuff that 's happened about , , , the  SRI recognizer et cetera ,. Y y you guys were doing a bunch of experiments with different front - ends and then with \nSpeaker PhD D: Now the  the  You saw the note that the PLP now is getting basically the same as the MFCC .\nSpeaker PhD C: , it looks like the vocal tract length normalization is working beautifully , actually ,. Because in all our previous experiments , we had the  , you know , we were essentially cheating by having the , , you know , the h the hand - segmentations as the basis of the recognition . And so now with Thilo 's segmenter working so well , I think we should  consider doing a \nSpeaker PhD G: And even  The good thing is that since you , , have high recall ,  even if you have low precision cuz you 're over - generating , that 's good\nSpeaker professor F: Has  has ,  ? We just  I think , just talked about this the other day , but h has  has anybody had a chance to try changing , , insertion penalty sort of things with the  with the ,   , using the tandem system input for the  ?\nSpeaker PhD C: But the PLP features work  , , you know , continue to improve the ,",
        "summary": "PLP results for the front-end look good, with the group also reporting progress in segmentation: Thilo's segmenter will now be used and ways of improving performance investigated;",
        "split": "train"
    },
    {
        "uid": "222-Bmr023",
        "id": "Bmr023",
        "text": "Speaker PhD G: But we did find that some of the features that , I gue Jane would know about , that are expressing sort of the  distance of , ,  boundaries from peaks in the utterance and  some  local , , range  pitch range effects , like how close people are to their floor , are showing up in these classifiers ,. , so we 're starting to see some patterns. because the  prosodic features are  very noisy and so you  you need a lot of data in order to model them .",
        "summary": "The classifier segmentation is progressing well, especially in the use of prosody for identifying interruption.",
        "split": "train"
    },
    {
        "uid": "223-Bmr023",
        "id": "Bmr023",
        "text": "Speaker professor F: Has  has ,  ? We just  I think , just talked about this the other day , but h has  has anybody had a chance to try changing , , insertion penalty sort of things with the  with the ,   , using the tandem system input for the  ?\nSpeaker PhD C: As I said before , the  using Dan 's , , , vocal tract normalization option works very well . But the PLP features work  , , you know , continue to improve the ,. Well , but if you add them all up you have , , almost five percent difference now .\nSpeaker professor F: And I think I agree with you that if we fixed lots of different things and they would all add up , we would probably have a  a  a competitive system . But I think not that much of it is due to the front - end per se . I think maybe a couple percent of it is , as far as I can see from this .\nSpeaker PhD C: eh At this point I 'm as I mean , you know  e I 'm wondering is it  Can we expect , , a tandem system to do better than a properly trained  you know , a Gaussian system trained directly on the features with , you know , the right ch choice of  parameters ?",
        "summary": "Work on the front end continues, with improvements of 3-5% being made.",
        "split": "train"
    },
    {
        "uid": "224-Bmr024",
        "id": "Bmr024",
        "text": "Speaker professor D: Well , maybe , since that  that was a pretty short one , maybe we should talk about the IBM transcription status .\nSpeaker graduate student F: So , we ,  we did another version of the beeps , where we separated each beeps with a spoken digit .\nSpeaker Postdoc A: I  I hire  I 've hired two extra people already , expect to hire two more . which are now being edited by my head transcriber ,  in terms of spelling errors and all that . She 's also checking through and mar and   and monitoring , , the transcription of another transcriber . And  and you indicated to me that we have a g a goal now ,  for the  for the , ,   the , , DARPA demo , of twenty hours . So , I 'm gonna go up to twenty hours , be sure that everything gets processed , and released , and    and that 's  that 's what my goal is .\nSpeaker professor D: But I guess the other thing is that , , that  that 's kinda twenty hours ASAP because the longer before the demo we actually have the twenty hours , the more time it 'll be for people to actually do cool things with it . Yeah , I mean , I guess the  So the difference if  if , , if the IBM stuff works out , the difference in the job would be that they p primarily would be checking through things that were already done by someone else ?",
        "summary": "In particular, the group discuss their preparation of materials for the transcriptions of digits by IBM, and also the human transcribers who are working towards preparing the set of 20 for the DARPA meeting.",
        "split": "train"
    },
    {
        "uid": "225-Bmr024",
        "id": "Bmr024",
        "text": "Speaker PhD B: N I 'm successfully , , increasing the error rate .\nSpeaker professor D: We 've always viewed it , anyway , as the major difference between the two , is actually in the smoothing ,. that the  that the , ,  PLP , and  and the reason PLP has been advantageous in , , slightly noisy situations is because ,  PLP does the smoothing at the end by an auto - regressive model ,",
        "summary": "Other discussion focuses on the re-evaluation of recognition without cheating on segmentation, and also how SRI recognition can be improved, especially for the female group.",
        "split": "train"
    },
    {
        "uid": "226-Bmr024",
        "id": "Bmr024",
        "text": "Speaker graduate student F: and the ,  Porzel  and the , , SmartKom group are collecting some dialogues .\nSpeaker professor D: I mean , I don't care what directory tree you have it under .\nSpeaker graduate student F: Well , but  but ,  I put it under the same directory tree . and just simply in the file you mark somewhere that this is this type of interaction , rather than another type of interaction . We 're about  we 're about half  halfway through our disk right now .\nSpeaker Postdoc A: Well , but you can have it NW archive to  you can have ,  , a non - backed - up disk NW archived ,",
        "summary": "A number of issues regarding the management of data are addressed by the group:",
        "split": "train"
    },
    {
        "uid": "227-Bmr024",
        "id": "Bmr024",
        "text": "Speaker graduate student F: and the ,  Porzel  and the , , SmartKom group are collecting some dialogues .\nSpeaker professor D: It 's just that it 's , you know , different directory , it 's called something different , it 's \nSpeaker graduate student F: and just simply in the file you mark somewhere that this is this type of interaction , rather than another type of interaction .\nSpeaker professor D: I mean , I don't care what directory tree you have it under .\nSpeaker graduate student F: Well , but  but ,  I put it under the same directory tree . We 're about  we 're about half  halfway through our disk right now .\nSpeaker Postdoc A: Well , but you can have it NW archive to  you can have ,  , a non - backed - up disk NW archived ,",
        "summary": "The inclusion of different data types in the corpus, and the storage and back-up of the group's data.",
        "split": "train"
    },
    {
        "uid": "228-Bmr024",
        "id": "Bmr024",
        "text": "Speaker professor D: but  but , , probably , if we had to pick something  that we would talk on for ten minutes or so while they 're coming here . Or I guess it would be , you think , reorganization status ,\nSpeaker graduate student F: I mean , I think , Chuck was the one who added out the agenda item . I don't really have anything to say other than that we still haven't done it . So , naming conventions and things like that , that I 've been trying to keep actually up to date . And I 've been sharing them with U - d UW folks also .",
        "summary": "Progress has been made in naming conventions, with file reorganisation to be done at a later date, however this was not discussed fully due to Chuck's absence.",
        "split": "train"
    },
    {
        "uid": "229-Bmr024",
        "id": "Bmr024",
        "text": "Speaker professor D: So , is there something quick about Absinthe  that you  ?\nSpeaker graduate student F: and got   a speedup roughly proportional to the number of processors times the clock cycle . But the  what it means is that it 's likely that for net training and forward passes , we 'll  Absinthe will be a good machine . Especially if we get a few more processors and upgrade the processors .",
        "summary": "Finally, Absinthe is now up and running with improved performance.",
        "split": "train"
    },
    {
        "uid": "230-Bmr024",
        "id": "Bmr024",
        "text": "Speaker professor D: So I guess the other thing that we were gonna talk about is  is , , demo . And , , so , these are the demos for the  , July , , meeting  and ,  DARPA mee. but maybe ,  maybe we 'll just put that off for now , given that . But I think maybe we should have a  a sub - meeting ,. I think , , probably , , Adam and  and , , Chuck and me should talk about  should get together and talk about that sometime soon .",
        "summary": "Discussion of demos for the July DARPA meeting were left to the individuals concerned.",
        "split": "train"
    },
    {
        "uid": "231-Bmr025",
        "id": "Bmr025",
        "text": "Speaker professor B: DARPA demos ,",
        "summary": "The most pressing issue concerns the demos which the group are preparing for the DARPA meeting next month.",
        "split": "train"
    },
    {
        "uid": "232-Bmr025",
        "id": "Bmr025",
        "text": "Speaker graduate student H: but it does mean you need to be running a web server . And so it  it 's pretty big and complex . and it would be difficult to port to Windows. the other option is Dan did the Tcl - TK THISL GUI front - end for Broadcast News. And so I 've written some tools to convert everything into the right for file formats . And the command line version of the indexing and the querying is now working .\nSpeaker PhD G: So another idea I w t had just now actually for the demo was whether it might be of interest to sh to show some of the prosody  work that Don 's been doing .",
        "summary": "Here they discuss the querying and indexing tool which is progressing well albeit with a few front-end issues, and also the transcriber tool.",
        "split": "train"
    },
    {
        "uid": "233-Bmr025",
        "id": "Bmr025",
        "text": "Speaker Postdoc A: I hired several more transcribers ,. They 're making great progress . I 've been finishing up the double checking .",
        "summary": "Transcription is progressing well, with new people hired, and double checking almost complete.",
        "split": "train"
    },
    {
        "uid": "234-Bmr025",
        "id": "Bmr025",
        "text": "Speaker PhD F: We 're sort of doing things in parallel ,\nSpeaker graduate student H: especially for the information retrieval stuff .",
        "summary": "Work is also going on in parallel with IBM.",
        "split": "train"
    },
    {
        "uid": "235-Bmr025",
        "id": "Bmr025",
        "text": "Speaker graduate student H: I spoke with Dave Johnson about putting all the Meeting Recorder stuff on non - backed - up disk to save the overhead of backup. And , so the only issue here is the timing between getting more disks and recording meetings .\nSpeaker professor B: So I guess the idea is that we would be reserving the non - backed - up space for things that took less than twenty - four hours to recreate or something like that ,\nSpeaker graduate student H: Things that are recreatable easily and also  Yeah , basically things that are recreatable .",
        "summary": "Additionally, the group have progressed further with data storage issues, with backing-up their data now regarded as a priority, and more disk space required.",
        "split": "train"
    },
    {
        "uid": "236-Bmr025",
        "id": "Bmr025",
        "text": "Speaker graduate student H: So I 've been doing a bunch of XML tools. Yeah and then the other thing also that Thilo noticed is , on the microphone ,. I mean this is why I wanna use a g a tool to do it rather than the plain text. the  the one that shows up here ,  that will flash yellow if the mike isn't connected .",
        "summary": "Tools for accessing key file information have been developed which should ensure all meeting information is present.",
        "split": "train"
    },
    {
        "uid": "237-Bmr025",
        "id": "Bmr025",
        "text": "Speaker professor B: Good . CrossPads ?\nSpeaker graduate student H: who basically said \" if you 're not using them , could you return them ? \". We  we used them a couple times ,\nSpeaker professor B: we  we get somebody to buy into the idea of doing this as part of the task . part of the reason  I think part of the reason that Adam was so interested in the SpeechCorder sort of f idea from the beginning is he said from the beginning he hated taking notes\nSpeaker PhD E: Well if you wanted to do that maybe the right architecture for it is to get a PDA with a wireless card . And  and that way you can synchronize very easily with the  the  the meeting\nSpeaker graduate student H: I mean for what  what you 've been describing buttons would be even more convenient than anything else ,\nSpeaker PhD G: Maybe we could do like a student project ,. you know , maybe someone who wants to do this as their main like s project for something would be cool .\nSpeaker graduate student H: I mean if we had them out and sitting on the table people might use them a little more",
        "summary": "The collection of CrossPad note-taking data will be pursued in future meetings.",
        "split": "train"
    },
    {
        "uid": "238-Bmr025",
        "id": "Bmr025",
        "text": "Speaker Postdoc A: I know that that Thilo you were , , bringing the Channeltrans interface onto the Windows machine ?\nSpeaker PhD D: Yeah it 's  it  Basically it 's done ,\nSpeaker graduate student H: And then at the same time I 'll probably rewire the room as per Jane 's suggestion. W   We ordered more wireless ,. so that the first N channels are wireless , eh are the m the close - talking and the next N are far - field .\nSpeaker professor B: I mean there 's  there 's all this stuff going on between Andreas and  and  and Dave and Chuck and others with various kinds of runs.  recognition runs ,. trying to figure things out about the features. but it 's  it 's all sort of in process ,",
        "summary": "Finally, other progress made includes getting the ChannelTrans interface working, ordering more wireless microphones, and analysing recognition runs.",
        "split": "train"
    },
    {
        "uid": "239-Bmr026",
        "id": "Bmr026",
        "text": "Speaker graduate student A: So , I think this is gonna be a pretty short meeting because I have four agenda items ,",
        "summary": "This is a relatively short meeting of the Meeting Recorder group, with only a few agenda items.",
        "split": "train"
    },
    {
        "uid": "240-Bmr026",
        "id": "Bmr026",
        "text": "Speaker graduate student A: three of them were requested by Jane who is not gonna be at the meeting today .\nSpeaker PhD F:  Well first of all with IBM I got a note from Brian yesterday saying that they finally made the tape for the thing that we sent them a  week or week and a half ago. and hopefully next week we 'll have the transcription back from that .\nSpeaker graduate student E: So we 're doing some in parallel .",
        "summary": "Transcription was discussed briefly because Jane was not present, however this appears to be progressing well in parallel with IBM.",
        "split": "train"
    },
    {
        "uid": "241-Bmr026",
        "id": "Bmr026",
        "text": "Speaker PhD F: so I 've been trying to keep a web page up to date f showing what the current status is of the trans of all the things we 've collected. That 's the thing that I sent out just to foo people saying can you update these pages\nSpeaker graduate student A: So Jane also wanted to talk about participant approval , but I don't really think there 's much to talk about . I 'm gonna send out to the participants , , with links to web pages which contain the transcripts and allow them to  suggest edits .\nSpeaker PhD C: So but it 's just transcripts , not the  not the audio ?\nSpeaker graduate student A: Nope , they 'll have access to the audio also . Because the transcripts might not be right .\nSpeaker PhD F: So , the audio that they 're gonna have access to , will that be the uncompressed version ?. Or will you have scripts that like uncompress the various pieces and \nSpeaker graduate student A: Yeah , it 's  it 's probably going to have to be the uncompressed versions because , , , it takes too long to do random access decompression .",
        "summary": "Web pages have been set up to show transcription status and to allow participants to approve transcripts.",
        "split": "train"
    },
    {
        "uid": "242-Bmr026",
        "id": "Bmr026",
        "text": "Speaker graduate student A: , DARPA demo status , not much to say . The back - end stuff is working out fine .\nSpeaker graduate student E: And , also , I was just showing Andreas , I got an X Waves kind of display ,. and I don't know how much more we can do with it . with like the prosodic stuff where we have like stylized pitches and signals and the transcripts on the bottom",
        "summary": "DARPA demos are progressing well with the back-end indexed to allow front-end filtering, and a potential demo ideas investigated which would use X Waves.",
        "split": "train"
    },
    {
        "uid": "243-Bmr026",
        "id": "Bmr026",
        "text": "Speaker PhD C: I 've been putting together Transcriber things for Windows\nSpeaker PhD D: But  But it would be cool if the Transcriber interface had like another window for the  you know , maybe above the waveform where it would show some arbitrary valued function that is  that is you know time synchron ti ti time synchronous with the wavform .\nSpeaker graduate student E: and see the pitch contours also .\nSpeaker graduate student A: Just record the audio clip and show an image and I think that 's \nSpeaker professor B: and ,  the more live , the better , but , given the crunch of time , we may have to retreat from it to some extent . So I think   For a lot of reasons , I think it would be very nice to have this Transcriber interface be able to show some other interesting signal along with it",
        "summary": "Transcriber is now working for Windows, however live pitch contours may not work in the time available.",
        "split": "train"
    },
    {
        "uid": "244-Bmr026",
        "id": "Bmr026",
        "text": "Speaker graduate student A: And the last i item on the agenda is disk issues yet again . We 're  We 're only about thirty percent on the second disk . but we are like ninety five percent , ninety eight percent on the scratch disks for the expanded meetings .",
        "summary": "Backed-up disk space is now fine, however temporary space is running out fast.",
        "split": "train"
    },
    {
        "uid": "245-Bmr026",
        "id": "Bmr026",
        "text": "Speaker professor B: , you know Dave Johnson is gone for , like , ten days ,. I mean it 's just a question of figuring out where they should be and hanging them ,. So this is a question that 's pretty hard to solve without talking to Dave ,. But at any rate I think that there 's a  there 's a longer term thing and there 's immediate need",
        "summary": "Interim measures are discussed while sysadmin are away.",
        "split": "train"
    },
    {
        "uid": "246-Bmr026",
        "id": "Bmr026",
        "text": "Speaker PhD D: yot I tested the  the sort of final version of the PLP configuration on development test data for  for this year 's Hub - five test set . And the recognition performance was exactly , and I mean exactly up to the  you know , the first decimal , same as with the Mel Cepstra front - end . They  They were  The males I think were slightly better and the females were slightly worse but nothing really . And then the really nice thing was that if  if we combine the two systems we get a one and a half percent improvement .",
        "summary": "Improvement has been made in the final version of the PLP, which shows better female performance, and combined with Mel Ceptra offers 1.5% improvement.",
        "split": "train"
    },
    {
        "uid": "247-Bmr026",
        "id": "Bmr026",
        "text": "Speaker PhD D: And then we had some results on  digits , , with . And the reason is basically there 's a whole bunch of read speech data in the Hub - five training set .",
        "summary": "Digit performance also improved thanks to training using scripted speech data.",
        "split": "train"
    },
    {
        "uid": "248-Bmr026",
        "id": "Bmr026",
        "text": "Speaker PhD D: And then I th guess Chuck and I had some discussions about how to proceed with the tandem system",
        "summary": "Progress has also been made in SRI alignment for tandem system.",
        "split": "train"
    },
    {
        "uid": "249-Bmr026",
        "id": "Bmr026",
        "text": "Speaker professor B: so something that we wanna do next meeting is  is to put together , a kind of reasonable list for ourselves of what is it , , that we 've done . I mean just sort of bulletize I mean o e do do I can  I can dream up text but  this is basically gonna lead to the annual report .\nSpeaker graduate student A: So just a week from tomorrow ?\nSpeaker PhD D:   One thing  I mean  we    in past meetings we had also a you know various  variously talked about the work that w was happening sort of on the  on the recognition side. Well , it 's that  It 's just gonna be ver very boring for people who are not you know , sort of really interested in the details of the recognition system .\nSpeaker professor B: Well , OK , so how many  how many people here would not be interested in  in a meeting about recognition ?\nSpeaker PhD D: Liz and Jane probably .\nSpeaker PhD F: Why don't we alternate this meeting every other week ?. But I do I don't  I mean a lot of times lately it seems like we don't really have enough for a full meeting on Meeting Recorder .\nSpeaker professor B: And then if we find , you know we 're just not getting enough done , there 's all these topics not coming up , then we can expand into another meeting . . So . . Let 's chat about it with Liz and Jane  when we get a chance , see what they think and ",
        "summary": "The group note that the annual report needs to be worked on for next week, and it is also suggested to hold recognition meetings separately, however these issues will be discussed in more detail at the next meeting.",
        "split": "train"
    },
    {
        "uid": "250-Bmr027",
        "id": "Bmr027",
        "text": "Speaker graduate student F: So I didn't send out agenda items. because until five minutes ago we only had one agenda item. and now we have two . And if you disagree with it , why don't you read it and give me comments on it ?",
        "summary": "Although the Meeting Recorder group only list two agenda items, this meeting explores transcription, and in particular, consent forms in depth, and at times results in heated debate.",
        "split": "train"
    },
    {
        "uid": "251-Bmr027",
        "id": "Bmr027",
        "text": "Speaker graduate student F: So , , as most of you should know , I did send out the consent form thingies. and we had decided that they have  they only needed to sign once . No .\nSpeaker professor B: At some point y you go around and get people to sign something ?\nSpeaker Postdoc A: This is in the summer period. and presumably people may be out of town . But we can make the assumption , can't we ? that , , they will be receiving email , , most of the month .\nSpeaker professor B: It  well , it  well , you 're right . Sometimes somebody will be  away. That 's  it 's , you know , just a certain risk to take . cuz i because if we wanna be able to give it to people July fifteenth ,. if somebody 's gonna come back and say \" OK , I don't want this and this and this used \" , , clearly we need some time to respond to that .",
        "summary": "With regard to obtaining consent, the group discuss the extent to which they need to attempt to contact people, which methods are most appropriate, and how much responsibility rests on participants being available and checking their e-mail regularly.",
        "split": "train"
    },
    {
        "uid": "252-Bmr027",
        "id": "Bmr027",
        "text": "Speaker Postdoc A: But I thought it might be good to remind people two weeks prior to that\nSpeaker professor B: cuz i because if we wanna be able to give it to people July fifteenth ,. if somebody 's gonna come back and say \" OK , I don't want this and this and this used \" , , clearly we need some time to respond to that .\nSpeaker PhD H: Maybe  , do we have mailing addresses for these people ?\nSpeaker Postdoc A: Al - altogether we 've got twenty people . These people are people who read their email almost all the time . I  I really don't see that it 's a problem . I  I think that it 's a common courtesy to ask them  , to expect for them to , , be able to have @ @  us try to contact them ,. u just in case they hadn't gotten their email . I think they 'd appreciate it .\nSpeaker professor B: and if there 's half the people , say , who don't respond  at all by , you know , some period of time ,  we can just make a list of these people. and I 'll hand it to administrative staff or whatever ,. and they 'll just call them up and say , you know , \" have you . Is  is this OK ? And would you please mail  you know , mail Adam that it is , if i if it , you know , is or not . \"\nSpeaker PhD E: The other thing that there 's a psychological effect that  at least for most people , that if they 've responded to your email saying \" yes , I will do it \" or \" yes , I got your email \" , they 're more likely to actually do it   later  than to just ignore it .\nSpeaker graduate student F: So what are we gonna do when we run into someone that we can't get in touch with ?\nSpeaker Postdoc A: I don't think ,  They 're so recent , these visitors . I  I mean , I  I w I 'll be able to  if you have any trouble finding them , I really think I could find them .\nSpeaker professor B: Well , the way ICSI goes , people , , who , , were here ten years ago still have acc  have forwards to other accounts and so on .\nSpeaker graduate student F: that if they give us contact information and that contact information isn't accurate that  we fulfilled our burden .\nSpeaker Postdoc A: and it  I  this discussion has made me think it might be nice to have a follow - up email within the next couple of days saying \" by the way , you know , we wanna hear back from you by X date",
        "summary": "The group suggest sending reminder e-mails, although since many participants are local they can be contacted by other means if necessary.",
        "split": "train"
    },
    {
        "uid": "253-Bmr027",
        "id": "Bmr027",
        "text": "Speaker professor B: We heard anything from IBM ?\nSpeaker PhD C: So we got the transcript back from that one meeting . Everything seemed fine . Adam  had a script that will  put everything back together and there was  Well , there was one small problem but it was a simple thing to fix .\nSpeaker graduate student F: Yeah . Now we haven't actually had anyone go through that meeting , to see whether the transcript is correct\nSpeaker PhD C: Yeah . It 's gonna have to go through our regular process .\nSpeaker graduate student F: I mean , the one thing I noticed is it did miss a lot of backchannels .\nSpeaker Postdoc A: Do you suppose that was because they weren't caught by the pre - segmenter ?\nSpeaker graduate student F: Yeah . They 're  they 're not in the segmented . It 's not that the  IBM people didn't do it .",
        "summary": "Transcriptions are back from IBM, and the group discuss the checking of these, particularly since the pre-segmenter has interfered with back-channel data.",
        "split": "train"
    },
    {
        "uid": "254-Bmr027",
        "id": "Bmr027",
        "text": "Speaker Postdoc A: The German ones will be ready for next week .\nSpeaker professor B: NSA .\nSpeaker Postdoc A: @ @  So , this is from one of the NSA meetings. No , no . These are  these are our local transcriptions of the NSA meetings . Sometimes some speakers will insert foreign language terms . and I 'm hoping that when the checked versions are run through the recognizer that you 'll see s substantial improvements in performance\nSpeaker graduate student F: Yeah , but I bet  I bet they 're acoustically challenging parts anyway , though .\nSpeaker Postdoc A: No , actually no .\nSpeaker graduate student F: Oh , so it 's just jargon .\nSpeaker Postdoc A: I mean this is  cuz , you know you don't realize in daily life how much you have top - down influences in what you 're hearing . And it 's jar it 's jargon coupled with a foreign accent .\nSpeaker PhD H: But we don't  I mean , our language model right now doesn't know about these words anyhow .",
        "summary": "Checking of the NSA meetings has revealed that this non-native English meeting data contains transcription inaccuracies due to the use of foreign language terms and technical vocabulary.",
        "split": "train"
    },
    {
        "uid": "255-Bmr027",
        "id": "Bmr027",
        "text": "Speaker graduate student F: Disk space ,. That for every meeting . any meeting which has any bleeps in it we need yet another copy of .\nSpeaker Postdoc A: Well   I  you know , I think at a certain point , that copy that has the deletions will become the master copy .\nSpeaker graduate student F: So I  I don't want  I really would rather make a copy of it , rather than bleep it out\nSpeaker professor B: Are you del are you bleeping it by adding ?\nSpeaker Postdoc A: we 've been , , contacted by University of Washington now , of course , to , . We sent them the transcripts that correspond to those  six meetings. and they 're downloading the audio files .\nSpeaker graduate student F: , the only one was Don wanted to , , talk about disk space yet again .\nSpeaker professor B: We 've just ordered a hundred gigabytes . , and there 's also an annual report . Now ,. so they  so DARPA just said do an annual report .\nSpeaker PhD H: I mean , the  the next thing on our agenda is to go back and look at the ,   the automatic alignments. I  I  I learned from Thilo what data we can use as a benchmark to see how well we 're doing on automatic alignments of the background speech . or , of the foreground speech with background speech .\nSpeaker PhD E: And then , , I guess , the new data that Don will start to process . You know , before we were working with these segments that were all synchronous. We got our abstract accepted for this conference ,. ISCA workshop , in , , , New Jersey . but we 're hoping to have a paper for that as well ,. which should be an interesting . But , I mean , the good news is that that will have sort of the European experts in prosody . sort of a different crowd ,. and I think we 're the only people working on prosody in meetings so far ,. , it 's ISCA Workshop on Prosody in Speech Recognition and Understanding , or something like that \nSpeaker professor B: Y you going to , , Eurospeech ?\nSpeaker graduate student F: I don't have a paper. but I 'd kinda like to go ,",
        "summary": "Additional topics covered more briefly in this meeting are disk space, the DARPA annual report, progress with the demo, conference submissions and attendance, and requests from the University of Washington for data.",
        "split": "train"
    },
    {
        "uid": "256-Bro003",
        "id": "Bro003",
        "text": "Speaker professor F: , We should talk a little bit about the plans for the  the field trip next week . And  mostly First though about the logistics for it . Then maybe later on in the meeting we should talk about what we actually you know , might accomplish . , in and  kind of go around  see what people have been doing  talk about that ,  a r progress report . , Essentially .  And then  Another topic I had was that    Dave here had said \" Give me something to do . \". And so maybe we can discuss that a little bit . , and , then , talk a little bit about  about disks and resource  resource issues that  that 's starting to get worked out .\nSpeaker PhD A: Did you  happen to find out anything about the OGI multilingual database ?\nSpeaker PhD G: One they call the multi - language database , and another one is a twenty - two language , something like that . But it 's also telephone speech . Well , actually , for the moment if we w do not want to use these phone databases , we  we already have  English , Spanish and French , with microphone speech . , actually , these three databases are generic databases . So w f for  for Italian , which is close to Spanish , French and , i i , TI - digits we have both , digits  training data and also  more general training data .\nSpeaker professor F: Well , we also have this Broadcast News that we were talking about taking off the disk , which is   is microphone data for  for English .\nSpeaker PhD G: Yeah , perhaps  yeah , there is also TIMIT .",
        "summary": "The main topics discussed were arrangements and objectives of an\nupcoming field trip to visit research partners OGI; a number of\nmembers reported their progress to date; if there are any tasks that\none member can help others with; an overall description of the Cube\nproject, a multi-lingual speech recognition system for use by the\ncellular phone industry, along with consideration of some of the\nissues therein, specifically disk and resource issues.",
        "split": "train"
    },
    {
        "uid": "257-Bro003",
        "id": "Bro003",
        "text": "Speaker graduate student C: Well , the inputs are one dimension of the cube ,\nSpeaker professor F: So , a a actually  maybe  now you 've got me sort of intrigued . Can you describe what  what 's on the cube ?\nSpeaker graduate student C: basically , the  the cube will have three dimensions . The first dimension is the  the features that we 're going to use . And the second dimension , , is the training corpus . And that 's the training on the discriminant neural net . And then , there 's the testing corpus .",
        "summary": "Essentially the cube consists of three dimension: input features;\ntraining corpus; and test corpus.",
        "split": "train"
    },
    {
        "uid": "258-Bro003",
        "id": "Bro003",
        "text": "Speaker graduate student C: Well , the inputs are one dimension of the cube ,. which , , we 've talked about it being , , PLP , , M F C Cs , , J - JRASTA , JRASTA - LDA . , for the training corpus  corpus , , we have , , the  the d  digits  from the various languages .\nSpeaker professor F: So that 's , , three hundred and forty - three , ,  different systems that are going to be developed . something like seven things in each ,  each column . So it seems like there 's  there 's some peculiarities of the ,  of each of these dimensions that are getting sorted out . And then , , if  if you work on getting the , , assembly lines together , and then the  the pieces sort of get ready to go into the assembly line. What 's  what 's great about this is it sets it up in a very systematic way ,. so that , , once these  all of these , you know , mundane but real problems get sorted out , we can just start turning the crank. And , , the thing is that once you get a better handle on how much you can realistically do , , ,  concurrently on different machines , different SPERTs , and so forth , , and you see how long it takes on what machine and so forth , you can stand back from it and say , \" OK , if we look at all these combinations we 're talking about , and combinations of combinations , and so forth , \" you 'll probably find you can't do it all . so then at that point , , we should sort out which ones do we throw away . Which of the combinations across  you know , what are the most likely ones ,",
        "summary": "Most important concerns are which\ncombinations of features to use, and what combinations of languages\nand broad/specific corpora to use for the training",
        "split": "train"
    },
    {
        "uid": "259-Bro004",
        "id": "Bro004",
        "text": "Speaker professor B: So where are we on   on   our runs ?\nSpeaker PhD D: so .   We  So  As I was already said , we  we mainly focused on four kind of features . The PLP , the PLP with JRASTA , the MSG , and the MFCC from the baseline Aurora . , and we focused for the  the test part on the English and the Italian . . We 've trained several neural networks on . so  on the TI - digits English  and on the Italian data. and also on the broad  English French and Spanish databases . and , actually what we  we @ @ observed is that if the network is trained on the task data it works pretty well .",
        "summary": "The meeting was dominated by a discussion of the first results coming\nin.",
        "split": "train"
    },
    {
        "uid": "260-Bro004",
        "id": "Bro004",
        "text": "Speaker PhD D: The first testing is  with task data . The second test is trained on a single language with broad database ,. but the same language as the t task data . But for Italian we choose Spanish which  we assume is close to Italian . The third test is by using , the three language database\nSpeaker professor B: That 's including the w the   the . the one that it 's \nSpeaker PhD D: Yeah .\nSpeaker PhD A: it 's the broad  data .\nSpeaker PhD D: And the fourth test is  excluding from these three languages the language  that is  the task language .",
        "summary": "There have been four types of test, in which the training data\nvaries, and a variety of input features have been tried.",
        "split": "train"
    },
    {
        "uid": "261-Bro004",
        "id": "Bro004",
        "text": "Speaker PhD D: But actually we didn't train network on  both types of data. We only did either task  task data or  broad  data . And then when we jump to the multilingual data it 's it become worse. . The error rate increase u of  of  of ten percent , relative . example  when we go from TI - digits training to  TIMIT training  we lose  around ten percent ,. Twenty to  to thirty percent further .\nSpeaker professor B: OK , but I think that  given the pressure of time we probably want to draw  because of that  especially , we wanna draw some conclusions from this ,. and make some strong decisions for what we 're gonna do testing on before next week .",
        "summary": "The process\nand results were explained to the group, the implications of the\nresults discussed, and plans for moving forward were made.",
        "split": "train"
    },
    {
        "uid": "262-Bro004",
        "id": "Bro004",
        "text": "Speaker professor B: So they 're  they 're doing  the  the VAD. I guess they mean voice activity detection So again , it 's the silence . So Their   the results look pretty good . So I think that it 's  it 's nice to do that in this. because in fact , it 's gonna give a better word error result. and therefore will help within an evaluation . . , as you know , part of the problem with evaluation right now is that the  word models are pretty bad. and nobody wants   has  has approached improving them . So The question we 're gonna wanna go  through next week when Hynek shows up I guess is given that we 've been . we 're looking at  ,. by then I guess , combinations of features and multi - band. , and we 've been looking at  cross - language , cross  task  issues . But they 've been looking at   at these issues . At the on - line normalization and the  voice activity detection . And I guess when he comes here we 're gonna have to start deciding about  what do we choose  from what we 've looked at  to blend with  some group of things in what they 've looked at. And once we choose that ,  how do we split up the  effort ?",
        "summary": "There was also discussion of some of the work being conducted by\nresearch partners OGI, including how the two groups should best work\ntogether.",
        "split": "train"
    },
    {
        "uid": "263-Bro004",
        "id": "Bro004",
        "text": "Speaker professor B: We have the  little tiny IBM machine   that might someday grow up to be a big  IBM machine . It 's got s slots for eight ,. I think we only got two so far ,. Yeah , I mean you can check with  Dave Johnson . and   Somebody could do   you know , , check out  the multi - threading  libraries . I mean , I guess the prudent thing to do would be for somebody to do the work on   on getting our code running  on that machine with two processors  even though there aren't five or eight .",
        "summary": "The group also briefly touched upon resource issues.",
        "split": "train"
    },
    {
        "uid": "264-Bro005",
        "id": "Bro005",
        "text": "Speaker professor D: so , , you 've got some , , Xerox things to pass out ?\nSpeaker PhD A: OK , s so there is kind of summary of what has been done . Summary of experiments since , well , since last week. and also since the  we 've started to run  work on this . .  So since last week we 've started to fill the column with  features w with nets trained on PLP with on - line normalization",
        "summary": "The main topic for discussion by the Berkeley Meeting Recorder group was progress on the experiments run as part of the groups main project, a speech recogniser for the cellular industry.",
        "split": "train"
    },
    {
        "uid": "265-Bro005",
        "id": "Bro005",
        "text": "Speaker professor D: so , , you 've got some , , Xerox things to pass out ?\nSpeaker PhD A: Yeah , I 'm sorry for the table ,. but as it grows in size , , it .\nSpeaker professor D: , so for th the last column we use our imagination .\nSpeaker PhD A: OK , s so there is kind of summary of what has been done . Summary of experiments since , well , since last week. and also since the  we 've started to run  work on this . .  So since last week we 've started to fill the column with  features w with nets trained on PLP with on - line normalization. but with delta also ,.  when we use the large training set using French , Spanish , and English , you have one hundred and six without delta. and eighty - nine with the delta .\nSpeaker professor D: a And again all of these numbers are with a hundred percent being , , the baseline performance ,\nSpeaker PhD A: and training with other languages is a little bit worse . we have a ninety - one number ,. so , it 's multi - English ,. And , yeah , and here the gap is still more important between using delta and not using delta . If y if I take the training s the large training set , it 's  we have one hundred and seventy - two ,. and one hundred and four when we use delta . .  Even if the contexts used is quite the same ,. except for the multi - English , which is always one of the best . then we started to work on a large dat database containing , , sentences from the French , from the Spanish , from the TIMIT , from SPINE , from  English digits , and from Italian digits . and  , actually we did this before knowing the result of all the data ,. , so we have to to redo the  the experiment training the net with , PLP , but with delta .\nSpeaker PhD B: And first in the experiment - one I  I do  I  I use different MLP ,\nSpeaker PhD A: Yeah , and test across everything .\nSpeaker professor D: So I guess the other thing is to take  you know  if one were to take , , you know , a couple of the most successful of these ,. Yeah , try all these different tests .\nSpeaker PhD A: we still have to work on Finnish ,. , basically , to make a decision on which MLP can be the best across the different languages . For the moment it 's the TIMIT network , and perhaps the network trained on everything . , well , the next part of the document is , well , basically , a kind of summary of what  everything that has been done . So . We have seventy - nine M L Ps trained on. ten  on ten different databases .",
        "summary": "This included reporting the results, and making conclusions to shape future work.",
        "split": "train"
    },
    {
        "uid": "266-Bro005",
        "id": "Bro005",
        "text": "Speaker PhD A: , discussion with Hynek , Sunil and Pratibha for trying to plug in their our  our networks with their  within their block diagram ,. , where to plug in the  the network , , after the  the feature ,. before as a as a plugin or as a anoth another path ,. actually Hynek would like to see ,. perhaps if you remember the block diagram there is , , temporal LDA followed b by a spectral LDA for each critical band . And he would like to replace these by a network. which would , , make the system look like a TRAP . , there are still open questions there ,. The future work is ,  well , try to connect to the  to make  to plug in the system to the OGI. where to put the MLP basically .\nSpeaker professor D: So . , we  we wanna get their path running here ,. If so , we can add this other stuff . as an additional path\nSpeaker PhD A: Yeah , the way we want to do it perhaps is to  just to get the VAD labels and the final features . So they will send us the  Well , provide us with the feature files ,\nSpeaker professor D: So we  So . First thing of course we 'd wanna do there is to make sure that when we get those labels of final features is that we get the same results as them . Without putting in a second path . Yeah just th w i i Just to make sure that we  have  we understand properly what things are , our very first thing to do is to  is to double check that we get the exact same results as them on HTK .",
        "summary": "Also discussed were the details of the continued collaboration with project partner OGI.",
        "split": "train"
    },
    {
        "uid": "267-Bro007",
        "id": "Bro007",
        "text": "Speaker professor B: today we 're looking at a number of things we 're trying\nSpeaker PhD D: It 's only one small experiment to know what happened . To apply also to in include also the  the silence of the MLP we have the fifty - six form and the silence to pick up the silence and we include those .\nSpeaker professor B: The silence plus the KLT output ?\nSpeaker PhD C: No they 're  I think there is this silence in addition to the KLT outputs. it is because we  we  we just keep we don't keep all the dimensions after the KLT\nSpeaker PhD D: and we not s we are not sure if we pick  we have the silence .\nSpeaker PhD C: So we try to add the silence also in addition to the  these twenty - eight dimensions .\nSpeaker professor B: Do you e they mentioned  made some  when I was on the phone with Sunil they  they mentioned some weighting scheme that was used to evaluate all of these numbers .\nSpeaker PhD C: well it 's forty percent for TI - digit , sixty for all the SpeechDat - Cars ,\nSpeaker professor B: and we don't have the TI - digits part yet ?\nSpeaker PhD C: Generally what you observe with TI - digits is that the result are very close whatever the  the system .\nSpeaker professor B: so it looks to me  I guess the same . given that we have to take the filt ones out of the  the running because of this delay problem  so it looks to me like the ones you said I agree are  are the ones to look at. but I just would add the  the  the second row one. so if we can know what  how many words are in each. and then Dave Dave promised to get us something tomorrow which will be there as far as they 've gotten  Friday. and then we 'll operate with that. do we fix the system tomorrow or do we fix the system on Tuesday ?\nSpeaker PhD C: I think we fixed on Tuesday , yeah .\nSpeaker professor B: I  Yeah , OK except that we do have to write it up . so maybe what we do is we  we  we as soon as we get the data from them we start the training and so forth. but we start the write - up right away because as you say there  there 's only minor differences between these .\nSpeaker PhD C: I think you  we could  we could start soon , yeah . Write up something .\nSpeaker professor B: Well anyway , sounds like there 'll be a lot to do just to  work with our partners to fill out the tables  over the next next few days. Yes , so I mean  I think we have to actually get it done Tuesday. so then next Thursday we can sort of have a little aftermath. but my assumption is that we basically have to be done Tuesday .",
        "summary": "They discussed most recent results, finalized plans to continue and discussed the work required and timing needed for completion of this stage of the project.",
        "split": "train"
    },
    {
        "uid": "268-Bro008",
        "id": "Bro008",
        "text": "Speaker professor D: So , I got ,  these results from , , Stephane . Also , , I think that ,   we might hear later today , about other results . I think s that , , there were some other very good results that we 're gonna wanna compare to . But ,  r our results from other  other places ,. You know most of the time , even  I mean even though it 's true that the overall number for Danish  we didn't improve it. I mean , I think that , , one of the things that Hynek was talking about was understanding what was in the other really good proposals. and trying to see if what should ultimately be proposed is some , , combination of things . So   , since we have a bit farther to travel than  some of the others ,  , we 'll have to get done a little quicker . But , , I mean , it 's just tracing down these bugs . I mean , just exactly this sort of thing of , you know , why  why these features seem to be behaving differently , , in California than in Oregon .",
        "summary": "This included some discussion of results, comparing various other groups' systems, issues involving the set up, and plans for future work.",
        "split": "train"
    },
    {
        "uid": "269-Bro010",
        "id": "Bro010",
        "text": "Speaker professor C: So what are you doing ?\nSpeaker PhD B: , well , we 've  a little bit worked on trying to see , , what were the bugs and the problem with the latencies .",
        "summary": "The Berkeley Meeting Recorder Group discussed the progress of several of their members.",
        "split": "train"
    },
    {
        "uid": "270-Bro010",
        "id": "Bro010",
        "text": "Speaker professor C: You  you had a discussion with Sunil about this though ?\nSpeaker PhD B: No .\nSpeaker professor C: Yeah , you should talk with him . , cuz they could be doing the same thing and  or something . We just  we just have to be in contact more . I think that  the  the fact that we  we did that with  had that thing with the latencies was indicative of the fact that there wasn't enough communication .\nSpeaker PhD B: But , well , when we add up everything it 's  it will be alright . So it would be around two hundred and forty \nSpeaker PhD A: What 's the allowable ?\nSpeaker professor C: Two - fifty ,. , well the people who had very low latency want it to be low  , very   very very narrow , , latency bound . Unfortunately we 're the main ones with long latency ,\nSpeaker PhD A: A person  I don't think a person can tell the difference between , , you know , a quarter of a second and a hundred milliseconds ,. I 'm not even sure if we can tell the difference between a quarter of a second and half a second . I mean it just  it feels so quick .\nSpeaker professor C: , one thing that would be no  good to find out about from this conference call is that what they were talking about , what they 're proposing doing , was having a third party , , run a good VAD , and  and determine boundaries . And then given those boundaries , then have everybody do the recognition . , I guess they argued about that yesterday",
        "summary": "The group also touched upon matters that had broader implications for the work, such as the work of other groups on the same project.",
        "split": "train"
    },
    {
        "uid": "271-Bro010",
        "id": "Bro010",
        "text": "Speaker professor C: , maybe we can talk about a couple other things briefly ,. So you 're coming up with your quals proposal ,\nSpeaker graduate student E: , but I 'm , , looking into extending the work done by Larry Saul and John Allen and Mazin Rahim .\nSpeaker professor C: so , , y you want to talk maybe a c two or three minutes about what we 've been talking about today and other days ?\nSpeaker graduate student F: we 're interested in , , methods for far mike speech recognition ,. ,  mainly , , methods that deal with the reverberation  in the far mike signal .",
        "summary": "There were also some progress reports from group members working on other projects.",
        "split": "train"
    },
    {
        "uid": "272-Bro011",
        "id": "Bro011",
        "text": "Speaker professor A: Let 's  let 's , I mean , I think that as  as we said before that one of the things that we 're imagining is that there  there will be  in the system we end up with there 'll be something to explicitly do something about noise. So I suggest actually now we  we  we sorta move on and  and hear what 's  what 's  what 's happening in  in other areas. .  And I don't know if we 've talked lately about the  the plans you 're developing that we talked about this morning. what 's next ?",
        "summary": "The Berkeley Meeting Recorder Group met to discuss their recent progress.",
        "split": "train"
    },
    {
        "uid": "273-Bro011",
        "id": "Bro011",
        "text": "Speaker professor A: So y you guys had a  a meeting with  with Hynek which I unfortunately had to miss . So everybody knows what happened except me .\nSpeaker PhD C: Well . first we discussed about some of the points that I was addressing in the mail I sent last week . About the , well  the downsampling problem . and about the f the length of the filters. So basically that was  that 's  all we discussed about .",
        "summary": "This included a recap of a meeting with one of the members of their research partner OGI.",
        "split": "train"
    },
    {
        "uid": "274-Bro011",
        "id": "Bro011",
        "text": "Speaker professor A: Let 's  let 's , I mean , I think that as  as we said before that one of the things that we 're imagining is that there  there will be  in the system we end up with there 'll be something to explicitly do something about noise. So I suggest actually now we  we  we sorta move on and  and hear what 's  what 's  what 's happening in  in other areas. like  what 's  what 's happening with your  investigations  about echos and so on .\nSpeaker graduate student F: Well I haven't started writing the test yet , I 'm meeting with Adam today. and he 's going t show me the scripts he has for   running recognition on mee Meeting Recorder digits . I haven't asked Hynek for  for the  for his code yet . Cuz I looked at Avendano 's thesis and  I don't really understand what he 's doing yet\nSpeaker professor A: .  And I don't know if we 've talked lately about the  the plans you 're developing that we talked about this morning\nSpeaker graduate student E: .  So continuing to extend\nSpeaker professor A: So I mean , there 's these issues of what are the  what are the variables that you use. and do you combine them using the soft \" AND - OR \" or you do something , you know , more complicated. what 's next ?\nSpeaker PhD B: I could say a little bit about w stuff I 've been playing with .",
        "summary": "There were progress reports from group members working on echo cancellation, acoustic feature detection, and HTK optimization, along with discussion of many issues arising from this topics.",
        "split": "train"
    },
    {
        "uid": "275-Bro012",
        "id": "Bro012",
        "text": "Speaker professor A: OK , so  had some interesting mail from Dan Ellis .\nSpeaker PhD F: . Since the last meeting we 've  we 've tried to put together  the clean low - pass downsampling , upsampling , I mean ,",
        "summary": "The Meeting Recorder group at Berkeley met to discuss recent progress.",
        "split": "train"
    },
    {
        "uid": "276-Bro012",
        "id": "Bro012",
        "text": "Speaker PhD F: . Since the last meeting we 've  we 've tried to put together  the clean low - pass downsampling , upsampling , I mean ,. the new filter that 's replacing the LDA filters ,",
        "summary": "Of greatest interest was the progress on improving the latency and performance of their recogniser.",
        "split": "train"
    },
    {
        "uid": "277-Bro012",
        "id": "Bro012",
        "text": "Speaker professor A: OK , so  had some interesting mail from Dan Ellis . where this came up was that I was showing off these wave forms that we have on the web. and  and  I just sort of hadn't noticed this , but that  the major , major component in the wave  in the second wave form in that pair of wave forms is actually the air conditioner . Can I ask a , I mean  a sort of top - level question ,. which is  \" if  if most of what the OGI folk are working with is trying to  integrate this other  other spectral subtraction ,  why are we worrying about it ? \"",
        "summary": "There was also concern over overlap of work with partners OGI, and a lack of a good example of room reverberation for demonstrations.",
        "split": "train"
    },
    {
        "uid": "278-Bro013",
        "id": "Bro013",
        "text": "Speaker professor A: .   What are we talking about today ?\nSpeaker PhD E: , well , first there are perhaps these Meeting Recorder digits that we tested .",
        "summary": "The Main purpose of the meeting of ICSI's Meeting Recorder Group at Berkeley was to discuss the recent progress of it's members.",
        "split": "train"
    },
    {
        "uid": "279-Bro013",
        "id": "Bro013",
        "text": "Speaker PhD E: , well , first there are perhaps these Meeting Recorder digits that we tested . Perhaps the point is that we 've been working on  is ,. yeah , we have put the the good VAD in the system. and  it really makes a huge difference . Yeah , and then we 've started to work with this of voiced - unvoiced stuff .\nSpeaker PhD D: No , I w  I begin to play  with Matlab and to found some parameter robust for voiced - unvoiced decision .\nSpeaker professor A: What 's up with you ?\nSpeaker graduate student C: so I 've been looking at Avendano 's work. but it 's  it 's an approach to deal with  reverberation or that  the aspect of his work that I 'm interested in",
        "summary": "This includes reports on the progress of the groups main digit recogniser project, with interest on voice-activity detectors and voiced/unvoiced detection, work on acoustic feature detection, and research into dealing with reverberation.",
        "split": "train"
    },
    {
        "uid": "280-Bro013",
        "id": "Bro013",
        "text": "Speaker PhD E: , well , first there are perhaps these Meeting Recorder digits that we tested .\nSpeaker professor A: The  both the   the SRI System and the oth\nSpeaker graduate student C: y you do  I think you read some of the  the zeros as O 's and some as zeros . Is there a particular way we 're supposed to read them ?\nSpeaker PhD E: Perhaps in the sheets there should be another sign for the \nSpeaker professor A: I mean . I think people will do what they say . I mean in digit recognition we 've done before , you have  you have two pronunciations for that value , \" O \" and \" zero \" . No , they just write \nSpeaker PhD E: and  and people pronounce \" O \" or zero \nSpeaker professor A: and you just  They just want people to read the digits as you ordinarily would",
        "summary": "There was also talk of comparing different recognition systems and training datasets, and a discussion of the pronunciation of the digit zero for the recording at the end of the meeting.",
        "split": "train"
    },
    {
        "uid": "281-Bro014",
        "id": "Bro014",
        "text": "Speaker PhD A: So what happened since , ,  last week is . well , from OGI , these experiments on  putting VAD on the baseline .",
        "summary": "The ICSI Meeting Recorder Group at Berkeley met to discuss progress on their main project, Aurora.",
        "split": "train"
    },
    {
        "uid": "282-Bro014",
        "id": "Bro014",
        "text": "Speaker PhD C: I have something just fairly brief to report on . And  but it runs much much faster . I  I think m  it only took something like , , three or four hours to do the full training ,. as opposed to wh what , sixteen hours or something like that ?. Oh , the other thing that I did was , ,  I compiled  the HTK stuff for the Linux boxes .\nSpeaker PhD A: There was a conference call this Tuesday . I don't know yet the   what happened  Tuesday ,. but  the points that they were supposed to discuss is still ,  , things like  the weights ,. So what happened since , ,  last week is \nSpeaker professor B: There was a  start of some effort on something related to voicing or something .\nSpeaker PhD A: So basically we try to ,   , find  good features that could be used for voicing detection ,",
        "summary": "They discussed a conference call with project partners, there have been some developments that should help speed up experiments, along with some progress made in the current area they are looking, voiced/unvoiced detection.",
        "split": "train"
    },
    {
        "uid": "283-Bro014",
        "id": "Bro014",
        "text": "Speaker graduate student D: N , not not not much is new .\nSpeaker professor B: , anything to  add ?\nSpeaker graduate student E: Well , I 've been continuing reading . I went off on a little tangent this past week ,",
        "summary": "A number of other members of the group also reported the progress they were making on their work.",
        "split": "train"
    },
    {
        "uid": "284-Bro016",
        "id": "Bro016",
        "text": "Speaker PhD F: I don't really have , , anything new . Been working on  Meeting Recorder stuff .\nSpeaker professor E: What 's new with you ?\nSpeaker PhD B: So there 's nothing  new .\nSpeaker professor E: What 's old with you that has developed over the last week or two ?\nSpeaker PhD B: Well , so we 've been mainly working on the report\nSpeaker PhD F: Any - anything new on the thing that , , you were working on with the ,  ?\nSpeaker PhD C: I don't have results yet .\nSpeaker professor E: So , what  wha  wh wha what what 's going on ?\nSpeaker PhD C: Well , we work in the report , too ,\nSpeaker professor E: How are , ,  how are things going with what you 're doing ?\nSpeaker graduate student D: I took a lot of time just getting my taxes out of the way . So , I 'm  I 'm starting to write code now for my work. but I don't have any results yet .\nSpeaker professor E: do you wanna  say something about your stuff here ?\nSpeaker graduate student A: I  just , , continuing looking at , , ph , phonetic events ,. It 's  that 's pretty much it .",
        "summary": "Although the members of ICSI's Meeting Recorder Group at Berkeley had little progress to report, there were still a number of issues relating to their work to discuss.",
        "split": "train"
    },
    {
        "uid": "285-Bro016",
        "id": "Bro016",
        "text": "Speaker professor E: Do you think that would be the case for next week also ?. What 's your projection on  ?\nSpeaker PhD F: so the experiment is to , , run our front - end like normal , with the default , , insertion penalties and so forth ,. and then tweak that a little bit. and see how much of a difference it makes\nSpeaker professor E: That 's something I 'd like to understand before we actually use something from it ,\nSpeaker graduate student A: I  I was thinking getting  getting us a set of acoustic events to  , to be able to distinguish between , , phones and words and stuff .\nSpeaker graduate student D: Can you give an example of an event ?\nSpeaker graduate student A: So , he In this paper , , it 's talking about phoneme recognition using acoustic events . So , things like frication or , , nasality .\nSpeaker PhD F: just to expand a little bit on the idea of acoustic event . There 's ,  in my mind , anyways , there 's a difference between , , acoustic features and acoustic events . And I think of acoustic features as being , , things that linguists talk about ,. Stuff that 's not based on data , necessarily . That 's not based on , you know , acoustic data . So they talk about features for phones ,. which may or may not be all that easy to measure in the acoustic signal . Versus an acoustic event , which is just  some  something in the acoustic signal  that is fairly easy to measure . It 's kinda like the difference between top - down and bottom - up . I think of the acoustic  you know , phonetic features as being top - down . You know , you look at the phone. and you say this phone is supposed to be  you know , have this feature , this feature , and this feature . Whether tha those features show up in the acoustic signal is sort of irrelevant . Whereas , an acoustic event goes the other way . Here 's the signal . Here 's some event . And then that  you know , that may map to this phone sometimes ,. And so it 's sort of a different way of looking .",
        "summary": "These included making plans for upcoming experiments, clarifying definitions, and approaches which may or may not be against the rules of the Aurora project, alongside alternatives that would not be.",
        "split": "train"
    },
    {
        "uid": "286-Bro016",
        "id": "Bro016",
        "text": "Speaker professor E: So , my suggestion , though , is that you  you not necessarily finish that . But that you put it all together so that it 's  you 've got  you 've got a clearer structure to it . So that , you know  so that such a thing can be written . And right now it 's kind of important that we actually go forward with experiments .",
        "summary": "There was also debate about the necessary continuation of a group report.",
        "split": "train"
    },
    {
        "uid": "287-Bro016",
        "id": "Bro016",
        "text": "Speaker professor E: I was saying Hynek 'll be here next week ,. , Wednesday through Friday . , through Saturday ,. I won't be here Thursday and Friday . But my suggestion is that , , at least for this meeting , people should go ahead ,. , cuz Hynek will be here ,\nSpeaker PhD F: So maybe I can have that for next week when Hynek 's here .\nSpeaker professor E: Maybe  that 's maybe a topic . Especially if you talk with him when I 'm not here ,. that 's a topic you should discuss with Hynek. to , you know , double check it 's OK . Well , this 'll be , I think , something for discussion with Hynek next week .",
        "summary": "Plans were also made with regard to a visitor from research partner OGI",
        "split": "train"
    },
    {
        "uid": "288-Bro017",
        "id": "Bro017",
        "text": "Speaker professor B: And  and so , I  I think that Carmen and Stephane reported on Amsterdam meeting ,. which was kind of interesting. because it was for the first time we realized we are not friends really , but we are competitors .",
        "summary": "He reported on a recent project meeting from his group's perspective.",
        "split": "train"
    },
    {
        "uid": "289-Bro017",
        "id": "Bro017",
        "text": "Speaker professor B: because it was for the first time we realized we are not friends really , but we are competitors .\nSpeaker PhD E: It seemed like there were still some issues ,. that they were trying to decide ?\nSpeaker professor B: There is a plenty of  there 're plenty of issues .",
        "summary": "There was much politics involved, and disagreement between groups.",
        "split": "train"
    },
    {
        "uid": "290-Bro017",
        "id": "Bro017",
        "text": "Speaker professor B: So what we are doing at OGI now is working basically on our parts which we I think a little bit neglected ,. And then most of the effort is now also aimed at this e e TRAP recognition .",
        "summary": "He also brought the ICSI members up to date with his group's latest work.",
        "split": "train"
    },
    {
        "uid": "291-Bro017",
        "id": "Bro017",
        "text": "Speaker PhD E: How 's your documentation or whatever. So have you been running some new experiments ?",
        "summary": "The ICSI group reported their most recent progress and detailed their recent findings.",
        "split": "train"
    },
    {
        "uid": "292-Bro017",
        "id": "Bro017",
        "text": "Speaker professor B: So we were just discussing , since you mentioned that , in  it w. driving in the car with Morgan this morning , we were discussing a good experiment for b for beginning graduate student who wants to run a lot of  who wants to get a lot of numbers on something. which is , like , \" imagine that you will  you will start putting every co any coefficient , which you are using in your vector , in some general power . Like sort of you take a s power of two , or take a square root , or something . Because your Gaussian mixture model ,. So you 're compressing the range of this coefficient , so it 's becoming less efficient . Morgan was @ @ and he was  he was saying well this might be the alternative way how to play with a  with a fudge factor ,. you know ,. And I said \" well in that case why don't we just start compressing individual elements , like when  when . because we observed that higher parameters were more important than lower for recognition . And basically the  the C - ze C - one contributes mainly slope ,",
        "summary": "Having discussed this with the ICSI project leader, the OGI member told of some future investigation they had devised, which would look at the adjusting the importance of some features.",
        "split": "train"
    },
    {
        "uid": "293-Bro017",
        "id": "Bro017",
        "text": "Speaker professor B: When we talked about Aurora still I wanted to m make a plea  encourage for more communication between  between  different parts of the distributed  center . even when there is absolutely nothing to  to s to say but the weather is good in Ore - in  in Berkeley . I 'm sure that it 's being appreciated in Oregon and maybe it will generate similar responses down here ,",
        "summary": "There were also further calls for greater communication between the groups.",
        "split": "train"
    },
    {
        "uid": "294-Bro018",
        "id": "Bro018",
        "text": "Speaker graduate student B: well I  tried this mean subtraction method . Due to Avendano ,  I 'm taking s  six seconds of speech ,",
        "summary": "There has been further work on voiced/unvoiced detection, along with spectral subtraction.",
        "split": "test"
    },
    {
        "uid": "295-Bro018",
        "id": "Bro018",
        "text": "Speaker professor C: So , he 's not here ,. OK , and wh when did Stephane take off ?\nSpeaker PhD D: I think that Stephane will arrive today or tomorrow .\nSpeaker professor C: So he 's  he 's going to ICASSP which is good .\nSpeaker PhD D: and also mmm I  H Hynek last week say that if I have time I can to begin to  to study. well seriously the France Telecom proposal. to look at the code. I begin to  to work also in that . But the first thing that I don't understand is that they are using R - the log energy that this quite . I don't know why they have some constant in the expression of the lower energy .",
        "summary": "The group discussed one members attendance at a conference, and another groups code, which is proving hard to follow.",
        "split": "test"
    },
    {
        "uid": "296-Bro019",
        "id": "Bro019",
        "text": "Speaker professor C: Sunil 's here for the summer ,. Sunil since you 're  haven't  haven't been at one of these yet , why don't yo you tell us what 's  what 's up with you ?",
        "summary": "The ICSI Meeting Recorder Group at Berkley have a temporary new member on loan from research partner OGI.",
        "split": "train"
    },
    {
        "uid": "297-Bro019",
        "id": "Bro019",
        "text": "Speaker professor C: Sunil since you 're  haven't  haven't been at one of these yet , why don't yo you tell us what 's  what 's up with you ?\nSpeaker PhD A: , the other  other thing what I tried was , I just , , took the baseline and then ran it with the endpoint inf th information ,. just the Aurora baseline ,. to see that how much the baseline itself improves. by just supplying the information of the  I mean the w speech and nonspeech . I found that the baseline itself improves by twenty - two percent by just giving the wuh . because the  the second  the new phase is going to be with the endpointed speech . And just to get a feel of how much the baseline itself is going to change by adding this endpoint information , I just , , use \nSpeaker PhD F: So people won't even have to worry about , , doing speech - nonspeech then .\nSpeaker PhD A: Yeah",
        "summary": "He began the meeting by reporting his recent activities, which included looking at the new baseline system.",
        "split": "train"
    },
    {
        "uid": "298-Bro019",
        "id": "Bro019",
        "text": "Speaker professor C: and then just , I guess , progress reports individually , and then , plans for where we go between now and then , pretty much . so maybe , just briefly , you could remind us about the related experiments . Cuz you did some stuff that you talked about last week ,\nSpeaker PhD D: The main thing that we did is just to take the spectral subtraction from the France Telecom ,. We are playing  we are also playing , trying to put other spectral subtraction mmm , in the code . it would be a very simple spectral subtraction , on the , mel energies\nSpeaker professor C: Anything else going on ?\nSpeaker PhD B: I don't have good result , with the  inc including the new parameters ,",
        "summary": "The other members of the group also reported their recent progress in areas such as spectral subtraction and voicing detection.",
        "split": "train"
    },
    {
        "uid": "299-Bro019",
        "id": "Bro019",
        "text": "Speaker PhD A: With what  what other new p new parameter ?\nSpeaker professor C: So maybe  You probably need to back up a bit\nSpeaker PhD B: I tried to include another new parameter to the traditional parameter ,. that , like , the auto - correlation , the R - zero and R - one over R - zero. and another estimation of the var the variance of the difference for  of the spec si , spectrum of the signal. and  and the spectrum of time after filt mel filter bank . The idea is to found another feature for discriminate between voice sound and unvoice sound . And we try to use this new feature  feature .\nSpeaker professor C: anything on your end you want to talk about ?\nSpeaker graduate student G: Sunil hasn't  hasn't heard about , what I 've been doing . So basically that 's just , , trying to propose , , your next your  your following years of  of your PHD work ,. trying  trying to find a project to  to define and  and to work on . So , I 've been , , looking into , , doing something about r , speech recognition using acoustic events . , building robust , primary detectors for these acoustic events ,. and using the outputs of these robust detectors to do speech recognition .",
        "summary": "They also explained some of their projects to their guest.",
        "split": "train"
    },
    {
        "uid": "300-Bro019",
        "id": "Bro019",
        "text": "Speaker PhD F: I could say a few words about , some of the , compute stuff that 's happening around here ,. so that people in the group know . So we just put in an order for about twelve new machines , , to use as sort of a compute farm . and Andreas has sort of gotten that all , fixed up and up to speed . And he 's got a number of little utilities that make it very easy to ,  run things using P - make and Customs . And I can send an email around. or , maybe I should do an FAQ on the web site about it or something .\nSpeaker professor C: How about an email that points to the FAQ ,\nSpeaker PhD F: And , if you say that and then some job that you want to execute , , it will find the fastest currently available machine , and export your job to that machine ,. And , so , soon , when we get all the new machines up ,  , e then we 'll have lots more compute to use . there 's a lot of nice features to it. and it kinda helps to balance the load of the machines",
        "summary": "The group shall soon be taking delivery of more machines for a computation farm, and they discussed some software tools for running large processes.",
        "split": "train"
    },
    {
        "uid": "301-Bro021",
        "id": "Bro021",
        "text": "Speaker PhD F: Let 's see , maybe we should just get a list of items . I guess there 's the usual  updates ,. everybody going around and saying , , you know , what they 're working on ,. the things that happened the last week .",
        "summary": "The ICSI Meeting Recorder Group at Berkeley met once more to discuss group members' progress.",
        "split": "train"
    },
    {
        "uid": "302-Bro021",
        "id": "Bro021",
        "text": "Speaker PhD C: well , I 've been working on  on t mainly on on - line normalization this week . , I 've been trying different  slightly  slightly different approaches . Yeah . I 've been playing a little bit with some kind of thresholding ,\nSpeaker PhD F: How about you , Sunil ?\nSpeaker PhD D: So , , I 've been , , implementing this , , Wiener filtering for this Aurora task .\nSpeaker PhD F: Oh . How about you , Carmen ?\nSpeaker PhD E: Mmm . I 'm working with VTS .",
        "summary": "The majority of the group are working on tasks related to the Aurora Project, including on-line normalization and Wiener filtering.",
        "split": "train"
    },
    {
        "uid": "303-Bro021",
        "id": "Bro021",
        "text": "Speaker PhD F: How about you , Barry ?\nSpeaker graduate student A: ,  still working on my  my quals preparation stuff .\nSpeaker PhD F: So , ,  I guess I 'll just pass it on to Dave .\nSpeaker graduate student G: Well , in my lunch talk last week I  I said I 'd tried phase normalization and gotten garbage results using that l , long - term mean subtraction approach .",
        "summary": "Other progress was also reported.",
        "split": "train"
    },
    {
        "uid": "304-Bro022",
        "id": "Bro022",
        "text": "Speaker PhD A: So , should we just do the same kind of deal where we  go around and do , , status report  kind of things ?",
        "summary": "A typical progress report meeting for the ICSI Meeting Recorder Group at Berkeley.",
        "split": "train"
    },
    {
        "uid": "305-Bro022",
        "id": "Bro022",
        "text": "Speaker PhD A: So , should we just do the same kind of deal where we  go around and do , , status report  kind of things ?. Why don't you go ahead , Barry ?\nSpeaker graduate student F: Well , this past week I 've just been , , getting down and dirty into writing my  my proposal .\nSpeaker PhD A: So , , you want to go next , Dave ?\nSpeaker graduate student E: last week I finally got results from the SRI system about this mean subtraction approach . And I also , , did some experiments  about normalizing the phase .\nSpeaker PhD A: Do you want to go , Stephane ?\nSpeaker PhD C: I 'm more interested in trying to figure out what 's still the difference between the SRI system and the Aurora system .\nSpeaker PhD G: th I 've been playing with this Wiener filter , like .\nSpeaker PhD A: How about you , Carmen ?\nSpeaker PhD D: Well , I am still working with , eh , VTS .",
        "summary": "Each of the group reported their most recent progress, and any results they have achieved.",
        "split": "train"
    },
    {
        "uid": "306-Bro022",
        "id": "Bro022",
        "text": "Speaker graduate student E: wh why would that be , ,  considering that we actually got an improvement in near - mike performance using HTK ?. , with some input from , , Andreas , I have a theory in two parts .\nSpeaker PhD C: because  this is also one big difference between  the two systems . the other differences were  the fact that maybe the acoustic models of the SRI are more  SRI system are more complex .\nSpeaker professor B: You know , they have channel adaptation .\nSpeaker PhD A: Well , there 's also the normalization .",
        "summary": "This then prompted discussion about the reasons behind such findings, which were for the most part not as expected.",
        "split": "train"
    },
    {
        "uid": "307-Bro022",
        "id": "Bro022",
        "text": "Speaker PhD C: I 'm more interested in trying to figure out what 's still the difference between the SRI system and the Aurora system . , the next thing is this  this VAD problem that ,. , the second thing is the  this spectral subtraction . which I 've just started yesterday to launch a bunch of , ,  twenty - five experiments ,. , with different , , values for the parameters that are used .",
        "summary": "Topics the group touched upon included spectral subtraction, phase normalization, Voice activity detection, along with comparisons between systems.",
        "split": "train"
    },
    {
        "uid": "308-Bro023",
        "id": "Bro023",
        "text": "Speaker PhD A: So , ,   I guess we got lots to catch up on . And we haven't met for a couple of weeks .",
        "summary": "The ICSI Meeting Recorder Group of Berkeley met for the first time in two weeks.",
        "split": "train"
    },
    {
        "uid": "309-Bro023",
        "id": "Bro023",
        "text": "Speaker graduate student E: So , , since we 're looking at putting this ,  mean log m magnitude spectral subtraction , , into the SmartKom system , I I did a test seeing if , , it would work using past only  and plus the present to calculate the mean .\nSpeaker PhD B: So I 've been working on that Wiener filtering .\nSpeaker PhD D: So ,  I 've been , , working still on the spectral subtraction .",
        "summary": "Group members reported their progress in the areas of spectral subtraction, Wiener filtering and noise estimation.",
        "split": "train"
    },
    {
        "uid": "310-Bro023",
        "id": "Bro023",
        "text": "Speaker professor C: I don't know much about  as much as I should about the rest of the system. But if you did first pass with , , the  with  either without the mean sub subtraction or with a  a very short time one ,. and then , , once you , , actually had the whole utterance in , if you did , , the , , , longer time version then , based on everything that you had , , and then at that point only used it to distinguish between , you know , top N , , possible utterances or something , you  you might  it might not take very much time . I mean , I know in the large vocabulary stu , , systems , people were evaluating on in the past , some people really pushed everything in to make it in one pass. but other people didn't and had multiple passes . the argument , , against multiple passes was u u has often been \" but we want to this to be r you know  have a nice interactive response \" . And the counterargument to that which , say , , BBN I think had ,  was \" yeah ,. but our second responses are  second , , passes and third passes are really , really fast \" . do we know yet ?. about  as far as what they 're  what the rules are going to be and what we can use ?\nSpeaker PhD D: so actually I received a  a new document , describing this . And what they did finally is to , mmm , , not to align the utterances but to perform recognition ,. , only on the close - talking microphone ,. and to take the result of the recognition to get the boundaries , of speech .\nSpeaker professor C: Oh , so they will send files. so everybody will have the same boundaries to work with ?\nSpeaker PhD D: Yeah .\nSpeaker professor C: all of that sort of stuff is things that they 're debating in their standards committee . And  and that 's sort of one of the . Because if we completely ignore latency , and then we discover that we really have to do something about it , we 're going to be  find ourselves in a bind .",
        "summary": "They also discusses topics relating to the rules and preferences of the project they are working on, including single vs multiple passes.",
        "split": "train"
    },
    {
        "uid": "311-Bro023",
        "id": "Bro023",
        "text": "Speaker PhD A: Can I ask just a  a high level question ?. Can you just say like one or two sentences about Wiener filtering and why  why are people doing that ?\nSpeaker PhD B: I mean , so the basic principle of Wiener filter is like you try to minimize the , , d , difference between the noisy signal and the clean signal\nSpeaker PhD D: and for this I u simply used some code that , ,  I had from  from Belgium ,. which is technique that , , takes a bunch of frame ,. and for each frequency bands of this frame , takes a look at the minima of the energy . And then average these minima and take this as an  an energy estimate of the noise for this particular frequency band .",
        "summary": "A number of the group also took time to explain the basics of their approaches to the group.",
        "split": "train"
    },
    {
        "uid": "312-Bro023",
        "id": "Bro023",
        "text": "Speaker PhD A: Just for a visit ?\nSpeaker professor C: , we 'll see . We might  might end up with some longer collaboration or something . So he 's gonna look in on everything we 're doing. and give us his  his thoughts . And Hans - , Hans - Guenter will be here , , I think by next  next Tuesday or so . So he 's  he 's going to be here for about three weeks ,",
        "summary": "There are hopes that a visitor coming for three weeks, may lead to a longer term collaboration.",
        "split": "train"
    },
    {
        "uid": "313-Bro024",
        "id": "Bro024",
        "text": "Speaker graduate student C: so , yeah , the  this past week I 've been main mainly occupied with , , getting some results , u from the SRI system trained on this short Hub - five training set for the mean subtraction method .\nSpeaker PhD B: so the last week , , I showed some results with only SpeechDat - Car. So I was like looking into \" why , what is wrong with the TI - digits ? \" . And I found that , the noise estimation is a reason for the TI - digits to perform worse than the baseline .\nSpeaker PhD E: yeah , there are two figures showing actually the , mmm , , performance of the current VAD .\nSpeaker PhD H: Well , I only say that the  this is , a summary of the  of all the VTS experiments",
        "summary": "The groups regulars reported progress on their work on mean subtraction, noise estimation, voice activity detection and the Vector Taylor Series.",
        "split": "train"
    },
    {
        "uid": "314-Bro024",
        "id": "Bro024",
        "text": "Speaker graduate student C: And then there 's , another thing I wanna start looking at , ,  wi is , , the choice of the analysis window length . with the  with the HTK set - up I should be able to do some experiments , on just varying that length ,. say between one and three seconds , in a few different reverberation conditions ,\nSpeaker professor D: I guess one thing that might also be an issue , , cuz part of what you 're doing is you 're getting a  a spectrum over a bunch of different kinds of speech sounds . and so it might matter how fast someone was talking for instance . You know , if you  if  if  if there 's a lot of phones in one second maybe you 'll get a  a really good sampling of all these different things ,. and   and , , on the other hand if someone 's talking slowly maybe you 'd need more .\nSpeaker graduate student C: a actually I was just thinking about what I was asking about earlier , wi which is about having  less than say twelve seconds in the SmartKom system to do the mean subtraction . You said in  systems where you use cepstral mean subtraction , they concatenate utterances. and ,  do you know how they address this issue of , , testing versus training ?\nSpeaker professor G: I think what they do is they do it always on - line ,. I mean , that you just take what you have from the past ,. that you calculate the mean of this and subtract the mean .\nSpeaker graduate student C: and , , so  so in tha in that case , wh what do they do when they 're t , performing the cepstral mean subtraction on the training data ?. So  because you 'd have hours and hours of training data . So do they cut it off and start over ?\nSpeaker professor D: and so if you 're splitting things up into utterances . So , for instance , in a dialogue system ,  where you 're gonna be asking , , you know , th for some information , there 's some initial th something . and I think the heuristics of exactly how people handle that and how they handle their training I 'm sure vary from place to place .\nSpeaker graduate student C: so you 'd  you  and so in training you would start over at  at every new phone call or at every  new speaker .\nSpeaker professor G: it  it seems to be the best what  wh wh what  what we can do in this moment is multi - condition training . And every when we now start introducing some  some noise reduction technique we  we introduce also somehow artificial distortions . And these artificial distortions  , I have the feeling that they are the reason why  why we have the problems in this multi - condition training . That means the H M Ms we trained , they are  they are based on Gaussians ,. And if we introduce now this  this u spectral subtraction , or Wiener filtering stuff . I mean , this is your noise estimate and you somehow subtract it or do whatever . And then I think what you do is you introduce some  some artificial distribution in this. in  in the models .\nSpeaker professor D: So  So , basically our  our position is  that , , we shouldn't be unduly constraining the latency at this point. because we 're all still experimenting with trying to make the performance better in the presence of noise . , there is a minority in that group who is a arguing  who are arguing for  , , having a further constraining of the latency . So we 're s just continuing to keep aware of what the trade - offs are and , you know , what  what do we gain from having longer or shorter latencies ?. Well , France Telecom was  was  was very short latency\nSpeaker professor G: It was in the order of thirty milliseconds",
        "summary": "While on these topics, related areas discussed included recognition window length, training versus test set sizes, artificial distortion and latency concerns.",
        "split": "train"
    },
    {
        "uid": "315-Bro025",
        "id": "Bro025",
        "text": "Speaker professor B: anyway we   after coming back from QualComm we had , you know , very strong feedback. and , , I think it was  Hynek and Guenter 's and my opinion also that , , you know , we sort of spread out to look at a number of different ways of doing noise suppression . But given the limited time , , it was sort of time to  choose one . , and so , , th the vector Taylor series hadn't really worked out that much . , the subspace stuff , , had not been worked with so much . , so it sort of came down to spectral subtraction versus Wiener filtering . , we had a long discussion about how they were the same and how they were d , completely different .",
        "summary": "ICSI's Meeting Recorder Group have returned from a meeting with some important decisions to make.",
        "split": "train"
    },
    {
        "uid": "316-Bro025",
        "id": "Bro025",
        "text": "Speaker professor B: so instead they went to Yosemite and bonded , and  and they came out with a single  single piece of software . So it 's  another  another victory for international collaboration .\nSpeaker PhD A: So  so you guys have combined  or you 're going to be combining the software ?\nSpeaker PhD C: Well , the piece of software has , like , plenty of options ,. So depending on that , it  it becomes either spectral subtraction or Wiener filtering .\nSpeaker professor B: but the thing is  the important thing is that there is a piece of software that you  that we all will be using now .",
        "summary": "They have developed a piece of software which allows them to implement their two main approaches to dealing with noise.",
        "split": "train"
    },
    {
        "uid": "317-Bro025",
        "id": "Bro025",
        "text": "Speaker PhD E: But , still  so , there will be a piece of software with ,   , will give this system , the fifty - three point sixty - six , by default\nSpeaker PhD A: How  how is  how good is that ?\nSpeaker PhD E: It 's just one percent off of the  best proposal . It 's between  i we are second actually if we take this system .\nSpeaker PhD A: Compared to the last evaluation numbers ? Yeah .\nSpeaker PhD C: Yeah .\nSpeaker professor B: So it  so , , it 's  it it 's not using our full bal bag of tricks , if you will . And , , and it  it is , , very close in performance to the best thing that was there before . , but , you know , looking at it another way , maybe more importantly , ,  we didn't have any explicit noise , , handling . we didn't explicitly have anything to deal with stationary noise .",
        "summary": "The base rate is currently set at the second best rate as of the last project evaluation, and it does not yet include everything the group have been working on.",
        "split": "train"
    },
    {
        "uid": "318-Bro025",
        "id": "Bro025",
        "text": "Speaker professor B: I mean , I gather you have  it sounds like you have a few more days of  of nailing things down with the software and so on . But  and then  but , ,  arguably what we should do is , even though the software can do many things , we should for now pick a set of things ,. and not change that . And then focus on  everything that 's left . So there 's the neural net issue . There 's the VAD issue . And , , there 's the second stream  thing .\nSpeaker PhD A: What was the issue with the VAD ?\nSpeaker professor B: I guess they still allow two hundred milliseconds on either side or some ?\nSpeaker PhD E: And all the speech pauses ,. which is  Sometimes on the SpeechDat - Car you have pauses that are more than one or two seconds . We cou we can do better , I think ,. So , our current VAD is  is more than twenty percent ,. while their is fourteen .\nSpeaker professor B: That 's  that 's a good set of work that  that , \nSpeaker PhD C: Just one more thing . Like , should we do something f more for the noise estimation ,\nSpeaker professor B: Yeah . I was wondering about that .",
        "summary": "With this in mind, they have decided to set most things, and concentrate on studying only a few key aspects, the neural network, the voice activity detector, and the noise estimation.",
        "split": "train"
    },
    {
        "uid": "319-Bro026",
        "id": "Bro026",
        "text": "Speaker professor B: so  We  we had a meeting with ,  with Hynek , , in  in which , , , Sunil and Stephane ,  summarized where they were and  and , , talked about where we were gonna go . So that  that happened sort of mid - week . But I guess maybe the thing  since you weren't  yo you guys weren't at that  that meeting , might be just  just to , , sort of recap , , the  the conclusions of the meeting .\nSpeaker PhD E: You 're talking about the meeting with Hynek ?\nSpeaker professor B: Since he 's going out of town like now , and I 'm going out town in a couple weeks , , and time is marching , sort of , given all the mu many wonderful things we could be working on , what  what will we actually focus on ?. And ,  and what do we freeze ?. And , you know , what do we  ?. and then within that , I guess the idea was to freeze a certain set of options for now , to run it , , a particular way , and decide on what things are gonna be experimented with , as opposed to just experimenting with everything . So keep a certain set of things constant . , maybe describe roughly what  what we are keeping constant for now ,\nSpeaker PhD A: Well . So we 've been working like six weeks on  on the noise compensation and we end up with something that seems reasonable .\nSpeaker PhD E: Are you gonna use  which of the two techniques ?\nSpeaker PhD A: So finally it 's  it 's , , Wiener filtering on FFT bins . So we are going to fix this for the moment and work on the other aspects of  the whole system .\nSpeaker professor B: But structurally it seemed like the things  the main things that  that we brought up that , , are  are gonna need to get worked on seriously are , , , a   a significantly better VAD , , putting the neural net on , , which , you know , we haven't been doing anything with , the , , neural net at the end there , and , , the , ,  opening up the second front .",
        "summary": "Some members of the group met recently with research partners to settle on the current state of their software, and decide on the future work they would investigate, and these decisions were relayed to the rest of the group.",
        "split": "train"
    },
    {
        "uid": "320-Bro026",
        "id": "Bro026",
        "text": "Speaker professor B: But structurally it seemed like the things  the main things that  that we brought up that , , are  are gonna need to get worked on seriously are , , , a   a significantly better VAD , , putting the neural net on , , which , you know , we haven't been doing anything with , the , , neural net at the end there , and , , the , ,  opening up the second front .\nSpeaker PhD E: The other half of the channel ?\nSpeaker professor B: Yeah , yeah , I mean , cuz we  we have  we have , , , half the  the , , data rate that they allow . And , , so the initial thing which came from , , the meeting that we had down south was , , that , , we 'll initially just put in a mel spectrum as the second one . It 's , you know ,  cheap , easy . There 's a question about exactly how we do it . We probably will go to something better later ,. And  and ,  , you know , in some sense we 're all doing fairly similar things .\nSpeaker PhD E: So how did they fill up this  all these  these bits ?\nSpeaker professor B: , why are we using half ?. We have the on - line normalization and then we have the LDA RASTA . The LDA RASTA , , throws away high modulation frequencies . And they 're not doing that . So that if you throw away high modulation frequencies , then you can downsample . And , , so I  you know , we  we 've found in a lot of ways for quite a while that having a second stream , helps a lot . So that 's  that 's put in , and you know , it may even end up with mel spectrum even though I 'm saying I think we could do much better , just because it 's simple .\nSpeaker PhD E: So this second stream , will it add latency to the system\nSpeaker professor B: No , it 's in parallel . We 're not talking about computation time here . So it 's just in terms of what data it 's depending on . It 's depending on the same data as the other .",
        "summary": "Of the three areas for the future, they touched mostly upon the use of a second, parallel, data stream.",
        "split": "train"
    },
    {
        "uid": "321-Bro026",
        "id": "Bro026",
        "text": "Speaker PhD E: What about the ,  , the new part of the evaluation ,. the , , Wall Street Journal part ?\nSpeaker professor B: Have you ever worked with the Mississippi State h , software ?\nSpeaker PhD E: Not yet .\nSpeaker professor B: Well you  you may be called upon to help , , , on account of , , all the work in this stuff here has been , , with small vocabulary .\nSpeaker PhD E: OK . Oh , so they 're gonna just deliver a system basically .\nSpeaker PhD D: Yeah , th I  I guess it 's almost ready . So they have released their , , document , describing the system .\nSpeaker professor B: Cuz one of the things that might be helpful , if you 've  if you 've got time in all of this is , is if  if these guys are really focusing on improving , , all the digit stuff , , maybe  and you got the front - end from them , maybe you could do the runs for the \nSpeaker PhD E: Sure .\nSpeaker professor B: and  and , you know , iron out hassles that  that you have to , , tweak Joe about or whatever ,. because you 're more experienced with running the large vocabulary stuff .\nSpeaker PhD D: So I 'll point you to the web site and the mails corresponding . So these sugges these  this , , period during which people are gonna make suggestions is to know whether it is actually biased towards any set of features or \nSpeaker professor B: Yeah , so I th th certainly the thing that I would want to know about is whether we get really hurt , , on in insertion penalty , language model , scaling , sorts of things .\nSpeaker PhD E: Using our features .\nSpeaker professor B: , in which case , , H Hari or Hynek will need to , you know , push the case  more about  about this .\nSpeaker PhD E: And we may be able to revisit this idea about , you know , somehow modifying our features to work with ",
        "summary": "The group also discussed a new part to the evaluation, the use of a chunk of the Wall Street Journal.",
        "split": "train"
    },
    {
        "uid": "322-Bro026",
        "id": "Bro026",
        "text": "Speaker professor B: Got anything to tell us ?\nSpeaker graduate student C: Well , I 've been reading some literature about clustering of data . OK , so we 're talking about discovering intermediate categories to ,  to classify . And , , I was looking at some of the work that , , Sangita was doing on these TRAPS things . So she has ,  she has temporal patterns for , , a certain set of phonemes , from  from TIMIT ,. , and , , I was thinking about ways to  to generalize this. because w you 're  it 's sort of like a  it 's not a completely automatic way of clustering ,\nSpeaker professor B: Are you looking at these in narrow bands ?. Yeah , I mean , it seems somehow that needs th , there 's a couple things that I wonder about with this . I mean , if you 're going for this sort of thing where you have  , little detectors that are looking at narrow bands , then what you 're going to be looking for should be some category that you can find with the narrow bands . , the sort of standard answer about this sort of thing is that if you 're trying to find  the right system in some sense , whether you 're trying by categories or  or parameters  , and your goal is discrimination , then having choices based on discrimination as opposed to , , unsupervised nearness of things , , is actually better . , and I don't know if that  I mean , since you 're dealing with issues of robustness , you know , maybe  maybe this isn't right , but it 'd be something I 'd be concerned about . Because , for instance , you can imagine , , , i i if you remember from  from ,  from your  your quals , John Ohala saying that , , \" buh \"  and \" puh \"  differed , , not really cuz of voicing but because of aspiration . So , , if you looked  if you were doing some coarse clustering , you probably would put those two sounds together . And yet , I would gue I would guess that many of your recognition errors were coming from , , , pfft ,  screwing up on this distinction . if you go and take any recognizer that 's already out there and you say , \" how well is it distinguishing between  schwas and stops ? \". Boy , I bet they 're all doing nearly perfectly on this ,",
        "summary": "Speaker me006 is working on data clustering, and discussion of related issues led to more general acoustic matters.",
        "split": "train"
    },
    {
        "uid": "323-Bro027",
        "id": "Bro027",
        "text": "Speaker PhD C: , I 've been playing with , first , the , , VAD . ,  so it 's exactly the same approach ,",
        "summary": "The main areas being worked on were the voice activity detector and the tandem data streams.",
        "split": "train"
    },
    {
        "uid": "324-Bro027",
        "id": "Bro027",
        "text": "Speaker PhD C: But well , we could probably put the delta , ,  before on - line normalization .\nSpeaker PhD A: What if you used a smaller window for the delta ?. I mean , I guess there 's a lot of things you could do to \nSpeaker professor B: So if you  if you put the delta before the , , ana on - line  If .  then  then it could go in parallel .\nSpeaker PhD C: cuz the time constant of the on - line normalization is pretty long compared to the delta window ,\nSpeaker professor B: and you could experiment with cutting various pieces of these back a bit ,. I mean , we 're s we 're not  we 're not in terrible shape . Well , what 's your  what 's your thought about what to do next with it ?\nSpeaker PhD C: I 'm surprised ,. because I expected the neural net to help more when there is more mismatch , as it was the case for the \nSpeaker professor B: Well , we might  , we might have to experiment with , better training sets . I  The other thing is , I mean , before you found that was the best configuration , but you might have to retest those things now that we have different  The rest of it is different ,. For instance , what 's the effect of just putting the neural net on without the o other  other path ?. I mean , you know what the straight features do .\nSpeaker PhD A: In the ,  a lot of the ,  the Hub - five systems , , recently have been using LDA . and  and they ,  They run LDA on the features right before they train the models .\nSpeaker PhD D: , this LDA is different from the LDA that you are talking about . The LDA that you  saying is , like , you take a block of features , like nine frames or something ,  and then do an LDA on it ,. and then reduce the dimensionality to something like twenty - four or something like that . So this is a two dimensional tile . And the LDA that we are f applying is only in time ,. So it 's like  more like a filtering in time ,\nSpeaker PhD A: but what if you put  ran the other kind of LDA , , on your features right before they go into the HMM ?\nSpeaker PhD C: But it 's  it 's like a nonlinear discriminant analysis .\nSpeaker PhD A: The tandem stuff is kind of like i nonlinear LDA . But I mean , w but the other features that you have , , th the non - tandem ones ,\nSpeaker PhD C: Well , in the proposal , they were transformed u using PCA ,. Yeah , it might be that LDA could be better .\nSpeaker PhD D: The , other thing I was wondering was , , if the neural net , , has any  because of the different noise con unseen noise conditions for the neural net ,. where , like , you train it on those four noise conditions , while you are feeding it with , like , a additional  some four plus some  f few more conditions which it hasn't seen , actually ,. instead of just h having c , those cleaned up t cepstrum , sh should we feed some additional information , like  The  the . I mean , should we f feed the VAD flag , also , at the input so that it  it has some additional discriminating information at the input ?. We have the VAD information also available at the back - end . So if it is something the neural net is not able to discriminate the classes . So , by having an additional , , feature which says \" this is speech and this is nonspeech \" , I mean , it certainly helps in some unseen noise conditions for the neural net .\nSpeaker PhD A: So you 're saying , feed that , also , into  the neural net .\nSpeaker PhD D: Yeah . So it it 's an  additional discriminating information .\nSpeaker professor B: The other thing  you could do is just , , p modify the , , output probabilities of the  of the , , , , neural net , tandem neural net ,  based on the fact that you have a silence probability .",
        "summary": "The group discussed possible further investigations that arose from these areas, including better linking the two.",
        "split": "train"
    },
    {
        "uid": "325-Bro027",
        "id": "Bro027",
        "text": "Speaker professor B: And actually it brought up a question which may be relevant to the Aurora stuff too . , I know that when you figured out the filters that we 're using for the Mel scale , there was some experimentation that went on at  at ,  at OGI . but one of the differences that we found between the two systems that we were using ,  the  the Aurora HTK system baseline system  and the system that we were  the  the , other system we were using , the , the SRI system , was that the SRI system had maybe a , , hundred hertz high - pass . still , it 's possible that we 're getting in some more noise . So I wonder , is it  @ @ Was there  their experimentation with , , say , throwing away that filter or something ?. so I think when  when he gets done with his prelim study I think  one of the next things we 'd want to do is to take this ,  , noise , , processing stuff and  and ,  , synthesize some speech from it .",
        "summary": "They also consider how aspects of an absent member's work might be applied to the current project.",
        "split": "train"
    },
    {
        "uid": "326-Bro027",
        "id": "Bro027",
        "text": "Speaker professor B: So I won't be here for . , I 'm leaving next Wednesday . I 'm leaving  leaving next Wednesday . so next week I won't ,. and the week after I won't ,. cuz I 'll be in Finland . By that time you 'll be   , you 'll both be gone  from here . So it 'll be a few weeks , really , before we have a meeting of the same cast of characters . and then , , we 'll start up again with Dave and  Dave and Barry and Stephane and us on the , , twentieth .",
        "summary": "The meeting closed with a discussion of upcoming absences, and how meetings would continue.",
        "split": "train"
    },
    {
        "uid": "327-Bro028",
        "id": "Bro028",
        "text": "Speaker PhD D: Yeah . So there was this conference call this morning ,. and the only topic on the agenda was just to discuss. a and to come at  , to get a decision about this latency problem .",
        "summary": "On the Aurora Project, there were reports on a project conference call, the status of the tandem neural networks, and progress with the Mississippi State recognizer.",
        "split": "train"
    },
    {
        "uid": "328-Bro028",
        "id": "Bro028",
        "text": "Speaker PhD D: , yeah . There were like two hours of  discussions ,. and then suddenly ,  , people were tired , I guess ,. and they decided on  a number ,. two hundred and twenty ,. included e including everything . So , currently d , we have system that has two hundred and thirty .\nSpeaker professor B: we have to reduce it by ten milliseconds somehow .\nSpeaker PhD D: That 's not a problem , I  I guess .\nSpeaker professor B: W It 's  it 's p d primary  primarily determined by the VAD at this point ,. S so we can make the VAD a little shorter . Yeah . We probably should do that pretty soon so that we don't get used to it being a certain way .\nSpeaker PhD D: , yeah . So , the second thing is the system that we have currently . Oh , yes . We have , like , a system that gives sixty - two percent improvement ,. but  if you want to stick to the   this latency . Well , it has a latency of two thirty ,. but  if you want also to stick to the number  of features that  limit it to sixty ,  then we go a little bit down. but it 's still sixty - one percent .",
        "summary": "The latency limit has been set, and the group's system is performing very well, but is a little over.",
        "split": "train"
    },
    {
        "uid": "329-Bro028",
        "id": "Bro028",
        "text": "Speaker professor B: , while we 're still on Aurora stuff  maybe you can talk a little about the status with the , ,  Wall Street Journal  things for it .\nSpeaker PhD A: So I 've , , downloaded , , a couple of things from Mississippi State . They wrote some scripts that sort of make it easy to run  the system on the Wall Street Journal , , data . , so I haven't run the scripts yet . , I 'm waiting  there was one problem with part of it. and I wrote a note to Joe asking him about it . So I 'm waiting to hear from him . they 're  I I 'm still waiting for them to  release the , ,  multi - CPU version of their scripts ,. cuz right now their script only handles processing on a single CPU ,. which will take a really long time to run . So , as soon as they get that , then I 'll  I 'll grab those too\nSpeaker professor B: Yeah . Cuz we have to get started ,\nSpeaker PhD A: Yeah . I 'll go ahead and try to run it though with just the single CPU one ,. and  I  they  they ,  , released like a smaller data set that you can use that only takes like sixteen hours to train and stuff . So I can  I can run it on that just to make sure that the   the thing works and everything .\nSpeaker professor B: So it could be  I mean , Chuck and I had actually talked about this a couple times , and  and  over some lunches , I think ,  that , ,  one thing that we might wanna do . The - there 's this question about , you know , what do you wanna scale ?. Suppose y you can't adjust  these word insertion penalties and so forth ,. so you have to do everything at the level of the features . And , , one thing I had suggested at an earlier time was maybe some sort of scaling ,. some sort of root or  or something of the , ,  , features . it occurred to me later ,. because what you really want to do is scale the , , @ @  the range of the likelihoods rather than . But ,  I mean , I guess we still haven't had a   a ruling back on this . And we may end up being in a situation where we just you know really can't change the  word insertion penalty . But the other thing we could do  is  also we could . I mean , this  this may not help us ,  , in the evaluation. but it might help us in our understanding at least . We might ,  just run it with different insper insertion penalties ,. and show that , , \" well , OK , not changing it ,  playing the rules the way you wanted , we did this . But in fact if we did that , it made a   a big difference . \"",
        "summary": "On the larger vocabulary task, there are still a few issues to resolve before work can really get started.",
        "split": "train"
    },
    {
        "uid": "330-Bro028",
        "id": "Bro028",
        "text": "Speaker graduate student C: So Michael Kleinschmidt , who 's a PHD student from Germany ,  showed up this week . He 'll be here for about six months . And he 's done some work using  an auditory model  of , ,  human hearing ,. and  using that f , to generate speech recognition features . And  he did  work back in Germany  with , , a toy recognition system  using , , isolated  digit recognition  as the task . he w he 's coming here to u u use it on a  , a real speech recognition system . Th - this is  because it 's ,  there are these different parameters for the shape of these  basis functions ,    there are a lot of different possible basis functions . And so he   he actually does  an optimization procedure to choose an   an optimal set of basis functions out of all the possible ones . is ,   ,  he starts with  he has a set of M of them . I mean , he t he tries , ,  using  just M minus one of them . So there are M possible subsets of this  length - M vector . He tries classifying , using each of the M  possible sub - vectors . Whichever sub - vector ,  , works the  the best , I guess , he says   the  the fe feature that didn't use was the most useless feature ,. so we 'll throw it out. and we 're gonna randomly select another feature  from the set of possible basis functions .\nSpeaker professor B: So I th I think it 's  it 's  I think it 's kinda neat stuff . the thing that I wanted to  to add to it also was to have us use this in a multi - stream way . so  so that , ,  when you come up with these different things ,  and these different functions ,  you don't necessarily just put them all into one huge vector ,. but perhaps  you  have some of them in one stream and some of them in another stream , and so forth .\nSpeaker graduate student E: Well , that sort of segues into  what  what I 'm doing . ,  so , , the big picture is k ,  come up with a set of ,  , intermediate categories ,. then build intermediate category classifiers , then do recognition ,. , so right now I 'm in  in the phase where  I 'm looking at  at , , deciding on a initial set of intermediate categories . And  I 'm looking  for data data - driven  methods that can help me find ,  , a set of intermediate categories  of speech that , , will help me to discriminate  later down the line . And one of the ideas ,  , that was to take a  take a neural net . train  train an ordinary neural net  to   , to learn the posterior probabilities of phones . ,  the other one  was ,  , to ,  , come up with a  a  a model   , a graphical model ,  that treats  the intermediate categories  as hidden  hidden variables , latent variables , that we don't know anything about ,. but that through ,  , s statistical training and the EM algorithm ,  , at the end of the day ,  we have ,  we have learned something about these  these latent ,  latent variables. which happen to correspond to  intermediate categories .",
        "summary": "The group heard of the plan of one of it's member's work into intermediate classifiers, and also of how a visiting research student's work into auditory models can be applied to their work.",
        "split": "train"
    },
    {
        "uid": "331-Buw001",
        "id": "Buw001",
        "text": "Speaker professor D: So what we had  was that we were gonna talk about data collection ,. So   so the question  that  that we started with was whether there was anything else we should do during  during th during the collection . I guess a lot of the stuff we 're doing now really is pilot",
        "summary": "The discussion concerned mainly ideas about data collection and the nature and generation of queries on meetings.",
        "split": "train"
    },
    {
        "uid": "332-Buw001",
        "id": "Buw001",
        "text": "Speaker PhD E: Right . I mean , we  because you 'd have several people with these pads , you could collect different things .\nSpeaker professor A: And  So why don't we just use the notes that somebody takes ?\nSpeaker professor D: And I guess the CrossPads was certainly one idea ,\nSpeaker professor A: So , I j I think we should just say this is not  we don't want to put any extra burden on people , but if they happen to generate minutes , could  could they send it to us ?\nSpeaker professor D: But  but if there 's some cases where they will , then it would be helpful .\nSpeaker professor A: CrossPads we were going to try ,",
        "summary": "Meeting notes taken by participants as standard minutes or summaries, or on devices like CrossPads can provide useful information.",
        "split": "train"
    },
    {
        "uid": "333-Buw001",
        "id": "Buw001",
        "text": "Speaker PhD B: But I 'm just saying first of all there 's a whole bunch of fusion issues that DARPA 's interested in .",
        "summary": "There is also interest in the speech community for fusion of speech with visual data.",
        "split": "train"
    },
    {
        "uid": "334-Buw001",
        "id": "Buw001",
        "text": "Speaker PhD E: I think for this data capture , it would be nice to have a digital camera. just to take pictures of who 's there ,. and then we could also put in what 's on the board .\nSpeaker professor D: Well , minimally , I mean , what  what Dan is referring to at least having some representation of the p the spatial position of the people ,. Like for a meeting like this , at least , , take a Polaroid of the   of the  of the boards ,\nSpeaker professor A: a couple digital pictures of the  the table and boards to set the context of the meeting .",
        "summary": "Taking some photos of the whiteboard and the positioning of participants is easy enough to do.",
        "split": "train"
    },
    {
        "uid": "335-Buw001",
        "id": "Buw001",
        "text": "Speaker Postdoc H: And the fir third thing I wanted to say is the summaries afterwards ,. I  e My thought was to have multiple people summarize it , on recording rather than writing. you know , a two - minute summary of what the meeting was about , I think you would get ,. So , my proposal would be that it may be worth considering both of those types , you know , the note - taking and a spontaneous oral summary afterwards ,\nSpeaker professor A: Yeah . I think that  I think doing it orally at the end of the meeting is the best time . And then the last thing c would be for those people who are willing to stay afterwards and give an oral summary .",
        "summary": "Another option would be the recording by participants of short oral summaries of the meeting.",
        "split": "train"
    },
    {
        "uid": "336-Buw001",
        "id": "Buw001",
        "text": "Speaker graduate student G: I just don't know how else to generate the queries other than getting an expert to actually listen to the meeting and say \" that 's important ,\nSpeaker professor D: but if we were asking the question , which I thought we were , of  of  of , , \" how do we figure out what 's the nature of the queries that people are gonna want to ask of such a system ? \" , knowing what 's important doesn't tell you what people are going to be asking . now I 'm thinking that the summary  a summary , , is actually a reasonable , , bootstrap into this  into what we 'd like to get at .\nSpeaker PhD F: the question I had about queries was , , so what we 're planning to do is have people look at the summaries and then generate queries ?\nSpeaker professor D: u I  I actually think that  that , , again , just as a bootstrap ,  if we do have something like summaries , then having the people who are involved in the meetings themselves , who are cooperative and willing to do yet more , come up with  with  with queries , , could at least give  give Landay an idea of the kind of things that people might want to know .",
        "summary": "Summaries could be used to bootstrap for queries, the exact nature of which remained nebulous.",
        "split": "train"
    },
    {
        "uid": "337-Buw001",
        "id": "Buw001",
        "text": "Speaker professor D: And  and th I think that might then help me to think of things  even things that aren't listed in the summary , but just as a  as a  as a refresh of what the general thing was going on in the meeting . and  but for some  new reason I 'm  I 'm  I 'm interested in  in  in the old stuff .\nSpeaker PhD B: you know , if this is something that requires a  a one - word answer or it 's one place in the recording versus was there general agreement on this issue of all the people who ha\nSpeaker graduate student G: Absolutely . So I think we 're gonna have to start with keywords\nSpeaker Postdoc H: I I was wondering if  if there might be one s more source of queries. which is indicator phrases like \" action item \" ,",
        "summary": "Candidate types are keyword searches, action items, elaboration on points of interest, and agreement between participants.",
        "split": "train"
    },
    {
        "uid": "338-Buw001",
        "id": "Buw001",
        "text": "Speaker professor D: I  I  I mean , I guess what I what I  I keep coming back to in my own mind is that , , the soonest we can do it , we need to get up some kind of system. If  you know , if  , as soon as we can get that going at any kind of level , then I think we 'll have a much better handle on what kind of questions people want to ask than in any  anything we do before that . Well , and again , if we can figure out a way to jimmy a  a  a  a very rough system , say in a year , then  , so that in the second and third years we  we actually have something to ",
        "summary": "An initial prototype system to test any hypotheses can be pipelined.",
        "split": "train"
    },
    {
        "uid": "339-Buw001",
        "id": "Buw001",
        "text": "Speaker professor D: and then what they 're gonna do is take the CD - ROM and transfer it to analog tape\nSpeaker graduate student G: Oh , is this IBM ?\nSpeaker professor D: Yeah . and  give it to a transcription service , , that will ",
        "summary": "The recorded data will be stored on CD-ROM's and sent to IBM for transcription.",
        "split": "train"
    },
    {
        "uid": "340-Buw001",
        "id": "Buw001",
        "text": "Speaker graduate student G: different level , prosody and all that sort of stuff .\nSpeaker professor A: W My  my u feeling right now on format is you guys have been doing all the work",
        "summary": "There is also work being done on the annotation of prosody.",
        "split": "train"
    },
    {
        "uid": "341-Buw001",
        "id": "Buw001",
        "text": "Speaker PhD B: And , I guess we just left it as  @ @  that  if there 's found data that can be transformed for use in speech recognition easily , then of course we would do it ,. but they were recorded anyway , like the congressional hearings and , you know , for legal purposes or whatever .\nSpeaker Postdoc H: But it includes like standard corpora that have been used for years in linguistics and  other fields .",
        "summary": "The corpus could be enriched with found data (public or collected by other projects), if those prove appropriate for use in the project.",
        "split": "train"
    },
    {
        "uid": "342-Buw001",
        "id": "Buw001",
        "text": "Speaker professor A: to c and I 'll put together an overall cover . people are supposed to send me U R. for their  for web pages ,. , you need to put together a mailing list .\nSpeaker professor D: We talked about that we 're getting the recording equipment running at UW .",
        "summary": "Finally, project web pages and mailing list are being set up and UW are going to investigate the suitability of their recording equipment.",
        "split": "train"
    }
]